<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>RStudio AI Blog</title>
    <link>https://blogs.rstudio.com/tensorflow/</link>
    <atom:link href="https://blogs.rstudio.com/tensorflow/index.xml" rel="self" type="application/rss+xml"/>
    <description>News, concepts, and applications as regards deep learning, probabilistic computation, distributed computing and machine learning automation from R.
</description>
    <image>
      <title>RStudio AI Blog</title>
      <url>https://blogs.rstudio.com/tensorflow/images/favicon.png</url>
      <link>https://blogs.rstudio.com/tensorflow/</link>
    </image>
    <generator>Distill</generator>
    <lastBuildDate>Wed, 30 Sep 2020 00:00:00 +0000</lastBuildDate>
    <item>
      <title>Getting familiar with torch tensors</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-10-01-torch-network-from-scratch</link>
      <description>


&lt;p&gt;Two days ago, I introduced &lt;a href="https://github.com/mlverse/torch"&gt;torch&lt;/a&gt;, an R package natively providing functionality that is brought to Python users by &lt;a href="https://pytorch.org/"&gt;PyTorch&lt;/a&gt;. In that post, I assumed basic familiarity with TensorFlow/Keras – in all likelihood, not an unreasonable assumption in the context of this blog. Consequently, I portrayed &lt;code&gt;torch&lt;/code&gt; in a way I figured would be helpful to someone who “grew up” with the Keras way of training a model: Aiming to focus on differences, yet not lose sight of the overall process.&lt;/p&gt;
&lt;p&gt;This post now changes perspective. We code a simple neural network “from scratch”, making use of just a single of &lt;code&gt;torch&lt;/code&gt;’s building blocks (a pretty major one, though): &lt;em&gt;tensors&lt;/em&gt;. This network will be as “raw” (low-level) as can be. (For the less math-inclined people among us, it may serve as a refresher of what’s actually going on beneath all those convenience tools they built for us. But the real purpose is to illustrate what can be done with tensors alone.)&lt;/p&gt;
&lt;p&gt;Subsequently, three posts (of increasingly shorter length) will show how to reduce the effort – noticeably right from the start, enormously once we finish. At the end of this mini-series, you will have seen how automatic differentiation works in &lt;code&gt;torch&lt;/code&gt;, how to use &lt;code&gt;module&lt;/code&gt;s (layers, in &lt;code&gt;keras&lt;/code&gt; speak, and compositions thereof), and optimizers. By then, you’ll have a lot of the background desirable when applying &lt;code&gt;torch&lt;/code&gt; to real-world tasks.&lt;/p&gt;
&lt;p&gt;Back to the current post. This one will be the longest, since there is a lot to learn about tensors: How to create them; how to manipulate their contents and/or modify their shapes; how to convert them to R arrays, matrices or vectors; and of course, given the omnipresent need for speed: how to get all those operations executed on the GPU. Once we’ve cleared that agenda, we code the aforementioned little network, seeing all those aspects in action.&lt;/p&gt;
&lt;h2 id="tensors"&gt;Tensors&lt;/h2&gt;
&lt;h3 id="creation"&gt;Creation&lt;/h3&gt;
&lt;p&gt;Tensors may be created by specifying individual values. Here we create two one-dimensional tensors (vectors), of type &lt;code&gt;float&lt;/code&gt; and &lt;code&gt;bool&lt;/code&gt;, respectively:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(torch)
# a 1d vector of length 2
t &amp;lt;- torch_tensor(c(1, 2))
t

# also 1d, but of type boolean
t &amp;lt;- torch_tensor(c(TRUE, FALSE))
t&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1
 2
[ CPUFloatType{2} ]

torch_tensor 
 1
 0
[ CPUBoolType{2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here are two ways to create two-dimensional tensors (matrices). Note how in the second approach, you need to specify &lt;code&gt;byrow = TRUE&lt;/code&gt; in the call to &lt;code&gt;matrix()&lt;/code&gt; to get values arranged in row-major order.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# a 3x3 tensor (matrix)
t &amp;lt;- torch_tensor(rbind(c(1,2,0), c(3,0,0), c(4,5,6)))
t

# also 3x3
t &amp;lt;- torch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))
t&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1  2  0
 3  0  0
 4  5  6
[ CPUFloatType{3,3} ]

torch_tensor 
 1  2  3
 4  5  6
 7  8  9
[ CPULongType{3,3} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In higher dimensions especially, it can be easier to specify the type of tensor abstractly, as in: “give me a tensor of &amp;lt;…&amp;gt; of shape n1 x n2”, where &amp;lt;…&amp;gt; could be “zeros”; or “ones”; or, say, “values drawn from a standard normal distribution”:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# a 3x3 tensor of standard-normally distributed values
t &amp;lt;- torch_randn(3, 3)
t

# a 4x2x2 (3d) tensor of zeroes
t &amp;lt;- torch_zeros(4, 2, 2)
t&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
-2.1563  1.7085  0.5245
 0.8955 -0.6854  0.2418
 0.4193 -0.7742 -1.0399
[ CPUFloatType{3,3} ]

torch_tensor 
(1,.,.) = 
  0  0
  0  0

(2,.,.) = 
  0  0
  0  0

(3,.,.) = 
  0  0
  0  0

(4,.,.) = 
  0  0
  0  0
[ CPUFloatType{4,2,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many similar functions exist, including, e.g., &lt;code&gt;torch_arange()&lt;/code&gt; to create a tensor holding a sequence of evenly spaced values, &lt;code&gt;torch_eye()&lt;/code&gt; that returns an identity matrix, and &lt;code&gt;torch_logspace()&lt;/code&gt; that will fill a specified range with a list of values spaced logarithmically.&lt;/p&gt;
&lt;p&gt;If no &lt;code&gt;dtype&lt;/code&gt; argument is specified, &lt;code&gt;torch&lt;/code&gt; will infer the data type from the passed-in value(s). For example:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(c(3, 5, 7))
t$dtype

t &amp;lt;- torch_tensor(1L)
t$dtype&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_Float
torch_Long&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But we can explicitly request a different &lt;code&gt;dtype&lt;/code&gt; if we want:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(2, dtype = torch_double())
t$dtype&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_Double&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;torch&lt;/code&gt; tensors live on a &lt;em&gt;device&lt;/em&gt;. By default, this will be the CPU:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t$device&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_device(type=&amp;#39;cpu&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But we could also define a tensor to live on the GPU:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(2, device = &amp;quot;cuda&amp;quot;)
t$device&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_device(type=&amp;#39;cuda&amp;#39;, index=0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll talk more about devices below.&lt;/p&gt;
&lt;p&gt;There is another very important parameter to the tensor creation functions: &lt;code&gt;requires_grad&lt;/code&gt;. Here though, I need to ask for your patience: This one will prominently figure in the follow-up post.&lt;/p&gt;
&lt;h3 id="conversion-to-built-in-r-data-types"&gt;Conversion to built-in R data types&lt;/h3&gt;
&lt;p&gt;To convert &lt;code&gt;torch&lt;/code&gt; tensors to R, use &lt;code&gt;as_array&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))
as_array(t)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    7    8    9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Depending on whether the tensor is one-, two-, or three-dimensional, the resulting R object will be a vector, a matrix, or an array:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(c(1, 2, 3))
as_array(t) %&amp;gt;% class()

t &amp;lt;- torch_ones(c(2, 2))
as_array(t) %&amp;gt;% class()

t &amp;lt;- torch_ones(c(2, 2, 2))
as_array(t) %&amp;gt;% class()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;numeric&amp;quot;

[1] &amp;quot;matrix&amp;quot; &amp;quot;array&amp;quot; 

[1] &amp;quot;array&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For one-dimensional and two-dimensional tensors, it is also possible to use &lt;code&gt;as.integer&lt;/code&gt; / &lt;code&gt;as.matrix&lt;/code&gt;. (One reason you might want to do this is to have more self-documenting code.)&lt;/p&gt;
&lt;p&gt;If a tensor currently lives on the GPU, you need to move it to the CPU first:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(2, device = &amp;quot;cuda&amp;quot;)
as.integer(t$cpu())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="indexing-and-slicing-tensors"&gt;Indexing and slicing tensors&lt;/h3&gt;
&lt;p&gt;Often, we want to retrieve not a complete tensor, but only some of the values it holds, or even just a single value. In these cases, we talk about &lt;em&gt;slicing&lt;/em&gt; and &lt;em&gt;indexing&lt;/em&gt;, respectively.&lt;/p&gt;
&lt;p&gt;In R, these operations are 1-based, meaning that when we specify offsets, we assume for the very first element in an array to reside at offset &lt;code&gt;1&lt;/code&gt;. The same behavior was implemented for &lt;code&gt;torch&lt;/code&gt;. Thus, a lot of the functionality described in this section should feel intuitive.&lt;/p&gt;
&lt;p&gt;The way I’m organizing this section is the following. We’ll inspect the intuitive parts first, where by intuitive I mean: intuitive to the R user who has not yet worked with Python’s &lt;a href="https://numpy.org/"&gt;NumPy&lt;/a&gt;. Then come things which to this user, may look more surprising, but will turn out to be pretty useful.&lt;/p&gt;
&lt;h4 id="indexing-and-slicing-the-r-like-part"&gt;Indexing and slicing, the R-like part&lt;/h4&gt;
&lt;p&gt;None of these should be overly surprising:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(rbind(c(1,2,3), c(4,5,6)))
t

# a single value
t[1, 1]

# first row, all columns
t[1, ]

# first row, a subset of columns
t[1, 1:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1  2  3
 4  5  6
[ CPUFloatType{2,3} ]

torch_tensor 
1
[ CPUFloatType{} ]

torch_tensor 
 1
 2
 3
[ CPUFloatType{3} ]

torch_tensor 
 1
 2
[ CPUFloatType{2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how just as in R, singleton dimensions are dropped:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(rbind(c(1,2,3), c(4,5,6)))

# 2x3
t$size() 

# just a single row: will be returned as a vector
t[1, 1:2]$size() 

# a single element
t[1, 1]$size()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2 3

[1] 2

integer(0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And just like in R, you can specify &lt;code&gt;drop = FALSE&lt;/code&gt; to keep those dimensions:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t[1, 1:2, drop = FALSE]$size()

t[1, 1, drop = FALSE]$size()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 1 2

[1] 1 1&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id="indexing-and-slicing-what-to-look-out-for"&gt;Indexing and slicing: What to look out for&lt;/h4&gt;
&lt;p&gt;Whereas R uses negative numbers to remove elements at specified positions, in &lt;code&gt;torch&lt;/code&gt; negative values indicate that we start counting from the end of a tensor – with &lt;code&gt;-1&lt;/code&gt; pointing to its last element:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(rbind(c(1,2,3), c(4,5,6)))

t[1, -1]

t[ , -2:-1] &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
3
[ CPUFloatType{} ]

torch_tensor 
 2  3
 5  6
[ CPUFloatType{2,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a feature you might know from NumPy. Same with the following.&lt;/p&gt;
&lt;p&gt;When the slicing expression &lt;code&gt;m:n&lt;/code&gt; is augmented by another colon and a third number – &lt;code&gt;m:n:o&lt;/code&gt; –, we will take every &lt;code&gt;o&lt;/code&gt;th item from the range specified by &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_tensor(1:10)
t[2:10:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
  2
  4
  6
  8
 10
[ CPULongType{5} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sometimes we don’t know how many dimensions a tensor has, but we do know what to do with the final dimension, or the first one. To subsume all others, we can use &lt;code&gt;..&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t &amp;lt;- torch_randint(-7, 7, size = c(2, 2, 2))
t

t[.., 1]

t[2, ..]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
(1,.,.) = 
  2 -2
 -5  4

(2,.,.) = 
  0  4
 -3 -1
[ CPUFloatType{2,2,2} ]

torch_tensor 
 2 -5
 0 -3
[ CPUFloatType{2,2} ]

torch_tensor 
 0  4
-3 -1
[ CPUFloatType{2,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we move on to a topic that in practice, is just as indispensable as slicing: changing tensor &lt;em&gt;shapes&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="reshaping-tensors"&gt;Reshaping tensors&lt;/h3&gt;
&lt;p&gt;Changes in shape can occur in two fundamentally different ways. Seeing how “reshape” really means: &lt;em&gt;keep the values but modify their layout&lt;/em&gt;, we could either alter how they’re arranged physically or keep the physical structure as-is and just change the “mapping” (a semantic change, as it were).&lt;/p&gt;
&lt;p&gt;In the first case, storage will have to be allocated for two tensors, source and target, and elements will be copied from the latter to the former. In the second, physically there will be just a single tensor, referenced by two logical entities with distinct metadata.&lt;/p&gt;
&lt;p&gt;Not surprisingly, for performance reasons, the second operation is preferred.&lt;/p&gt;
&lt;h4 id="zero-copy-reshaping"&gt;Zero-copy reshaping&lt;/h4&gt;
&lt;p&gt;We start with zero-copy methods, as we’ll want to use them whenever we can.&lt;/p&gt;
&lt;p&gt;A special case often seen in practice is adding or removing a singleton dimension.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;unsqueeze()&lt;/code&gt; adds a dimension of size &lt;code&gt;1&lt;/code&gt; at a position specified by &lt;code&gt;dim&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randint(low = 3, high = 7, size = c(3, 3, 3))
t1$size()

t2 &amp;lt;- t1$unsqueeze(dim = 1)
t2$size()

t3 &amp;lt;- t1$unsqueeze(dim = 2)
t3$size()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 3 3 3

[1] 1 3 3 3

[1] 3 1 3 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Conversely, &lt;code&gt;squeeze()&lt;/code&gt; removes singleton dimensions:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t4 &amp;lt;- t3$squeeze()
t4$size()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 3 3 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The same could be accomplished with &lt;code&gt;view()&lt;/code&gt;. &lt;code&gt;view()&lt;/code&gt;, however, is much more general, in that it allows you to reshape the data to any valid dimensionality. (Valid meaning: The number of elements stays the same.)&lt;/p&gt;
&lt;p&gt;Here we have a &lt;code&gt;3x2&lt;/code&gt; tensor that is reshaped to size &lt;code&gt;2x3&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))
t1

t2 &amp;lt;- t1$view(c(2, 3))
t2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1  2
 3  4
 5  6
[ CPUFloatType{3,2} ]

torch_tensor 
 1  2  3
 4  5  6
[ CPUFloatType{2,3} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Note how this is different from matrix transposition.)&lt;/p&gt;
&lt;p&gt;Instead of going from two to three dimensions, we can flatten the matrix to a vector.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t4 &amp;lt;- t1$view(c(-1, 6))

t4$size()

t4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 1 6

torch_tensor 
 1  2  3  4  5  6
[ CPUFloatType{1,6} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In contrast to indexing operations, this does not drop dimensions.&lt;/p&gt;
&lt;p&gt;Like we said above, operations like &lt;code&gt;squeeze&lt;/code&gt; or &lt;code&gt;view()&lt;/code&gt; do not make copies. Or, put differently: The output tensor shares storage with the input tensor. We can in fact verify this ourselves:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1$storage()$data_ptr()

t2$storage()$data_ptr()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;0x5648d02ac800&amp;quot;

[1] &amp;quot;0x5648d02ac800&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What’s different is the storage &lt;em&gt;metadata&lt;/em&gt; &lt;code&gt;torch&lt;/code&gt; keeps about both tensors. Here, the relevant information is the &lt;em&gt;stride&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;A tensor’s &lt;code&gt;stride()&lt;/code&gt; method tracks, &lt;em&gt;for every dimension&lt;/em&gt;, how many elements have to be traversed to arrive at its next element (row or column, in two dimensions). For &lt;code&gt;t1&lt;/code&gt; above, of shape &lt;code&gt;3x2&lt;/code&gt;, we have to skip over 2 items to arrive at the next row. To arrive at the next column though, in every row we just have to skip a single entry:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1$stride()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;t2&lt;/code&gt;, of shape &lt;code&gt;3x2&lt;/code&gt;, the distance between column elements is the same, but the distance between rows is now 3:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t2$stride()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 3 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While zero-copy operations are optimal, there are cases where they won’t work.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;view()&lt;/code&gt;, this can happen when a tensor was obtained via an operation – other than &lt;code&gt;view()&lt;/code&gt; itself – that itself has already modified the &lt;em&gt;stride&lt;/em&gt;. One example would be &lt;code&gt;transpose()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))
t1
t1$stride()

t2 &amp;lt;- t1$t()
t2
t2$stride()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1  2
 3  4
 5  6
[ CPUFloatType{3,2} ]

[1] 2 1

torch_tensor 
 1  3  5
 2  4  6
[ CPUFloatType{2,3} ]

[1] 1 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In &lt;code&gt;torch&lt;/code&gt; lingo, tensors – like &lt;code&gt;t2&lt;/code&gt; – that re-use existing storage (and just read it differently), are said not to be “contiguous”&lt;a href="#fn1" class="footnote-ref" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. One way to reshape them is to use &lt;code&gt;contiguous()&lt;/code&gt; on them before. We’ll see this in the next subsection.&lt;/p&gt;
&lt;h4 id="reshape-with-copy"&gt;Reshape with copy&lt;/h4&gt;
&lt;p&gt;In the following snippet, trying to reshape &lt;code&gt;t2&lt;/code&gt; using &lt;code&gt;view()&lt;/code&gt; fails, as it already carries information indicating that the underlying data should not be read in physical order.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))

t2 &amp;lt;- t1$t()

t2$view(6) # error!&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in (function (self, size)  : 
  view size is not compatible with input tensor&amp;#39;s size and stride (at least one dimension spans across two contiguous subspaces).
  Use .reshape(...) instead. (view at ../aten/src/ATen/native/TensorShape.cpp:1364)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, if we first call &lt;code&gt;contiguous()&lt;/code&gt; on it, a &lt;em&gt;new tensor&lt;/em&gt; is created, which may then be (virtually) reshaped using &lt;code&gt;view()&lt;/code&gt;.&lt;a href="#fn2" class="footnote-ref" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t3 &amp;lt;- t2$contiguous()

t3$view(6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1
 3
 5
 2
 4
 6
[ CPUFloatType{6} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, we can use &lt;code&gt;reshape()&lt;/code&gt;. &lt;code&gt;reshape()&lt;/code&gt; defaults to &lt;code&gt;view()&lt;/code&gt;-like behavior if possible; otherwise it will create a physical copy.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t2$storage()$data_ptr()

t4 &amp;lt;- t2$reshape(6)

t4$storage()$data_ptr()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;0x5648d49b4f40&amp;quot;

[1] &amp;quot;0x5648d2752980&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="operations-on-tensors"&gt;Operations on tensors&lt;/h3&gt;
&lt;p&gt;Unsurprisingly, &lt;code&gt;torch&lt;/code&gt; provides a bunch of mathematical operations on tensors; we’ll see some of them in the network code below, and you’ll encounter lots more when you continue your &lt;code&gt;torch&lt;/code&gt; journey. Here, we just quickly take a look at the overall tensor method semantics.&lt;/p&gt;
&lt;p&gt;Tensor methods normally return references to new objects. Here, we add to &lt;code&gt;t1&lt;/code&gt; a clone of itself:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_tensor(rbind(c(1, 2), c(3, 4), c(5, 6)))
t2 &amp;lt;- t1$clone()

t1$add(t2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
  2   4
  6   8
 10  12
[ CPUFloatType{3,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this process, &lt;code&gt;t1&lt;/code&gt; has not been modified:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1  2
 3  4
 5  6
[ CPUFloatType{3,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many tensor methods have variants for mutating operations. These all carry a trailing underscore:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1$add_(t1)

# now t1 has been modified
t1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
  4   8
 12  16
 20  24
[ CPUFloatType{3,2} ]

torch_tensor 
  4   8
 12  16
 20  24
[ CPUFloatType{3,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, you can of course assign the new object to a new reference variable:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t3 &amp;lt;- t1$add(t1)

t3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
  8  16
 24  32
 40  48
[ CPUFloatType{3,2} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is one thing we need to discuss before we wrap up our introduction to tensors: How can we have all those operations executed on the GPU?&lt;/p&gt;
&lt;h2 id="running-on-gpu"&gt;Running on GPU&lt;/h2&gt;
&lt;p&gt;To check if your GPU(s) is/are visible to torch, run&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;cuda_is_available()

cuda_device_count()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] TRUE

[1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tensors may be requested to live on the GPU right at creation:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;device &amp;lt;- torch_device(&amp;quot;cuda&amp;quot;)

t &amp;lt;- torch_ones(c(2, 2), device = device) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, they can be moved between devices at any time:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t2 &amp;lt;- t$cuda()
t2$device&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_device(type=&amp;#39;cuda&amp;#39;, index=0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;t3 &amp;lt;- t2$cpu()
t3$device&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_device(type=&amp;#39;cpu&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it for our discussion on tensors — almost. There is one &lt;code&gt;torch&lt;/code&gt; feature that, although related to tensor operations, deserves special mention. It is called broadcasting, and “bilingual” (R + Python) users will know it from NumPy.&lt;/p&gt;
&lt;h2 id="broadcasting"&gt;Broadcasting&lt;/h2&gt;
&lt;p&gt;We often have to perform operations on tensors with shapes that don’t match exactly.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, we can add a scalar to a tensor:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(3,5))

t1 + 22&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 23.1097  21.4425  22.7732  22.2973  21.4128
 22.6936  21.8829  21.1463  21.6781  21.0827
 22.5672  21.2210  21.2344  23.1154  20.5004
[ CPUFloatType{3,5} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The same will work if we add tensor of size &lt;code&gt;1&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(3,5))

t1 + torch_tensor(c(22))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Adding tensors of different sizes normally won’t work:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(3,5))
t2 &amp;lt;- torch_randn(c(5,5))

t1$add(t2) # error&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Error in (function (self, other, alpha)  : 
  The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 1 (infer_size at ../aten/src/ATen/ExpandUtils.cpp:24)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, under certain conditions, one or both tensors may be virtually expanded so both tensors line up. This behavior is what is meant by &lt;em&gt;broadcasting&lt;/em&gt;. The way it works in &lt;code&gt;torch&lt;/code&gt; is not just inspired by, but actually identical to that of NumPy.&lt;/p&gt;
&lt;p&gt;The rules are:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;We align array shapes, &lt;em&gt;starting from the right&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Say we have two tensors, one of size &lt;code&gt;8x1x6x1&lt;/code&gt;, the other of size &lt;code&gt;7x1x5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here they are, right-aligned:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;# t1, shape:     8  1  6  1
# t2, shape:        7  1  5&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2" style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Starting to look from the right&lt;/em&gt;, the sizes along aligned axes either have to match exactly, or one of them has to be equal to &lt;code&gt;1&lt;/code&gt;: in which case the latter is &lt;em&gt;broadcast&lt;/em&gt; to the larger one.&lt;/p&gt;
&lt;p&gt;In the above example, this is the case for the second-from-last dimension. This now gives&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;# t1, shape:     8  1  6  1
# t2, shape:        7  6  5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;, with broadcasting happening in &lt;code&gt;t2&lt;/code&gt;.&lt;/p&gt;
&lt;ol start="3" style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;If on the left, one of the arrays has an additional axis (or more than one), the other is virtually expanded to have a size of &lt;code&gt;1&lt;/code&gt; in that place, in which case broadcasting will happen as stated in (2).&lt;/p&gt;
&lt;p&gt;This is the case with &lt;code&gt;t1&lt;/code&gt;’s leftmost dimension. First, there is a virtual expansion&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- --&gt;
&lt;pre&gt;&lt;code&gt;# t1, shape:     8  1  6  1
# t2, shape:     1  7  1  5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then, broadcasting happens:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# t1, shape:     8  1  6  1
# t2, shape:     8  7  1  5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to these rules, our above example&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(3,5))
t2 &amp;lt;- torch_randn(c(5,5))

t1$add(t2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;could be modified in various ways that would allow for adding two tensors.&lt;/p&gt;
&lt;p&gt;For example, if &lt;code&gt;t2&lt;/code&gt; were &lt;code&gt;1x5&lt;/code&gt;, it would only need to get broadcast to size &lt;code&gt;3x5&lt;/code&gt; before the addition operation:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(3,5))
t2 &amp;lt;- torch_randn(c(1,5))

t1$add(t2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
-1.0505  1.5811  1.1956 -0.0445  0.5373
 0.0779  2.4273  2.1518 -0.6136  2.6295
 0.1386 -0.6107 -1.2527 -1.3256 -0.1009
[ CPUFloatType{3,5} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If it were of size &lt;code&gt;5&lt;/code&gt;, a virtual leading dimension would be added, and then, the same broadcasting would take place as in the previous case.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(3,5))
t2 &amp;lt;- torch_randn(c(5))

t1$add(t2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
-1.4123  2.1392 -0.9891  1.1636 -1.4960
 0.8147  1.0368 -2.6144  0.6075 -2.0776
-2.3502  1.4165  0.4651 -0.8816 -1.0685
[ CPUFloatType{3,5} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a more complex example. Broadcasting how happens both in &lt;code&gt;t1&lt;/code&gt; and in &lt;code&gt;t2&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_randn(c(1,5))
t2 &amp;lt;- torch_randn(c(3,1))

t1$add(t2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
 1.2274  1.1880  0.8531  1.8511 -0.0627
 0.2639  0.2246 -0.1103  0.8877 -1.0262
-1.5951 -1.6344 -1.9693 -0.9713 -2.8852
[ CPUFloatType{3,5} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a nice concluding example, through broadcasting, an outer product can be computed like so:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t1 &amp;lt;- torch_tensor(c(0, 10, 20, 30))

t2 &amp;lt;- torch_tensor(c(1, 2, 3))

t1$view(c(4,1)) * t2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;torch_tensor 
  0   0   0
 10  20  30
 20  40  60
 30  60  90
[ CPUFloatType{4,3} ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now, we really get to implementing that neural network!&lt;/p&gt;
&lt;h2 id="a-simple-neural-network-using-torch-tensors"&gt;A simple neural network using &lt;code&gt;torch&lt;/code&gt; tensors&lt;/h2&gt;
&lt;p&gt;Our task, which we’ll approach in a low-level way today but considerably simplify in upcoming installments, consists of regressing a single target datum based on three input variables.&lt;/p&gt;
&lt;p&gt;We directly use &lt;code&gt;torch&lt;/code&gt; to simulate some data.&lt;/p&gt;
&lt;h4 id="toy-data"&gt;Toy data&lt;/h4&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(torch)

# input dimensionality (number of input features)
d_in &amp;lt;- 3
# output dimensionality (number of predicted features)
d_out &amp;lt;- 1
# number of observations in training set
n &amp;lt;- 100


# create random data
# input
x &amp;lt;- torch_randn(n, d_in)
# target
y &amp;lt;- x[, 1, drop = FALSE] * 0.2 -
  x[, 2, drop = FALSE] * 1.3 -
  x[, 3, drop = FALSE] * 0.5 +
  torch_randn(n, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we need to initialize the network’s weights. We’ll have one hidden layer, with &lt;code&gt;32&lt;/code&gt; units. The output layer’s size, being determined by the task, is equal to &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id="initialize-weights"&gt;Initialize weights&lt;/h4&gt;
&lt;pre class="r"&gt;&lt;code&gt;# dimensionality of hidden layer
d_hidden &amp;lt;- 32

# weights connecting input to hidden layer
w1 &amp;lt;- torch_randn(d_in, d_hidden)
# weights connecting hidden to output layer
w2 &amp;lt;- torch_randn(d_hidden, d_out)

# hidden layer bias
b1 &amp;lt;- torch_zeros(1, d_hidden)
# output layer bias
b2 &amp;lt;- torch_zeros(1, d_out)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now for the training loop proper. The training loop really here &lt;em&gt;is&lt;/em&gt; the network.&lt;/p&gt;
&lt;h4 id="training-loop"&gt;Training loop&lt;/h4&gt;
&lt;p&gt;In each iteration (“epoch”), the training loop does four things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;run through the network, computing predictions (&lt;em&gt;forward pass)&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;compare those predictions to the ground truth and quantify the loss&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;run backwards through the network, computing the gradients that indicate how the weights should be changed&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;actually update the weights, making use of the requested learning rate&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is the template we’re going to fill:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;for (t in 1:200) {
    
    ### -------- Forward pass -------- 
    
    # here we&amp;#39;ll compute the prediction
    
    
    ### -------- compute loss -------- 
    
    # here we&amp;#39;ll compute the sum of squared errors
    

    ### -------- Backpropagation -------- 
    
    # here we&amp;#39;ll pass through the network, calculating the required gradients
    

    ### -------- Update weights -------- 
    
    # here we&amp;#39;ll update the weights, subtracting portion of the gradients 
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The forward pass effectuates two affine transformations, one for the hidden and output layers each. In-between, ReLU activation is applied:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  # compute pre-activations of hidden layers (dim: 100 x 32)
  # torch_mm does matrix multiplication
  h &amp;lt;- x$mm(w1) + b1
  
  # apply activation function (dim: 100 x 32)
  # torch_clamp cuts off values below/above given thresholds
  h_relu &amp;lt;- h$clamp(min = 0)
  
  # compute output (dim: 100 x 1)
  y_pred &amp;lt;- h_relu$mm(w2) + b2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our loss here is mean squared error:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  loss &amp;lt;- as.numeric((y_pred - y)$pow(2)$sum())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculating gradients the manual way is a bit tedious, but it can be done:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  # gradient of loss w.r.t. prediction (dim: 100 x 1)
  grad_y_pred &amp;lt;- 2 * (y_pred - y)
  # gradient of loss w.r.t. w2 (dim: 32 x 1)
  grad_w2 &amp;lt;- h_relu$t()$mm(grad_y_pred)
  # gradient of loss w.r.t. hidden activation (dim: 100 x 32)
  grad_h_relu &amp;lt;- grad_y_pred$mm(w2$t())
  # gradient of loss w.r.t. hidden pre-activation (dim: 100 x 32)
  grad_h &amp;lt;- grad_h_relu$clone()
  
  grad_h[h &amp;lt; 0] &amp;lt;- 0
  
  # gradient of loss w.r.t. b2 (shape: ())
  grad_b2 &amp;lt;- grad_y_pred$sum()
  
  # gradient of loss w.r.t. w1 (dim: 3 x 32)
  grad_w1 &amp;lt;- x$t()$mm(grad_h)
  # gradient of loss w.r.t. b1 (shape: (32, ))
  grad_b1 &amp;lt;- grad_h$sum(dim = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final step then uses the calculated gradients to update the weights:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  learning_rate &amp;lt;- 1e-4
  
  w2 &amp;lt;- w2 - learning_rate * grad_w2
  b2 &amp;lt;- b2 - learning_rate * grad_b2
  w1 &amp;lt;- w1 - learning_rate * grad_w1
  b1 &amp;lt;- b1 - learning_rate * grad_b1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s use these snippets to fill in the gaps in the above template, and give it a try!&lt;/p&gt;
&lt;h4 id="putting-it-all-together"&gt;Putting it all together&lt;/h4&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(torch)

### generate training data -----------------------------------------------------

# input dimensionality (number of input features)
d_in &amp;lt;- 3
# output dimensionality (number of predicted features)
d_out &amp;lt;- 1
# number of observations in training set
n &amp;lt;- 100


# create random data
x &amp;lt;- torch_randn(n, d_in)
y &amp;lt;-
  x[, 1, NULL] * 0.2 - x[, 2, NULL] * 1.3 - x[, 3, NULL] * 0.5 + torch_randn(n, 1)


### initialize weights ---------------------------------------------------------

# dimensionality of hidden layer
d_hidden &amp;lt;- 32
# weights connecting input to hidden layer
w1 &amp;lt;- torch_randn(d_in, d_hidden)
# weights connecting hidden to output layer
w2 &amp;lt;- torch_randn(d_hidden, d_out)

# hidden layer bias
b1 &amp;lt;- torch_zeros(1, d_hidden)
# output layer bias
b2 &amp;lt;- torch_zeros(1, d_out)

### network parameters ---------------------------------------------------------

learning_rate &amp;lt;- 1e-4

### training loop --------------------------------------------------------------

for (t in 1:200) {
  ### -------- Forward pass --------
  
  # compute pre-activations of hidden layers (dim: 100 x 32)
  h &amp;lt;- x$mm(w1) + b1
  # apply activation function (dim: 100 x 32)
  h_relu &amp;lt;- h$clamp(min = 0)
  # compute output (dim: 100 x 1)
  y_pred &amp;lt;- h_relu$mm(w2) + b2
  
  ### -------- compute loss --------

  loss &amp;lt;- as.numeric((y_pred - y)$pow(2)$sum())
  
  if (t %% 10 == 0)
    cat(&amp;quot;Epoch: &amp;quot;, t, &amp;quot;   Loss: &amp;quot;, loss, &amp;quot;\n&amp;quot;)
  
  ### -------- Backpropagation --------
  
  # gradient of loss w.r.t. prediction (dim: 100 x 1)
  grad_y_pred &amp;lt;- 2 * (y_pred - y)
  # gradient of loss w.r.t. w2 (dim: 32 x 1)
  grad_w2 &amp;lt;- h_relu$t()$mm(grad_y_pred)
  # gradient of loss w.r.t. hidden activation (dim: 100 x 32)
  grad_h_relu &amp;lt;- grad_y_pred$mm(
    w2$t())
  # gradient of loss w.r.t. hidden pre-activation (dim: 100 x 32)
  grad_h &amp;lt;- grad_h_relu$clone()
  
  grad_h[h &amp;lt; 0] &amp;lt;- 0
  
  # gradient of loss w.r.t. b2 (shape: ())
  grad_b2 &amp;lt;- grad_y_pred$sum()
  
  # gradient of loss w.r.t. w1 (dim: 3 x 32)
  grad_w1 &amp;lt;- x$t()$mm(grad_h)
  # gradient of loss w.r.t. b1 (shape: (32, ))
  grad_b1 &amp;lt;- grad_h$sum(dim = 1)
  
  ### -------- Update weights --------
  
  w2 &amp;lt;- w2 - learning_rate * grad_w2
  b2 &amp;lt;- b2 - learning_rate * grad_b2
  w1 &amp;lt;- w1 - learning_rate * grad_w1
  b1 &amp;lt;- b1 - learning_rate * grad_b1
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Epoch:  10     Loss:  352.3585 
Epoch:  20     Loss:  219.3624 
Epoch:  30     Loss:  155.2307 
Epoch:  40     Loss:  124.5716 
Epoch:  50     Loss:  109.2687 
Epoch:  60     Loss:  100.1543 
Epoch:  70     Loss:  94.77817 
Epoch:  80     Loss:  91.57003 
Epoch:  90     Loss:  89.37974 
Epoch:  100    Loss:  87.64617 
Epoch:  110    Loss:  86.3077 
Epoch:  120    Loss:  85.25118 
Epoch:  130    Loss:  84.37959 
Epoch:  140    Loss:  83.44133 
Epoch:  150    Loss:  82.60386 
Epoch:  160    Loss:  81.85324 
Epoch:  170    Loss:  81.23454 
Epoch:  180    Loss:  80.68679 
Epoch:  190    Loss:  80.16555 
Epoch:  200    Loss:  79.67953 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This looks like it worked pretty well! It also should have fulfilled its purpose: Showing what all you can achieve using &lt;code&gt;torch&lt;/code&gt; tensors alone. In case you didn’t feel like going through the backprop logic with too much enthusiasm, don’t worry: In the next installment, this will get significantly less cumbersome. See you then!&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;Although the assumption may be tempting, “contiguous” does not correspond to what we’d call “contiguous in memory” in casual language.&lt;a href="#fnref1" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;For correctness’ sake, &lt;code&gt;contiguous()&lt;/code&gt; will only make a copy if the tensor it is called on is &lt;em&gt;not contiguous already.&lt;/em&gt;&lt;a href="#fnref2" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>b3342ae85ca28cf328840b0841a346d0</distill:md5>
      <category>Torch</category>
      <category>R</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-10-01-torch-network-from-scratch</guid>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-10-01-torch-network-from-scratch/images/pic.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Introducing sparklyr.flint: A time-series extension for sparklyr</title>
      <dc:creator>Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-09-07-sparklyr-flint</link>
      <description>


&lt;p&gt;In this blog post, we will showcase &lt;a href="https://cran.r-project.org/web/packages/sparklyr.flint/index.html"&gt;&lt;code&gt;sparklyr.flint&lt;/code&gt;&lt;/a&gt;, a brand new &lt;a href="https://sparklyr.ai"&gt;&lt;code&gt;sparklyr&lt;/code&gt;&lt;/a&gt; extension providing a simple and intuitive R interface to the &lt;a href="https://github.com/twosigma/flint"&gt;&lt;code&gt;Flint&lt;/code&gt;&lt;/a&gt; time series library. &lt;code&gt;sparklyr.flint&lt;/code&gt; is available on &lt;a href="https://cran.r-project.org/web/packages/sparklyr.flint/index.html"&gt;CRAN&lt;/a&gt; today and can be installed as follows:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;install.packages(&amp;quot;sparklyr.flint&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first two sections of this post will be a quick bird’s eye view on &lt;code&gt;sparklyr&lt;/code&gt; and &lt;code&gt;Flint&lt;/code&gt;, which will ensure readers unfamiliar with &lt;code&gt;sparklyr&lt;/code&gt; or &lt;code&gt;Flint&lt;/code&gt; can see both of them as essential building blocks for &lt;code&gt;sparklyr.flint&lt;/code&gt;. After that, we will feature &lt;code&gt;sparklyr.flint&lt;/code&gt;’s design philosophy, current state, example usages, and last but not least, its future directions as an open-source project in the subsequent sections.&lt;/p&gt;
&lt;h1 id="quick-intro-to-sparklyr"&gt;Quick Intro to &lt;code&gt;sparklyr&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;sparklyr&lt;/code&gt; is an open-source R interface that integrates the power of distributed computing from &lt;a href="https://spark.apache.org"&gt;Apache Spark&lt;/a&gt; with the familiar idioms, tools, and paradigms for data transformation and data modelling in R. It allows data pipelines working well with non-distributed data in R to be easily transformed into analogous ones that can process large-scale, distributed data in Apache Spark.&lt;/p&gt;
&lt;p&gt;Instead of summarizing everything &lt;code&gt;sparklyr&lt;/code&gt; has to offer in a few sentences, which is impossible to do, this section will solely focus on a small subset of &lt;code&gt;sparklyr&lt;/code&gt; functionalities that are relevant to connecting to Apache Spark from R, importing time series data from external data sources to Spark, and also simple transformations which are typically part of data pre-processing steps.&lt;/p&gt;
&lt;h3 id="connecting-to-an-apache-spark-cluster"&gt;Connecting to an Apache Spark cluster&lt;/h3&gt;
&lt;p&gt;The first step in using &lt;code&gt;sparklyr&lt;/code&gt; is to connect to Apache Spark. Usually this means one of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Running Apache Spark locally on your machine, and connecting to it to test, debug, or to execute quick demos that don’t require a multi-node Spark cluster:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(sparklyr)

sc &amp;lt;- spark_connect(master = &amp;quot;local&amp;quot;, version = &amp;quot;2.4.4&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Connecting to a multi-node Apache Spark cluster that is managed by a cluster manager such as &lt;a href="https://spark.apache.org/docs/latest/running-on-yarn.html"&gt;YARN&lt;/a&gt;, e.g.,&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(sparklyr)

sc &amp;lt;- spark_connect(master = &amp;quot;yarn-client&amp;quot;, spark_home = &amp;quot;/usr/lib/spark&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="importing-external-data-to-spark"&gt;Importing external data to Spark&lt;/h3&gt;
&lt;p&gt;Making external data available in Spark is easy with &lt;code&gt;sparklyr&lt;/code&gt; given the large number of data sources &lt;code&gt;sparklyr&lt;/code&gt; supports. For example, given an R dataframe, such as&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;dat &amp;lt;- data.frame(id = seq(10), value = rnorm(10))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;the command to copy it to a Spark dataframe with 3 partitions is simply&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sdf &amp;lt;- copy_to(sc, dat, name = &amp;quot;unique_name_of_my_spark_dataframe&amp;quot;, repartition = 3L)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, there are options for ingesting data in CSV, JSON, ORC, AVRO, and many other well-known formats into Spark as well:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sdf_csv &amp;lt;- spark_read_csv(sc, name = &amp;quot;another_spark_dataframe&amp;quot;, path = &amp;quot;file:///tmp/file.csv&amp;quot;, repartition = 3L)
# or
sdf_json &amp;lt;- spark_read_json(sc, name = &amp;quot;yet_another_one&amp;quot;, path = &amp;quot;file:///tmp/file.json&amp;quot;, repartition = 3L)
# or spark_read_orc, spark_read_avro, etc&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="transforming-a-spark-dataframe"&gt;Transforming a Spark dataframe&lt;/h3&gt;
&lt;p&gt;With &lt;code&gt;sparklyr&lt;/code&gt;, the simplest and most readable way to transformation a Spark dataframe is by using &lt;code&gt;dplyr&lt;/code&gt; verbs and the pipe operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) from &lt;a href="https://cran.r-project.org/web/packages/magrittr/index.html"&gt;magrittr&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Sparklyr&lt;/code&gt; supports a large number of &lt;code&gt;dplyr&lt;/code&gt; verbs. For example,&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sdf &amp;lt;- sdf %&amp;gt;%
  dplyr::filter(!is.null(id)) %&amp;gt;%
  dplyr::mutate(value = value ^ 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ensures &lt;code&gt;sdf&lt;/code&gt; only contains rows with non-null IDs, and then squares the &lt;code&gt;value&lt;/code&gt; column of each row.&lt;/p&gt;
&lt;p&gt;That’s about it for a quick intro to &lt;code&gt;sparklyr&lt;/code&gt;. You can learn more in &lt;a href="https://sparklyr.ai"&gt;sparklyr.ai&lt;/a&gt;, where you will find links to reference material, books, communities, sponsors, and much more.&lt;/p&gt;
&lt;h1 id="what-is-flint"&gt;What is &lt;code&gt;Flint&lt;/code&gt;?&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;Flint&lt;/code&gt; is a powerful open-source library for working with time-series data in Apache Spark. First of all, it supports efficient computation of aggregate statistics on time-series data points having the same timestamp (a.k.a &lt;code&gt;summarizeCycles&lt;/code&gt; in &lt;code&gt;Flint&lt;/code&gt; nomenclature), within a given time window (a.k.a., &lt;code&gt;summarizeWindows&lt;/code&gt;), or within some given time intervals (a.k.a &lt;code&gt;summarizeIntervals&lt;/code&gt;). It can also join two or more time-series datasets based on inexact match of timestamps using asof join functions such as &lt;code&gt;LeftJoin&lt;/code&gt; and &lt;code&gt;FutureLeftJoin&lt;/code&gt;. The author of &lt;code&gt;Flint&lt;/code&gt; has outlined many more of &lt;code&gt;Flint&lt;/code&gt;’s major functionalities in &lt;a href="https://databricks.com/blog/2018/09/11/introducing-flint-a-time-series-library-for-apache-spark.html"&gt;this article&lt;/a&gt;, which I found to be extremely helpful when working out how to build &lt;code&gt;sparklyr.flint&lt;/code&gt; as a simple and straightforward R interface for such functionalities.&lt;/p&gt;
&lt;p&gt;Readers wanting some direct hands-on experience with Flint and Apache Spark can go through the following steps to run a minimal example of using Flint to analyze time-series data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First, install Apache Spark locally, and then for convenience reasons, define the &lt;code&gt;SPARK_HOME&lt;/code&gt; environment variable. In this example, we will run Flint with Apache Spark 2.4.4 installed at &lt;code&gt;~/spark&lt;/code&gt;, so:&lt;/p&gt;
&lt;pre class="bash"&gt;&lt;code&gt;export SPARK_HOME=~/spark/spark-2.4.4-bin-hadoop2.7&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Launch Spark shell and instruct it to download &lt;code&gt;Flint&lt;/code&gt; and its Maven dependencies:&lt;/p&gt;
&lt;pre class="bash"&gt;&lt;code&gt;&amp;quot;${SPARK_HOME}&amp;quot;/bin/spark-shell --packages=com.twosigma:flint:0.6.0&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a simple Spark dataframe containing some time-series data:&lt;/p&gt;
&lt;pre class="scala"&gt;&lt;code&gt;import spark.implicits._

val ts_sdf = Seq((1L, 1), (2L, 4), (3L, 9), (4L, 16)).toDF(&amp;quot;time&amp;quot;, &amp;quot;value&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Import the dataframe along with additional metadata such as time unit and name of the timestamp column into a &lt;code&gt;TimeSeriesRDD&lt;/code&gt;, so that &lt;code&gt;Flint&lt;/code&gt; can interpret the time-series data unambiguously:&lt;/p&gt;
&lt;pre class="scala"&gt;&lt;code&gt;import com.twosigma.flint.timeseries.TimeSeriesRDD

val ts_rdd = TimeSeriesRDD.fromDF(
  ts_sdf
)(
  isSorted = true, // rows are already sorted by time
  timeUnit = java.util.concurrent.TimeUnit.SECONDS,
  timeColumn = &amp;quot;time&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, after all the hard work above, we can leverage various time-series functionalities provided by &lt;code&gt;Flint&lt;/code&gt; to analyze &lt;code&gt;ts_rdd&lt;/code&gt;. For example, the following will produce a new column named &lt;code&gt;value_sum&lt;/code&gt;. For each row, &lt;code&gt;value_sum&lt;/code&gt; will contain the summation of &lt;code&gt;value&lt;/code&gt;s that occurred within the past 2 seconds from the timestamp of that row:&lt;/p&gt;
&lt;pre class="scala"&gt;&lt;code&gt;import com.twosigma.flint.timeseries.Windows
import com.twosigma.flint.timeseries.Summarizers

val window = Windows.pastAbsoluteTime(&amp;quot;2s&amp;quot;)
val summarizer = Summarizers.sum(&amp;quot;value&amp;quot;)
val result = ts_rdd.summarizeWindows(window, summarizer)

result.toDF.show()&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;    +-------------------+-----+---------+
    |               time|value|value_sum|
    +-------------------+-----+---------+
    |1970-01-01 00:00:01|    1|      1.0|
    |1970-01-01 00:00:02|    4|      5.0|
    |1970-01-01 00:00:03|    9|     14.0|
    |1970-01-01 00:00:04|   16|     29.0|
    +-------------------+-----+---------+&lt;/code&gt;&lt;/pre&gt;
&lt;div class="line-block"&gt;     In other words, given a timestamp &lt;code&gt;t&lt;/code&gt; and a row in the result having &lt;code&gt;time&lt;/code&gt; equal to &lt;code&gt;t&lt;/code&gt;, one can notice the &lt;code&gt;value_sum&lt;/code&gt; column of that row contains sum of &lt;code&gt;value&lt;/code&gt;s within the time window of &lt;code&gt;[t - 2, t]&lt;/code&gt; from &lt;code&gt;ts_rdd&lt;/code&gt;.&lt;/div&gt;
&lt;h1 id="intro-to-sparklyr.flint"&gt;Intro to &lt;code&gt;sparklyr.flint&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The purpose of &lt;code&gt;sparklyr.flint&lt;/code&gt; is to make time-series functionalities of &lt;code&gt;Flint&lt;/code&gt; easily accessible from &lt;code&gt;sparklyr&lt;/code&gt;. To see &lt;code&gt;sparklyr.flint&lt;/code&gt; in action, one can skim through the example in the previous section, go through the following to produce the exact R-equivalent of each step in that example, and then obtain the same summarization as the final result:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First of all, install &lt;code&gt;sparklyr&lt;/code&gt; and &lt;code&gt;sparklyr.flint&lt;/code&gt; if you haven’t done so already.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;install.packages(&amp;quot;sparklyr&amp;quot;)
install.packages(&amp;quot;sparklyr.flint&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Connect to Apache Spark that is running locally from &lt;code&gt;sparklyr&lt;/code&gt;, but remember to attach &lt;code&gt;sparklyr.flint&lt;/code&gt; before running &lt;code&gt;sparklyr::spark_connect&lt;/code&gt;, and then import our example time-series data to Spark:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(sparklyr)
library(sparklyr.flint)

sc &amp;lt;- spark_connect(master = &amp;quot;local&amp;quot;, version = &amp;quot;2.4&amp;quot;)
sdf &amp;lt;- copy_to(sc, data.frame(time = seq(4), value = seq(4)^2))&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Convert &lt;code&gt;sdf&lt;/code&gt; above into a &lt;code&gt;TimeSeriesRDD&lt;/code&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ts_rdd &amp;lt;- fromSDF(sdf, is_sorted = TRUE, time_unit = &amp;quot;SECONDS&amp;quot;, time_column = &amp;quot;time&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;And finally, run the ‘sum’ summarizer to obtain a summation of &lt;code&gt;value&lt;/code&gt;s in all past-2-second time windows:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;result &amp;lt;- summarize_sum(ts_rdd, column = &amp;quot;value&amp;quot;, window = in_past(&amp;quot;2s&amp;quot;))

print(result %&amp;gt;% collect())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;## # A tibble: 4 x 3
##   time                value value_sum
##   &amp;lt;dttm&amp;gt;              &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 1970-01-01 00:00:01     1         1
## 2 1970-01-01 00:00:02     4         5
## 3 1970-01-01 00:00:03     9        14
## 4 1970-01-01 00:00:04    16        29&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="why-create-a-sparklyr-extension"&gt;Why create a &lt;code&gt;sparklyr&lt;/code&gt; extension?&lt;/h1&gt;
&lt;p&gt;The alternative to making &lt;code&gt;sparklyr.flint&lt;/code&gt; a &lt;code&gt;sparklyr&lt;/code&gt; extension is to bundle all time-series functionalities it provides with &lt;code&gt;sparklyr&lt;/code&gt; itself. We decided that this would not be a good idea because of the following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not all &lt;code&gt;sparklyr&lt;/code&gt; users will need those time-series functionalities&lt;/li&gt;
&lt;li&gt;&lt;code&gt;com.twosigma:flint:0.6.0&lt;/code&gt; and all Maven packages it transitively relies on are quite heavy dependency-wise&lt;/li&gt;
&lt;li&gt;Implementing an intuitive R interface for &lt;code&gt;Flint&lt;/code&gt; also takes a non-trivial number of R source files, and making all of that part of &lt;code&gt;sparklyr&lt;/code&gt; itself would be too much&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, considering all of the above, building &lt;code&gt;sparklyr.flint&lt;/code&gt; as an extension of &lt;code&gt;sparklyr&lt;/code&gt; seems to be a much more reasonable choice.&lt;/p&gt;
&lt;h1 id="current-state-of-sparklyr.flint-and-its-future-directions"&gt;Current state of &lt;code&gt;sparklyr.flint&lt;/code&gt; and its future directions&lt;/h1&gt;
&lt;p&gt;Recently &lt;code&gt;sparklyr.flint&lt;/code&gt; has had its first successful release on CRAN. At the moment, &lt;code&gt;sparklyr.flint&lt;/code&gt; only supports the &lt;code&gt;summarizeCycle&lt;/code&gt; and &lt;code&gt;summarizeWindow&lt;/code&gt; functionalities of &lt;code&gt;Flint&lt;/code&gt;, and does not yet support asof join and other useful time-series operations. While &lt;code&gt;sparklyr.flint&lt;/code&gt; contains R interfaces to most of the summarizers in &lt;code&gt;Flint&lt;/code&gt; (one can find the list of summarizers currently supported by &lt;code&gt;sparklyr.flint&lt;/code&gt; in &lt;a href="https://cran.r-project.org/web/packages/sparklyr.flint/sparklyr.flint.pdf"&gt;here&lt;/a&gt;), there are still a few of them missing (e.g., the support for &lt;code&gt;OLSRegressionSummarizer&lt;/code&gt;, among others).&lt;/p&gt;
&lt;p&gt;In general, the goal of building &lt;code&gt;sparklyr.flint&lt;/code&gt; is for it to be a thin “translation layer” between &lt;code&gt;sparklyr&lt;/code&gt; and &lt;code&gt;Flint&lt;/code&gt;. It should be as simple and intuitive as possibly can be, while supporting a rich set of &lt;code&gt;Flint&lt;/code&gt; time-series functionalities.&lt;/p&gt;
&lt;p&gt;We cordially welcome any open-source contribution towards &lt;code&gt;sparklyr.flint&lt;/code&gt;. Please visit &lt;a href="https://github.com/r-spark/sparklyr.flint/issues" class="uri"&gt;https://github.com/r-spark/sparklyr.flint/issues&lt;/a&gt; if you would like to initiate discussions, report bugs, or propose new features related to &lt;code&gt;sparklyr.flint&lt;/code&gt;, and &lt;a href="https://github.com/r-spark/sparklyr.flint/pulls" class="uri"&gt;https://github.com/r-spark/sparklyr.flint/pulls&lt;/a&gt; if you would like to send pull requests.&lt;/p&gt;
&lt;h1 id="acknowledgement"&gt;Acknowledgement&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First and foremost, the author wishes to thank Javier (&lt;a href="https://github.com/javierluraschi"&gt;@javierluraschi&lt;/a&gt;) for proposing the idea of creating &lt;code&gt;sparklyr.flint&lt;/code&gt; as the R interface for &lt;code&gt;Flint&lt;/code&gt;, and for his guidance on how to build it as an extension to &lt;code&gt;sparklyr&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Both Javier (&lt;a href="https://github.com/javierluraschi"&gt;@javierluraschi&lt;/a&gt;) and Daniel (&lt;a href="https://github.com/dfalbel"&gt;@dfalbel&lt;/a&gt;) have offered numerous helpful tips on making the initial submission of &lt;code&gt;sparklyr.flint&lt;/code&gt; to CRAN successful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We really appreciate the enthusiasm from &lt;code&gt;sparklyr&lt;/code&gt; users who were willing to give &lt;code&gt;sparklyr.flint&lt;/code&gt; a try shortly after it was released on CRAN (and there were quite a few downloads of &lt;code&gt;sparklyr.flint&lt;/code&gt; in the past week according to CRAN stats, which was quite encouraging for us to see). We hope you enjoy using &lt;code&gt;sparklyr.flint&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The author is also grateful for valuable editorial suggestions from Mara (&lt;a href="https://github.com/batpigandme"&gt;@batpigandme&lt;/a&gt;), Sigrid (&lt;a href="https://github.com/skeydan"&gt;@skeydan&lt;/a&gt;), and Javier (&lt;a href="https://github.com/javierluraschi"&gt;@javierluraschi&lt;/a&gt;) on this blog post.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>e6f4df01ae92eb2c9d4837fa81a92b15</distill:md5>
      <category>R</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-09-07-sparklyr-flint</guid>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-09-07-sparklyr-flint/images/thumb.png" medium="image" type="image/png" width="126" height="77"/>
    </item>
    <item>
      <title>An introduction to weather forecasting with deep learning</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction</link>
      <description>A few weeks ago, we showed how to forecast chaotic dynamical systems with deep learning, augmented by a custom constraint derived from domain-specific insight. Global weather is a chaotic system, but of much higher complexity than many tasks commonly addressed with machine and/or deep learning. In this post, we provide a practical introduction featuring a simple deep learning baseline for atmospheric forecasting. While far away from being competitive, it serves to illustrate how more sophisticated and compute-intensive models may approach that formidable task by means of methods situated on the "black-box end" of the continuum.</description>
      <category>R</category>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction</guid>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-09-01-weather-prediction/images/thumb.png" medium="image" type="image/png" width="1667" height="923"/>
    </item>
    <item>
      <title>Training ImageNet with R</title>
      <dc:creator>Javier Luraschi</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-08-24-training-imagenet-with-r</link>
      <description>This post explores how to train large datasets with TensorFlow and R. Specifically, we present how to download and repartition ImageNet, followed by training ImageNet across multiple GPUs in distributed environments using TensorFlow and Apache Spark.</description>
      <category>R</category>
      <category>TensorFlow/Keras</category>
      <category>Distributed Computing</category>
      <category>Data Management</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-08-24-training-imagenet-with-r</guid>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-08-24-training-imagenet-with-r/images/fishing-net.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Deepfake detection challenge from R</title>
      <dc:creator>Turgut Abdullayev</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-08-18-deepfake</link>
      <description>A couple of months ago, Amazon, Facebook, Microsoft, and other contributors initiated a challenge consisting of telling apart real and AI-generated ("fake") videos. We show how to approach this challenge from R.</description>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-08-18-deepfake</guid>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-08-18-deepfake/files/frame_2.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>FNN-VAE for noisy time series forecasting</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-07-31-fnn-vae-for-noisy-timeseries</link>
      <description>In the last part of this mini-series on forecasting with false nearest neighbors (FNN) loss, we replace the LSTM autoencoder from the previous post by a convolutional VAE, resulting in equivalent prediction performance but significantly lower training time. In addition, we find that FNN regularization is of great help when an underlying deterministic process is obscured by substantial noise.</description>
      <category>R</category>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-07-31-fnn-vae-for-noisy-timeseries</guid>
      <pubDate>Fri, 31 Jul 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-07-31-fnn-vae-for-noisy-timeseries/images/kb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>State-of-the-art NLP models from R</title>
      <dc:creator>Turgut Abdullayev</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-07-30-state-of-the-art-nlp-models-from-r</link>
      <description>Nowadays, Microsoft, Google, Facebook, and OpenAI are sharing lots of state-of-the-art models in the field of Natural Language Processing. However, fewer materials exist how to use these models from R. In this post, we will show how R users can access and benefit from these models as well.</description>
      <category>Natural Language Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-07-30-state-of-the-art-nlp-models-from-r</guid>
      <pubDate>Thu, 30 Jul 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-07-30-state-of-the-art-nlp-models-from-r/files/dino.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Parallelized sampling using exponential variates</title>
      <dc:creator>Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-07-29-parallelized-sampling</link>
      <description>How can the seemingly iterative process of weighted sampling without replacement be transformed into something highly parallelizable? Turns out a well-known technique based on exponential variates accomplishes exactly that.</description>
      <category>Concepts</category>
      <category>Distributed Computing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-07-29-parallelized-sampling</guid>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-07-29-parallelized-sampling/images/dice.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Time series prediction with FNN-LSTM</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm</link>
      <description>In a recent post, we showed how an LSTM autoencoder, regularized by false nearest neighbors (FNN) loss, can be used to reconstruct the attractor of a nonlinear, chaotic dynamical system. Here, we explore how that same technique assists in prediction. Matched up with a comparable, capacity-wise, "vanilla LSTM", FNN-LSTM improves performance on a set of very different, real-world datasets, especially for the initial steps in a multi-step forecast.</description>
      <category>R</category>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm</guid>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-07-20-fnn-lstm/images/old_faithful.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>sparklyr 1.3: Higher-order Functions, Avro and Custom Serializers</title>
      <dc:creator>Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-07-16-sparklyr-1.3.0-released</link>
      <description>Sparklyr 1.3 is now available, featuring exciting new functionalities such as integration of Spark higher-order functions and data import/export in Avro and in user-defined serialization formats.</description>
      <category>Packages/Releases</category>
      <category>Distributed Computing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-07-16-sparklyr-1.3.0-released</guid>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-07-16-sparklyr-1.3.0-released/images/sparklyr-1.3.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Deep attractors: Where deep learning meets chaos</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors</link>
      <description>In nonlinear dynamics, when the state space is thought to be multidimensional but all we have for data is just a univariate time series, one may attempt to reconstruct the true space via delay coordinate embeddings. However, it is not clear a priori how to choose dimensionality and time lag of the reconstruction space. In this post, we show how to use an autoencoder architecture to circumvent the problem: Given just a scalar series of observations, the autoencoder directly learns to represent attractors of chaotic systems in adequate dimensionality.</description>
      <category>R</category>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors</guid>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-06-24-deep-attractors/images/x_z.gif" medium="image" type="image/gif"/>
    </item>
    <item>
      <title>Easy PixelCNN with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-05-29-pixelcnn</link>
      <description>PixelCNN is a deep learning architecture - or bundle of architectures - designed to generate highly realistic-looking images. To use it, no reverse-engineering of arXiv papers or search for reference implementations is required: TensorFlow Probability and its R wrapper, tfprobability, now include a PixelCNN distribution that can be used to train a straightforwardly-defined neural network in a parameterizable way.</description>
      <category>R</category>
      <category>Image Recognition &amp; Image Processing</category>
      <category>TensorFlow/Keras</category>
      <category>Probabilistic ML/DL</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-05-29-pixelcnn</guid>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-05-29-pixelcnn/images/thumb.png" medium="image" type="image/png" width="400" height="203"/>
    </item>
    <item>
      <title>Hacking deep learning: model inversion attack by example</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-05-15-model-inversion-attacks</link>
      <description>Compared to other applications, deep learning models might not seem too likely as victims of privacy attacks. However, methods exist to determine whether an entity was used in the training set (an adversarial attack called member inference), and techniques subsumed under "model inversion" allow to reconstruct raw data input given just model output (and sometimes, context information). This post shows an end-to-end example of model inversion, and explores mitigation strategies using TensorFlow Privacy.</description>
      <category>R</category>
      <category>Privacy &amp; Security</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-05-15-model-inversion-attacks</guid>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-05-15-model-inversion-attacks/images/results.png" medium="image" type="image/png" width="600" height="394"/>
    </item>
    <item>
      <title>Towards privacy: Encrypted deep learning with Syft and Keras</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-29-encrypted_keras_with_syft</link>
      <description>Deep learning need not be irreconcilable with privacy protection. Federated learning enables on-device, distributed model training; encryption keeps model and gradient updates private; differential privacy prevents the training data from leaking. As of today, private and secure deep learning is an emerging technology. In this post, we introduce Syft, an open-source framework that integrates with PyTorch as well as TensorFlow. In an example use case, we obtain private predictions from a Keras model.</description>
      <category>R</category>
      <category>Privacy &amp; Security</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-29-encrypted_keras_with_syft</guid>
      <pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-04-29-encrypted_keras_with_syft/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>sparklyr 1.2: Foreach, Spark 3.0 and Databricks Connect</title>
      <dc:creator>Yitao Li</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-21-sparklyr-1.2.0-released</link>
      <description>A new sparklyr release is now available. This sparklyr 1.2 release features new functionalities such as support for Databricks Connect, a Spark backend for the 'foreach' package, inter-op improvements for working with Spark 3.0 preview, as well as a number of bug fixes and improvements addressing user-visible pain points.</description>
      <category>R</category>
      <category>Packages/Releases</category>
      <category>Distributed Computing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-21-sparklyr-1.2.0-released</guid>
      <pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-04-21-sparklyr-1.2.0-released/images/sparklyr.png" medium="image" type="image/png" width="1241" height="307"/>
    </item>
    <item>
      <title>pins 0.4: Versioning</title>
      <dc:creator>Javier Luraschi</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-13-pins-04</link>
      <description>A new release of pins is available on CRAN today. This release adds support to time travel across dataset versions, which improves collaboration and protects your code from breaking when remote resources change unexpectedly.</description>
      <category>R</category>
      <category>Packages/Releases</category>
      <category>Data Management</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-13-pins-04</guid>
      <pubDate>Mon, 13 Apr 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-04-13-pins-04/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>A first look at federated learning with TensorFlow</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-08-tf-federated-intro</link>
      <description>The term "federated learning" was coined to describe a form of distributed model training where the data remains on client devices, i.e., is never shipped to the coordinating server. In this post, we introduce central concepts and run first experiments with TensorFlow Federated, using R.</description>
      <category>Privacy &amp; Security</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-08-tf-federated-intro</guid>
      <pubDate>Wed, 08 Apr 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-04-08-tf-federated-intro/images/federated_learning.png" medium="image" type="image/png" width="1122" height="570"/>
    </item>
    <item>
      <title>Introducing: The RStudio AI Blog</title>
      <dc:creator>The Multiverse Team</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-04-01-rstudio-ai-blog</link>
      <description>This blog just got a new title: RStudio AI Blog. We explain why.</description>
      <category>Meta</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-04-01-rstudio-ai-blog</guid>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-04-01-rstudio-ai-blog/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Infinite surprise - the iridescent personality of Kullback-Leibler divergence</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-02-19-kl-divergence</link>
      <description>Kullback-Leibler divergence is not just used to train variational autoencoders or Bayesian networks (and not just a hard-to-pronounce thing). It is a fundamental concept in information theory, put to use in a vast range of applications. Most interestingly, it's not always about constraint, regularization or compression. Quite on the contrary, sometimes it is about novelty, discovery and surprise.</description>
      <category>Probabilistic ML/DL</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-02-19-kl-divergence</guid>
      <pubDate>Wed, 19 Feb 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-02-19-kl-divergence/images/ultimatemachine.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>NumPy-style broadcasting for R TensorFlow users</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-01-24-numpy-broadcasting</link>
      <description>Broadcasting, as done by Python's scientific computing library NumPy, involves dynamically extending shapes so that arrays of different sizes may be passed to operations that expect conformity - such as adding or multiplying elementwise. In NumPy, the way broadcasting works is specified exactly; the same rules apply to TensorFlow operations. For anyone who finds herself, occasionally, consulting Python code, this post strives to explain.</description>
      <category>TensorFlow/Keras</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-01-24-numpy-broadcasting</guid>
      <pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-01-24-numpy-broadcasting/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>First experiments with TensorFlow mixed-precision training</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2020-01-13-mixed-precision-training</link>
      <description>TensorFlow 2.1, released last week, allows for mixed-precision training, making use of the Tensor Cores available in the most recent NVidia GPUs. In this post, we report first experimental results and provide some background on what this is all about.</description>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2020-01-13-mixed-precision-training</guid>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2020-01-13-mixed-precision-training/images/tc.png" medium="image" type="image/png" width="589" height="399"/>
    </item>
    <item>
      <title>Differential Privacy with TensorFlow</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-12-20-differential-privacy</link>
      <description>Differential Privacy guarantees that results of a database query are basically independent of the presence in the data of a single individual. Applied to machine learning, we expect that no single training example influences the parameters of the trained model in a substantial way. This post introduces TensorFlow Privacy, a library built on top of TensorFlow, that can be used to train differentially private deep learning models from R.</description>
      <category>Privacy &amp; Security</category>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-12-20-differential-privacy</guid>
      <pubDate>Fri, 20 Dec 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-12-20-differential-privacy/images/cat.png" medium="image" type="image/png" width="400" height="251"/>
    </item>
    <item>
      <title>tfhub: R interface to TensorFlow Hub</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-12-18-tfhub-0.7.0</link>
      <description>TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-12-18-tfhub-0.7.0</guid>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-12-18-tfhub-0.7.0/images/tfhub.png" medium="image" type="image/png" width="1365" height="909"/>
    </item>
    <item>
      <title>Gaussian Process Regression with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-12-10-variational-gaussian-process</link>
      <description>Continuing our tour of applications of TensorFlow Probability (TFP), after Bayesian Neural Networks, Hamiltonian Monte Carlo and State Space Models, here we show an example of Gaussian Process Regression. In fact, what we see is a rather "normal" Keras network, defined and trained in pretty much the usual way, with TFP's Variational Gaussian Process layer pulling off all the magic.</description>
      <category>Probabilistic ML/DL</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-12-10-variational-gaussian-process</guid>
      <pubDate>Tue, 10 Dec 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-12-10-variational-gaussian-process/images/kernel_cookbook.png" medium="image" type="image/png" width="818" height="352"/>
    </item>
    <item>
      <title>Getting started with Keras from R - the 2020 edition</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-11-27-gettingstarted-2020</link>
      <description>Looking for materials to get started with deep learning from R? This post presents useful tutorials, guides, and background documentation on the new TensorFlow for R website.  Advanced users will find pointers to applications of new release 2.0 (or upcoming 2.1!) features alluded to in the recent TensorFlow 2.0 post.</description>
      <category>Packages/Releases</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-11-27-gettingstarted-2020</guid>
      <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-11-27-gettingstarted-2020/images/website.png" medium="image" type="image/png" width="1591" height="725"/>
    </item>
    <item>
      <title>Variational convnets with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-11-13-variational-convnet</link>
      <description>In a Bayesian neural network, layer weights are distributions, not tensors. Using tfprobability, the R wrapper to TensorFlow Probability, we can build regular Keras models that have probabilistic layers, and thus get uncertainty estimates "for free". In this post, we show how to define, train and obtain predictions from a probabilistic convolutional neural network.</description>
      <category>Probabilistic ML/DL</category>
      <category>Time Series</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-11-13-variational-convnet</guid>
      <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-11-13-variational-convnet/images/bbb.png" medium="image" type="image/png" width="796" height="378"/>
    </item>
    <item>
      <title>tfprobability 0.8 on CRAN: Now how can you use it?</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-11-07-tfp-cran</link>
      <description>Part of the r-tensorflow ecosystem, tfprobability is an R wrapper to TensorFlow Probability, the Python probabilistic programming framework developed by Google. We take the occasion of tfprobability's acceptance on CRAN to give a high-level introduction, highlighting interesting use cases and applications.</description>
      <category>Probabilistic ML/DL</category>
      <category>Packages/Releases</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-11-07-tfp-cran</guid>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-11-07-tfp-cran/images/tfprobability.png" medium="image" type="image/png" width="518" height="600"/>
    </item>
    <item>
      <title>Innocent unicorns considered harmful? How to experiment with GPT-2 from R</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <dc:creator>Javier Luraschi</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-10-23-gpt-2</link>
      <description>Is society ready to deal with challenges brought about by artificially-generated  information - fake images, fake videos, fake text? While this post won't answer that question, it should help form an opinion on the threat exerted by fake text as of this writing, autumn 2019.  We introduce gpt2, an R package that wraps OpenAI's public implementation of GPT-2, the language model that early this year surprised the NLP community with the unprecedented quality of its creations.</description>
      <category>Natural Language Processing</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-10-23-gpt-2</guid>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-10-23-gpt-2/images/thumb.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>TensorFlow 2.0 is here - what changes for R users?</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges</link>
      <description>TensorFlow 2.0 was finally released last week. As R users we have two kinds of questions. First, will my keras code still run? And second, what is it that changes? In this post, we answer both and, then, give a tour of exciting new developments in the r-tensorflow ecosystem.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges</guid>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-10-08-tf2-whatchanges/images/thumb.png" medium="image" type="image/png" width="400" height="400"/>
    </item>
    <item>
      <title>On leapfrogs, crashing satellites, and going nuts: A very first conceptual introduction to Hamiltonian Monte Carlo</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-10-03-intro-to-hmc</link>
      <description>TensorFlow Probability, and its R wrapper tfprobability, provide Markov Chain Monte Carlo (MCMC) methods that were used in a number of recent posts on this blog. These posts were directed to users already comfortable with the method, and terminology, per se, which readers mainly interested in deep learning won't necessarily be. Here we try to make up leeway, introducing Hamitonian Monte Carlo (HMC) as well as a few often-heard "buzzwords" accompanying it, always striving to keep in mind what it is all "for".</description>
      <category>Bayesian Modeling</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-10-03-intro-to-hmc</guid>
      <pubDate>Thu, 03 Oct 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-10-03-intro-to-hmc/images/mb.png" medium="image" type="image/png" width="548" height="345"/>
    </item>
    <item>
      <title>BERT from R</title>
      <dc:creator>Turgut Abdullayev</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r</link>
      <description>A deep learning model - BERT from Google AI Research - has yielded state-of-the-art results in a wide variety of Natural Language Processing (NLP) tasks. In this tutorial, we will show how to load and train the BERT model from R, using Keras.</description>
      <category>Natural Language Processing</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r</guid>
      <pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-09-30-bert-r/images/bert.png" medium="image" type="image/png" width="437" height="367"/>
    </item>
    <item>
      <title>So, how come we can use TensorFlow from R?</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-08-29-using-tf-from-r</link>
      <description>Have you ever wondered why you can call TensorFlow - mostly known as a Python framework - from R? If not - that's how it should be, as the R packages keras and tensorflow aim to make this process as transparent as possible to the user. But for them to be those helpful genies, someone else first has to tame the Python.</description>
      <category>TensorFlow/Keras</category>
      <category>Meta</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-08-29-using-tf-from-r</guid>
      <pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-08-29-using-tf-from-r/images/thumb.png" medium="image" type="image/png" width="739" height="516"/>
    </item>
    <item>
      <title>Image segmentation with U-Net</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-08-23-unet</link>
      <description>In image segmentation, every pixel of an image is assigned a class. Depending on the application, classes could be different cell types; or the task could be binary, as in "cancer cell yes or no?". Area of application notwithstanding, the established neural network architecture of choice is U-Net. In this post, we show how to preprocess data and train a U-Net model on the Kaggle Carvana image segmentation data.</description>
      <category>Image Recognition &amp; Image Processing</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-08-23-unet</guid>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-08-23-unet/images/unet.png" medium="image" type="image/png" width="1400" height="932"/>
    </item>
    <item>
      <title>Modeling censored data with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-07-31-censored-data</link>
      <description>In this post we use tfprobability, the R interface to TensorFlow Probability, to model censored data. Again, the exposition is inspired by the treatment of this topic in Richard McElreath's Statistical Rethinking. Instead of cute cats though, we model immaterial entities from the cold world of technology: This post explores durations of CRAN package checks, a dataset that comes with Max Kuhn's parsnip.</description>
      <category>Bayesian Modeling</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-07-31-censored-data</guid>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-07-31-censored-data/images/thumb_cropped.png" medium="image" type="image/png" width="955" height="396"/>
    </item>
    <item>
      <title>TensorFlow feature columns: Transforming your data recipes-style</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-07-09-feature-columns</link>
      <description>TensorFlow feature columns provide useful functionality for preprocessing categorical data and chaining transformations, like bucketization or feature crossing. From R, we use them in popular "recipes" style, creating and subsequently refining a feature specification. In this post, we show how using feature specs frees cognitive resources and lets you focus on what you really want to accomplish. What's more, because of its elegance, feature-spec code reads nice and is fun to write as well.</description>
      <category>TensorFlow/Keras</category>
      <category>Tabular Data</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-07-09-feature-columns</guid>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-07-09-feature-columns/images/feature_cols_hier.png" medium="image" type="image/png" width="1172" height="678"/>
    </item>
    <item>
      <title>Dynamic linear models with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-06-25-dynamic_linear_models_tfprobability</link>
      <description>Previous posts featuring tfprobability - the R interface to TensorFlow Probability - have focused on enhancements to deep neural networks (e.g., introducing Bayesian uncertainty estimates) and fitting hierarchical models with Hamiltonian Monte Carlo. This time, we show how to fit time series using dynamic linear models (DLMs), yielding posterior predictive forecasts as well as the smoothed and filtered estimates from the Kálmán filter.</description>
      <category>Probabilistic ML/DL</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-06-25-dynamic_linear_models_tfprobability</guid>
      <pubDate>Mon, 24 Jun 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-06-25-dynamic_linear_models_tfprobability/images/thumb.png" medium="image" type="image/png" width="2012" height="1065"/>
    </item>
    <item>
      <title>Adding uncertainty estimates to Keras models with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-06-05-uncertainty-estimates-tfprobability</link>
      <description>As of today, there is no mainstream road to obtaining uncertainty estimates from neural networks. All that can be said is that, normally, approaches tend to be Bayesian in spirit, involving some way of putting a prior over model weights. This holds true as well for the method presented in this post: We show how to use tfprobability, the R interface to TensorFlow Probability, to add uncertainty estimates to a Keras model in an elegant and conceptually plausible way.</description>
      <category>Probabilistic ML/DL</category>
      <category>TensorFlow/Keras</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-06-05-uncertainty-estimates-tfprobability</guid>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-06-05-uncertainty-estimates-tfprobability/images/uci_both.png" medium="image" type="image/png" width="2020" height="1020"/>
    </item>
    <item>
      <title>Hierarchical partial pooling, continued: Varying slopes models with TensorFlow Probability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-05-24-varying-slopes</link>
      <description>This post builds on our recent introduction to multi-level modeling with tfprobability, the R wrapper to TensorFlow Probability. We show how to pool not just mean values ("intercepts"), but also relationships ("slopes"), thus enabling models to learn from data in an even broader way. Again, we use an example from Richard McElreath's "Statistical Rethinking"; the terminology as well as the way we present this topic are largely owed to this book.</description>
      <category>Bayesian Modeling</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-05-24-varying-slopes</guid>
      <pubDate>Fri, 24 May 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-05-24-varying-slopes/images/thumb.png" medium="image" type="image/png" width="509" height="249"/>
    </item>
    <item>
      <title>Tadpoles on TensorFlow: Hierarchical partial pooling with tfprobability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow</link>
      <description>This post is a first introduction to MCMC modeling with tfprobability, the R interface to TensorFlow Probability (TFP). Our example is a multi-level model describing tadpole mortality, which may be known to the reader from Richard McElreath's wonderful "Statistical Rethinking".</description>
      <category>Bayesian Modeling</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow</guid>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow/images/thumb.png" medium="image" type="image/png" width="1612" height="659"/>
    </item>
    <item>
      <title>Experimenting with autoregressive flows in TensorFlow Probability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-04-24-autoregressive-flows</link>
      <description>Continuing from the recent introduction to bijectors in TensorFlow Probability (TFP), this post brings autoregressivity to the table. Using TFP through the new R package tfprobability, we look at the implementation of masked autoregressive flows (MAF) and put them to use on two different datasets.</description>
      <category>Probabilistic ML/DL</category>
      <category>Unsupervised Learning</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-04-24-autoregressive-flows</guid>
      <pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-04-24-autoregressive-flows/images/made.png" medium="image" type="image/png" width="686" height="398"/>
    </item>
    <item>
      <title>Auto-Keras: Tuning-free deep learning from R</title>
      <dc:creator>Juan Cruz Rodriguez</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-04-16-autokeras</link>
      <description>Sometimes in deep learning, architecture design and hyperparameter tuning pose substantial challenges. Using Auto-Keras, none of these is needed: We start a search procedure and extract the best-performing model. This post presents Auto-Keras in action on the well-known MNIST dataset.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-04-16-autokeras</guid>
      <pubDate>Tue, 16 Apr 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-04-16-autokeras/images/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Getting into the flow: Bijectors in TensorFlow Probability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-04-05-bijectors-flows</link>
      <description>Normalizing flows are one of the lesser known, yet fascinating and successful architectures in unsupervised deep learning. In this post we provide a basic introduction to flows using tfprobability, an R wrapper to TensorFlow Probability. Upcoming posts will build on this, using more complex flows on more complex data.</description>
      <category>Probabilistic ML/DL</category>
      <category>TensorFlow/Keras</category>
      <category>Concepts</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-04-05-bijectors-flows</guid>
      <pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-04-05-bijectors-flows/images/flows.png" medium="image" type="image/png" width="904" height="325"/>
    </item>
    <item>
      <title>Math, code, concepts: A third road to deep learning</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-03-15-concepts-way-to-dl</link>
      <description>Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it's all about.</description>
      <category>Meta</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-03-15-concepts-way-to-dl</guid>
      <pubDate>Fri, 15 Mar 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-03-15-concepts-way-to-dl/images/prev.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Audio classification with Keras: Looking closer at the non-deep learning parts</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-02-07-audio-background</link>
      <description>Sometimes, deep learning is seen - and welcomed - as a way to avoid laborious preprocessing of data. However, there are cases where preprocessing of sorts does not only help improve prediction, but constitutes a fascinating topic in itself. One such case is audio classification. In this post, we build on a previous post on this blog, this time focusing on explaining some of the non-deep learning background. We then link the concepts explained to updated for near-future releases TensorFlow code.</description>
      <category>TensorFlow/Keras</category>
      <category>Concepts</category>
      <category>Audio Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-02-07-audio-background</guid>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-02-07-audio-background/images/seven2.png" medium="image" type="image/png" width="1714" height="846"/>
    </item>
    <item>
      <title>Discrete Representation Learning with VQ-VAE and TensorFlow Probability</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-01-24-vq-vae</link>
      <description>Mostly when thinking of Variational Autoencoders (VAEs), we picture the prior as an isotropic Gaussian. But this is by no means a necessity. The Vector Quantised Variational Autoencoder (VQ-VAE) described in van den Oord et al's "Neural Discrete Representation Learning" features a discrete latent space that allows to learn impressively concise latent representations. In this post, we combine elements of Keras, TensorFlow, and TensorFlow Probability to see if we can generate convincing letters resembling those in Kuzushiji-MNIST.</description>
      <category>TensorFlow/Keras</category>
      <category>Probabilistic ML/DL</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-01-24-vq-vae</guid>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-01-24-vq-vae/images/thumb1.png" medium="image" type="image/png" width="510" height="287"/>
    </item>
    <item>
      <title>Getting started with TensorFlow Probability from R</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2019-01-08-getting-started-with-tf-probability</link>
      <description>TensorFlow Probability offers a vast range of functionality ranging from distributions over probabilistic network layers to probabilistic inference. It works seamlessly with core TensorFlow and (TensorFlow) Keras. In this post, we provide a short introduction to the distributions layer and then, use it for sampling and calculating probabilities in a Variational Autoencoder.</description>
      <category>TensorFlow/Keras</category>
      <category>Probabilistic ML/DL</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2019-01-08-getting-started-with-tf-probability</guid>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2019-01-08-getting-started-with-tf-probability/images/thumb.png" medium="image" type="image/png" width="884" height="584"/>
    </item>
    <item>
      <title>Concepts in object detection</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-12-18-object-detection-concepts</link>
      <description>As shown in a previous post, naming and locating a single object in an image is a task that may be approached in a straightforward way. This is not the same with general object detection, though - naming and locating several objects at once, with no prior information about how many objects are supposed to be detected.
In this post, we explain the steps involved in coding a basic single-shot object detector: Not unlike SSD (Single-shot Multibox Detector), but simplified and designed not for best performance, but comprehensibility.</description>
      <category>TensorFlow/Keras</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-12-18-object-detection-concepts</guid>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-12-18-object-detection-concepts/images/results.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Entity embeddings for fun and profit</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-11-26-embeddings-fun-and-profit</link>
      <description>Embedding layers are not just useful when working with language data. As "entity embeddings", they've recently become famous for applications on tabular, small-scale data. In this post, we exemplify two possible use cases, also drawing attention to what not to expect.</description>
      <category>TensorFlow/Keras</category>
      <category>Tabular Data</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-11-26-embeddings-fun-and-profit</guid>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-11-26-embeddings-fun-and-profit/images/thumb.png" medium="image" type="image/png" width="820" height="410"/>
    </item>
    <item>
      <title>You sure? A Bayesian approach to obtaining uncertainty estimates from neural networks</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout</link>
      <description>In deep learning, there is no obvious way of obtaining uncertainty estimates. In 2016, Gal and Ghahramani proposed a method that is both theoretically grounded and practical: use dropout at test time. In this post, we introduce a refined version of this method (Gal et al. 2017) that has the network itself learn how uncertain it is.</description>
      <category>Image Recognition &amp; Image Processing</category>
      <category>Probabilistic ML/DL</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout</guid>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-11-12-uncertainty_estimates_dropout/images/thumb.png" medium="image" type="image/png" width="2046" height="872"/>
    </item>
    <item>
      <title>Naming and locating objects in images</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-11-05-naming-locating-objects</link>
      <description>Object detection (the act of classifying and localizing multiple objects in a scene) is one of the more difficult, but very relevant in practice deep learning tasks. We'll build up to it in several posts. Here we start with the simpler tasks of naming and locating a single object.</description>
      <category>TensorFlow/Keras</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-11-05-naming-locating-objects</guid>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-11-05-naming-locating-objects/images/preds_train.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Representation learning with MMD-VAE</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-10-22-mmd-vae</link>
      <description>Like GANs, variational autoencoders (VAEs) are often used to generate images. However, VAEs add an additional promise: namely, to model an underlying latent space. Here, we first look at a typical implementation that maximizes the evidence lower bound. Then, we compare it to one of the more recent competitors, MMD-VAE, from the Info-VAE (information maximizing VAE) family.</description>
      <category>TensorFlow/Keras</category>
      <category>Unsupervised Learning</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-10-22-mmd-vae</guid>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-10-22-mmd-vae/images/thumb.png" medium="image" type="image/png" width="468" height="178"/>
    </item>
    <item>
      <title>Winner takes all: A look at activations and cost functions</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-10-11-activations-intro</link>
      <description>Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post we provide a conceptual introduction.</description>
      <category>TensorFlow/Keras</category>
      <category>Concepts</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-10-11-activations-intro</guid>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-10-11-activations-intro/images/output.png" medium="image" type="image/png" width="800" height="384"/>
    </item>
    <item>
      <title>More flexible models with TensorFlow eager execution and Keras</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-10-02-eager-wrapup</link>
      <description>Advanced applications like generative adversarial networks, neural style transfer, and the attention mechanism ubiquitous in natural language processing used to be not-so-simple to implement with the Keras declarative coding paradigm. Now, with the advent of TensorFlow eager execution, things have changed. This post explores using eager execution with R.</description>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-10-02-eager-wrapup</guid>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-10-02-eager-wrapup/images/m.png" medium="image" type="image/png" width="384" height="126"/>
    </item>
    <item>
      <title>Collaborative filtering with embeddings</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-09-26-embeddings-recommender</link>
      <description>Embeddings are not just for use in natural language processing. Here we apply embeddings to a common task in collaborative filtering - predicting user ratings - and on our way, strive for a better understanding of what an embedding layer really does.</description>
      <category>TensorFlow/Keras</category>
      <category>Tabular Data</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-09-26-embeddings-recommender</guid>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-09-26-embeddings-recommender/images/m.png" medium="image" type="image/png" width="700" height="402"/>
    </item>
    <item>
      <title>Image-to-image translation with pix2pix</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-09-20-eager-pix2pix</link>
      <description>Conditional GANs (cGANs) may be used to generate one type of object based on another - e.g., a map based on a photo, or a color video based on black-and-white. Here, we show how to implement the pix2pix approach with Keras and eager execution.</description>
      <category>TensorFlow/Keras</category>
      <category>Image Recognition &amp; Image Processing</category>
      <category>Unsupervised Learning</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-09-20-eager-pix2pix</guid>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-09-20-eager-pix2pix/images/pix2pixlosses.png" medium="image" type="image/png" width="842" height="536"/>
    </item>
    <item>
      <title>Attention-based Image Captioning with Keras</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-09-17-eager-captioning</link>
      <description>Image captioning is a challenging task at intersection of vision and language. Here, we demonstrate using Keras and eager execution to incorporate an attention mechanism that allows the network to concentrate on image features relevant to the current state of text generation.</description>
      <category>Natural Language Processing</category>
      <category>TensorFlow/Keras</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-09-17-eager-captioning</guid>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-09-17-eager-captioning/images/showattendandtell.png" medium="image" type="image/png" width="627" height="269"/>
    </item>
    <item>
      <title>Neural style transfer with eager execution and Keras</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-09-10-eager-style-transfer</link>
      <description>Continuing our series on combining Keras with TensorFlow eager execution, we show how to implement neural style transfer in a straightforward way. Based on this easy-to-adapt example, you can easily perform style transfer on your own images.</description>
      <category>TensorFlow/Keras</category>
      <category>Unsupervised Learning</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-09-10-eager-style-transfer</guid>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-09-10-eager-style-transfer/images/preview.png" medium="image" type="image/png" width="344" height="231"/>
    </item>
    <item>
      <title>Getting started with deep learning in R</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-09-07-getting-started</link>
      <description>Many fields are benefiting from the use of deep learning, and with the R keras, tensorflow and related packages, you can now easily do state of the art deep learning in R. In this post, we want to give some orientation as to how to best get started.</description>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-09-07-getting-started</guid>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-09-07-getting-started/images/digits.png" medium="image" type="image/png" width="557" height="317"/>
    </item>
    <item>
      <title>Generating images with Keras and TensorFlow eager execution</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-08-26-eager-dcgan</link>
      <description>Generative adversarial networks (GANs) are a popular deep learning approach to generating new entities (often but not always images). We show how to code them using Keras and TensorFlow eager execution.</description>
      <category>TensorFlow/Keras</category>
      <category>Unsupervised Learning</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-08-26-eager-dcgan</guid>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-08-26-eager-dcgan/images/thumb.png" medium="image" type="image/png" width="240" height="144"/>
    </item>
    <item>
      <title>Attention-based Neural Machine Translation with Keras</title>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-07-30-attention-layer</link>
      <description>As sequence to sequence prediction tasks get more involved, attention mechanisms have proven helpful. A prominent example is neural machine translation. Following a recent Google Colaboratory notebook, we show how to implement attention in R.</description>
      <category>Natural Language Processing</category>
      <category>TensorFlow/Keras</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-07-30-attention-layer</guid>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-07-30-attention-layer/images/attention.png" medium="image" type="image/png" width="606" height="448"/>
    </item>
    <item>
      <title>Classifying physical activity from smartphone data</title>
      <dc:creator>Nick Strayer</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-07-17-activity-detection</link>
      <description>Using Keras to train a convolutional neural network to classify physical activity. The dataset was built from the recordings of 30 subjects performing basic activities and postural transitions while carrying a waist-mounted smartphone with embedded inertial sensors.</description>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-07-17-activity-detection</guid>
      <pubDate>Tue, 17 Jul 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-07-17-activity-detection/index_files/figure-html5/unnamed-chunk-8-1.png" medium="image" type="image/png" width="1152" height="768"/>
    </item>
    <item>
      <title>Predicting Sunspot Frequency with Keras</title>
      <dc:creator>Matt Dancho</dc:creator>
      <dc:creator>Sigrid Keydana</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-06-25-sunspots-lstm</link>
      <description>In this post we will examine making time series predictions using the sunspots dataset that ships with base R. Sunspots are dark spots on the sun, associated with lower temperature. Our post will focus on both how to apply deep learning to time series forecasting, and how to properly apply cross validation in this domain.</description>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-06-25-sunspots-lstm</guid>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-06-25-sunspots-lstm/images/backtested_test.png" medium="image" type="image/png" width="800" height="416"/>
    </item>
    <item>
      <title>Simple Audio Classification with Keras</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-06-06-simple-audio-classification-keras</link>
      <description>In this tutorial we will build a deep learning model to classify words. We will use the Speech Commands dataset which consists of 65,000 one-second audio files of people saying 30 different words.</description>
      <category>TensorFlow/Keras</category>
      <category>Audio Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-06-06-simple-audio-classification-keras</guid>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      <media:content url="https://upload.wikimedia.org/wikipedia/commons/6/61/FFT-Time-Frequency-View.png" medium="image" type="image/png"/>
    </item>
    <item>
      <title>GPU Workstations in the Cloud with Paperspace</title>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-04-02-rstudio-gpu-paperspace</link>
      <description>If you don't have local access to a modern NVIDIA GPU, your best bet is typically to run GPU intensive training jobs in the cloud. Paperspace is a cloud service that provides access to a fully preconfigured Ubuntu 16.04 desktop environment equipped with a GPU.</description>
      <category>Cloud</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-04-02-rstudio-gpu-paperspace</guid>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-04-02-rstudio-gpu-paperspace/images/paperspace-mnist-cnn.png" medium="image" type="image/png" width="2030" height="1338"/>
    </item>
    <item>
      <title>lime v0.4: The Kitten Picture Edition</title>
      <dc:creator>Thomas Lin Pedersen</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-03-09-lime-v04-the-kitten-picture-edition</link>
      <description>A new major release of lime has landed on CRAN. lime is an R port of the Python library of the same name by Marco Ribeiro that allows the user to pry open black box machine learning models and explain their outcomes on a per-observation basis</description>
      <category>Packages/Releases</category>
      <category>TensorFlow/Keras</category>
      <category>Explainability</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-03-09-lime-v04-the-kitten-picture-edition</guid>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-03-09-lime-v04-the-kitten-picture-edition/images/unnamed-chunk-8-1.png" medium="image" type="image/png" width="1344" height="672"/>
    </item>
    <item>
      <title>Deep Learning for Cancer Immunotherapy</title>
      <dc:creator>Leon Eyrich Jessen</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-29-dl-for-cancer-immunotherapy</link>
      <description>The aim of this post is to illustrate how deep learning is being applied in cancer immunotherapy (Immuno-oncology or Immunooncology) - a cancer treatment strategy, where the aim is to utilize the cancer patient's own immune system to fight the cancer.</description>
      <category>TensorFlow/Keras</category>
      <category>Tabular Data</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-29-dl-for-cancer-immunotherapy</guid>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-01-29-dl-for-cancer-immunotherapy/images/01_ffn_02_results_3_by_3_confusion_matrix.png" medium="image" type="image/png" width="3000" height="1800"/>
    </item>
    <item>
      <title>Predicting Fraud with Autoencoders and Keras</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder</link>
      <description>In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset.</description>
      <category>TensorFlow/Keras</category>
      <category>Unsupervised Learning</category>
      <category>Cloud</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder</guid>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/images/preview.png" medium="image" type="image/png" width="790" height="537"/>
    </item>
    <item>
      <title>Analyzing rtweet Data with kerasformula</title>
      <dc:creator>Pete Mohanty</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-24-analyzing-rtweet-data-with-kerasformula</link>
      <description>The kerasformula package offers a high-level interface for the R interface to Keras. It’s main interface is the kms function, a regression-style interface to keras_model_sequential that uses formulas and sparse matrices. We use kerasformula to predict how popular tweets will be based on how often the tweet was retweeted and favorited.</description>
      <category>TensorFlow/Keras</category>
      <category>Natural Language Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-24-analyzing-rtweet-data-with-kerasformula</guid>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-01-24-analyzing-rtweet-data-with-kerasformula/images/densities-1.png" medium="image" type="image/png" width="672" height="480"/>
    </item>
    <item>
      <title>Deep Learning With Keras To Predict Customer Churn</title>
      <dc:creator>Matt Dancho</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn</link>
      <description>Using Keras to predict customer churn based on the IBM Watson Telco Customer Churn dataset. We also demonstrate using the lime package to help explain which features drive individual model predictions. In addition, we use three new packages to assist with Machine Learning: recipes for preprocessing, rsample for sampling data and yardstick for model metrics.</description>
      <category>TensorFlow/Keras</category>
      <category>Tabular Data</category>
      <category>Explainability</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn</guid>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-01-11-keras-customer-churn/images/customer_churn_analysis_corrr.png" medium="image" type="image/png" width="2696" height="1696"/>
    </item>
    <item>
      <title>R Interface to Google CloudML</title>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-10-r-interface-to-cloudml</link>
      <description>We are excited to announce the availability of the cloudml package, which provides an R interface to Google Cloud Machine Learning Engine. CloudML provides a number of services including on-demand access to training on GPUs and hyperparameter tuning to optimize key attributes of model architectures.</description>
      <category>Cloud</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-10-r-interface-to-cloudml</guid>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-01-10-r-interface-to-cloudml/images/cloudml.png" medium="image" type="image/png" width="394" height="211"/>
    </item>
    <item>
      <title>Classifying Duplicate Questions from Quora with Keras</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2018-01-09-keras-duplicate-questions-quora</link>
      <description>In this post we will use Keras to classify duplicated questions from Quora. Our implementation is inspired by the Siamese Recurrent Architecture, with modifications to the similarity measure and the embedding layers (the original paper uses pre-trained word vectors)</description>
      <category>TensorFlow/Keras</category>
      <category>Natural Language Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2018-01-09-keras-duplicate-questions-quora</guid>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2018-01-09-keras-duplicate-questions-quora/keras-duplicate-questions-quora.png" medium="image" type="image/png" width="1302" height="788"/>
    </item>
    <item>
      <title>Word Embeddings with Keras</title>
      <dc:creator>Daniel Falbel</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-12-22-word-embeddings-with-keras</link>
      <description>Word embedding is a method used to map words of a vocabulary to dense vectors of real numbers where semantically similar words are mapped to nearby points. In this example we'll use Keras to generate word embeddings for the Amazon Fine Foods Reviews dataset.</description>
      <category>TensorFlow/Keras</category>
      <category>Natural Language Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-12-22-word-embeddings-with-keras</guid>
      <pubDate>Fri, 22 Dec 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-12-22-word-embeddings-with-keras/word-embeddings-with-keras.png" medium="image" type="image/png" width="700" height="450"/>
    </item>
    <item>
      <title>Time Series Forecasting with Recurrent Neural Networks</title>
      <dc:creator>François Chollet</dc:creator>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks</link>
      <description>In this post, we'll review three advanced techniques for improving the performance and generalization power of recurrent neural networks.  We'll demonstrate all three concepts on a temperature-forecasting problem, where you have access to a time series of data points coming from sensors installed on the roof of a building.</description>
      <category>TensorFlow/Keras</category>
      <category>Time Series</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks</guid>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/images/jena_temp-r.png" medium="image" type="image/png" width="6000" height="4000"/>
    </item>
    <item>
      <title>Image Classification on Small Datasets with Keras</title>
      <dc:creator>François Chollet</dc:creator>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-12-14-image-classification-on-small-datasets</link>
      <description>Having to train an image-classification model using very little data is a common situation, in this article we review three techniques for tackling this problem including feature extraction and fine tuning from a pretrained network.</description>
      <category>TensorFlow/Keras</category>
      <category>Image Recognition &amp; Image Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-12-14-image-classification-on-small-datasets</guid>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-12-14-image-classification-on-small-datasets/images/swapping_fc_classifier.png" medium="image" type="image/png" width="678" height="453"/>
    </item>
    <item>
      <title>Deep Learning for Text Classification with Keras</title>
      <dc:creator>François Chollet</dc:creator>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-12-07-text-classification-with-keras</link>
      <description>Two-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. In this excerpt from the book Deep Learning with R, you'll learn to classify movie reviews as positive or negative, based on the text content of the reviews.</description>
      <category>TensorFlow/Keras</category>
      <category>Natural Language Processing</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-12-07-text-classification-with-keras</guid>
      <pubDate>Thu, 07 Dec 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-12-07-text-classification-with-keras/images/training-history.png" medium="image" type="image/png" width="1400" height="865"/>
    </item>
    <item>
      <title>tfruns: Tools for TensorFlow Training Runs</title>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-10-04-tfruns</link>
      <description>The tfruns package provides a suite of tools for tracking, visualizing, and managing TensorFlow training runs and experiments from R.</description>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-10-04-tfruns</guid>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-10-04-tfruns/preview.png" medium="image" type="image/png" width="2006" height="1116"/>
    </item>
    <item>
      <title>Keras for R</title>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r</link>
      <description>We are excited to announce that the keras package is now available on CRAN. The package provides an R interface to Keras, a high-level neural networks API developed with a focus on enabling fast experimentation.</description>
      <category>TensorFlow/Keras</category>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r</guid>
      <pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-09-06-keras-for-r/preview.png" medium="image" type="image/png" width="669" height="414"/>
    </item>
    <item>
      <title>TensorFlow Estimators</title>
      <dc:creator>Yuan Tang</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-08-31-tensorflow-estimators-for-r</link>
      <description>The tfestimators package is an R interface to TensorFlow Estimators, a high-level API that provides implementations of many different model types including linear models and deep neural networks.</description>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-08-31-tensorflow-estimators-for-r</guid>
      <pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-08-31-tensorflow-estimators-for-r/tensorflow-architecture.png" medium="image" type="image/png" width="1198" height="796"/>
    </item>
    <item>
      <title>TensorFlow v1.3 Released</title>
      <dc:creator>J.J. Allaire</dc:creator>
      <link>https://blogs.rstudio.com/tensorflow/posts/2017-08-17-tensorflow-v13-released</link>
      <description>The final release of TensorFlow v1.3 is now available. This release marks the initial availability of several canned estimators including DNNClassifier and  DNNRegressor.</description>
      <category>Packages/Releases</category>
      <guid>https://blogs.rstudio.com/tensorflow/posts/2017-08-17-tensorflow-v13-released</guid>
      <pubDate>Thu, 17 Aug 2017 00:00:00 +0000</pubDate>
      <media:content url="https://blogs.rstudio.com/tensorflow/posts/2017-08-17-tensorflow-v13-released/tensorflow-logo.png" medium="image" type="image/png" width="3876" height="741"/>
    </item>
  </channel>
</rss>
