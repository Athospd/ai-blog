<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="radix" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>tbd</title>
  
  <meta property="description" itemprop="description" content="tbd"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2018-07-30"/>
  <meta property="article:created" itemprop="dateCreated" content="2018-07-30"/>
  <meta name="article:author" content="Sigrid Keydana"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="tbd"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="tbd"/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="tbd"/>
  <meta property="twitter:description" content="tbd"/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","preview","categories","output"]}},"value":[{"type":"character","attributes":{},"value":["tbd"]},{"type":"character","attributes":{},"value":["tbd\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["tbd"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["http://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["07-30-2018"]},{"type":"character","attributes":{},"value":["tbd"]},{"type":"character","attributes":{},"value":["Keras","TensorFlow","Eager execution","Machine translation"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["attention-layer_files/bowser-1.9.3/bowser.min.js","attention-layer_files/distill-2.2.21/template.v2.js","attention-layer_files/jquery-1.11.3/jquery.min.js","attention-layer_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#fn1>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.text();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.text(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        if ($.inArray(language, ["r", "cpp", "c", "java"]) != -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      $(this).find('img, .html-widget').css('width', '100%');
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.radix-site-header a').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="attention-layer_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="attention-layer_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="attention-layer_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="attention-layer_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"tbd","description":"tbd","authors":[{"author":"Sigrid Keydana","authorURL":"tbd","affiliation":"RStudio","affiliationURL":"http://www.rstudio.com/"}],"publishedDate":"2018-07-30T00:00:00.000+02:00","citationText":"Keydana, 2018"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>tbd</h1>
<p>tbd</p>
</div>

<div class="d-byline">
  Sigrid Keydana tbd (RStudio)<a href="http://www.rstudio.com/" class="uri">http://www.rstudio.com/</a>
  
<br/>07-30-2018
</div>

<div class="d-article">
<p>As of this writing, it is not difficult to find example code (be it in R or Python) showing how to perform sequence to sequence translation. However, it has been established quite some time ago (tbd footnote) that depending on the task, incorporating an attention mechanism significantly improves performance. Ideally, if we’re using Keras, we’d just have an attention layer handling this for us. Unfortunately, as can be seen googling for code snippets and blog posts, implementing attention in pure Keras is not that straightforward, the main reason being that we need to train the decoder in a loop, at each point feeding the training input as well as the output from the encoder.</p>
<p>Consequently, until a short time ago, the best thing to do seemed to be translating the <a href="https://github.com/tensorflow/nmt">TensorFlow Neural Machine Translation Tutorial</a> to R TensorFlow. Then, <a href="https://www.tensorflow.org/guide/eager">TensorFlow Eager Execution</a> happened, and turned out to be a game changer for a number of things that used to be difficult (last not least, debugging). With eager execution, operations are executed immediately, instead of building a graph to be evaluated later. This means we can immediately inspect the values in our tensors - and it also means we can imperatively code loops to perform interleavings of sorts that earlier were more intricate to accomplish.</p>
<p>Under these circumstances, it is not surprising that the <a href="https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb">interactive notebook on neural machine translation</a>, published on Colaboratory, got a lot of attention (if you allow me the pun) for its straightforward implementation and highly intellegible explanations. Our goal here is to do the same thing from R. We will not end up with Keras code exactly the way we used to write it, but a hybrid of Keras layers and imperative code enabled by TensorFlow eager execution.</p>
<h3 id="enable-eager-execution">Enable eager execution</h3>
<p>There are two things we have to do to get this to work. For one, we need to call <code>tfe_enable_eager_execution()</code> right at the beginning of the program. Secondly, we need to use the TensorFlow implementation of Keras, not the “Keras Keras” so to say. This is because at a later point, we are going to access <code>model$variables</code> which at this point does not exist in “Keras Keras”.</p>
<p>Still from the TensorFlow stack, we are going to use <a href="tbd">tfdatasets</a>. So we end up with the following libraries needed for this example:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(keras)
use_implementation(&quot;tensorflow&quot;)

library(tensorflow)
tfe_enable_eager_execution()

library(tfdatasets)

library(purrr)
library(stringr)
library(reshape2)
library(viridis)
library(ggplot2)
library(tibble)</code></pre>
</div>
<h3 id="prepare-the-data">Prepare the data</h3>
<p>As our focus is on implementing the attention mechanism, we’re going to do a quick pass through pre-preprocessing. All operations are contained in short functions that are independently testable (which also makes it easy should you want to experiment with different preprocessing actions).</p>
<p>The site <a href="http://www.manythings.org/anki/" class="uri">http://www.manythings.org/anki/</a> is a great source for multilingual datasets. For variation, we’ll choose a different dataset from the colab notebook, and try to translate English to Dutch. I’m going to assume you have the unzipped file <code>nld.txt</code> in a subdirectory called <code>data</code> in your current directory. The file contains 28224 sentence pairs, of which we are going to use the first 10000. Under this restriction, sentences range from one-word exclamations</p>
<pre><code>
Run!    Ren!
Wow!    Da&#39;s niet gek!
Fire!   Vuur!</code></pre>
<p>over short phrases</p>
<pre><code>
Are you crazy?  Ben je gek?
Do cats dream?  Dromen katten?
Feed the bird!  Geef de vogel voer!</code></pre>
<p>to simple sentences such as</p>
<pre><code>
My brother will kill me.    Mijn broer zal me vermoorden.
No one knows the future.    Niemand kent de toekomst.
Please ask someone else.    Vraag alsjeblieft iemand anders.</code></pre>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
filepath &lt;- file.path(&quot;data&quot;, &quot;nld.txt&quot;)

lines &lt;- readLines(filepath, n = 10000)
sentences &lt;- str_split(lines, &quot;\t&quot;)</code></pre>
</div>
<p>Basic preprocessing includes adding space before punctuation, replacing special characters, reducing multiple spaces to one, and adding <code>&lt;start&gt;</code> and <code>&lt;stop&gt;</code> tokens at the beginnings resp. ends of the sentences.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
space_before_punct &lt;- function(sentence) {
  str_replace_all(sentence, &quot;([?.!])&quot;, &quot; \\1&quot;)
}

replace_special_chars &lt;- function(sentence) {
  str_replace_all(sentence, &quot;[^a-zA-Z?.!,¿]+&quot;, &quot; &quot;)
}

add_tokens &lt;- function(sentence) {
  paste0(&quot;&lt;start&gt; &quot;, sentence, &quot; &lt;stop&gt;&quot;)
}
add_tokens &lt;- Vectorize(add_tokens, USE.NAMES = FALSE)

preprocess_sentence &lt;- compose(add_tokens,
                               str_squish,
                               replace_special_chars,
                               space_before_punct)

word_pairs &lt;- map(sentences, preprocess_sentence)</code></pre>
</div>
<p>As usual with text data, we need to create lookup indices to get from words to integers and vice versa: one index each for the source and target languages.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
create_index &lt;- function(sentences) {
  unique_words &lt;- sentences %&gt;% unlist() %&gt;% paste(collapse = &quot; &quot;) %&gt;%
    str_split(pattern = &quot; &quot;) %&gt;% .[[1]] %&gt;% unique() %&gt;% sort()
  index &lt;- data.frame(
    word = unique_words,
    index = 1:length(unique_words),
    stringsAsFactors = FALSE
  ) %&gt;%
    add_row(word = &quot;&lt;pad&gt;&quot;,
                    index = 0,
                    .before = 1)
  index
}

word2index &lt;- function(word, index_df) {
  index_df[index_df$word == word, &quot;index&quot;]
}
index2word &lt;- function(index, index_df) {
  index_df[index_df$index == index, &quot;word&quot;]
}

src_index &lt;- create_index(map(word_pairs, ~ .[[1]]))
target_index &lt;- create_index(map(word_pairs, ~ .[[2]]))</code></pre>
</div>
<p>Conversion of text to integers uses the above indices as well as Keras’ convenient <code>pad_sequences()</code> function, at the end of which we have matrices of integers containing the source and target sentences, padded up to maximum sentence length found in the source and target corpus, respectively.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
sentence2digits &lt;- function(sentence, index_df) {
  map((sentence %&gt;% str_split(pattern = &quot; &quot;))[[1]], function(word)
    word2index(word, index_df))
}

sentlist2diglist &lt;- function(sentence_list, index_df) {
  map(sentence_list, function(sentence)
    sentence2digits(sentence, index_df))
}

src_diglist &lt;-
  sentlist2diglist(map(word_pairs, ~ .[[1]]), src_index)
src_maxlen &lt;- map(src_diglist, length) %&gt;% unlist() %&gt;% max()
src_matrix &lt;-
  pad_sequences(src_diglist, maxlen = src_maxlen,  padding = &quot;post&quot;)

target_diglist &lt;-
  sentlist2diglist(map(word_pairs, ~ .[[2]]), target_index)
target_maxlen &lt;- map(target_diglist, length) %&gt;% unlist() %&gt;% max()
target_matrix &lt;-
  pad_sequences(target_diglist, maxlen = target_maxlen, padding = &quot;post&quot;)</code></pre>
</div>
<p>All that remains to be done is the train-test-split.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_indices &lt;-
  sample(nrow(src_matrix), size = nrow(src_matrix) * 0.8)

validation_indices &lt;- setdiff(1:nrow(src_matrix), train_indices)

x_train &lt;- src_matrix[train_indices, ]
y_train &lt;- target_matrix[train_indices, ]

x_valid &lt;- src_matrix[validation_indices, ]
y_valid &lt;- target_matrix[validation_indices, ]

buffer_size &lt;- nrow(x_train)

# just for convenience, so we may get a glimpse at translation performance already during training
train_sentences &lt;- sentences[train_indices]
validation_sentences &lt;- sentences[validation_indices]
validation_sample &lt;- sample(validation_sentences, 5)</code></pre>
</div>
<h3 id="create-the-datasets-to-iterate-over">Create the datasets to iterate over</h3>
<p>While this section does not contain much code quantity-wise, it contains an important technique: the use of datasets. Remember the olden times when we used to pass in hand-crafted generators to Keras models? With <a href="https://tensorflow.rstudio.com/tools/tfdatasets/articles/introduction.html#reading-datasets">tfdatasets</a>, we can scalably feed data directly to the Keras <code>fit</code> function, having various preparatory actions being performed directly in native code. In our case, we will not be using <code>fit</code> as you’ll see below, instead iterate directly over the tensors contained in the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
train_dataset &lt;- 
  tensor_slices_dataset(keras_array(list(x_train, y_train)))  %&gt;%
  dataset_shuffle(buffer_size = buffer_size) %&gt;%
  dataset_batch(batch_size, drop_remainder = TRUE)

validation_dataset &lt;-
  tensor_slices_dataset(keras_array(list(x_valid, y_valid))) %&gt;%
  dataset_shuffle(buffer_size = buffer_size) %&gt;%
  dataset_batch(batch_size, drop_remainder = TRUE)</code></pre>
</div>
<p>Now we are ready to roll! In fact, before talking about that training loop we need to dive into the implementation of the core logic: the custom layers responsible to perform the attention operation.</p>
<h3 id="attention-encoder">Attention encoder</h3>
<p>We will create two custom layers, only the second of which is going to incorporate attention logic.</p>
<p>However, it’s worth introducing the encoder in detail too, because technically this is not a custom layer but a custom model, as described in the <a href="https://github.com/rstudio/keras/blob/master/vignettes/custom_models.Rmd">corresponding vignette</a>.</p>
<p>Custom models allow you to create member layers and then specify custom functionality defining the operations to be performed on these layers.</p>
<p>Let’s look at the complete code for the encoder.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
attention_encoder &lt;-
  function(gru_units,
           embedding_dim,
           src_vocab_size,
           name = NULL) {
    
    keras_model_custom(name = name, function(model) {
      
      model$embedding &lt;-
        layer_embedding(
          input_dim = src_vocab_size,
          output_dim = embedding_dim
          )
      model$gru &lt;-
        layer_gru(
          units = gru_units,
          return_sequences = TRUE,
          return_state = TRUE
          )
      
      function(inputs, mask = NULL) {
        
        x &lt;- inputs[[1]]
        hidden &lt;- inputs[[2]]
        
        x &lt;- model$embedding(x)
        c(output, state) %&lt;-% model$gru(x, initial_state = hidden)
    
        list(output, state)
      }
    })
  }</code></pre>
</div>
<p>The encoder has two layers, an embedding and a GRU layer. The ensuing anonymous function specifies what should happen when the layer is called. One thing that might look unexpected is the argument passed to that function: It is a list of tensors, where the first element are the inputs, and the second is the hidden state at the point the layer is called (in traditional Keras RNN usage, we are accustomed to seeing state manipulations being done transparently for us.) As the input to the call flows through the operations, let’s keep track of the shapes involved:</p>
<ul>
<li><p><code>x</code>, the input, is of size <code>(batch_size, max_length_input)</code>, where <code>max_length_input</code> is the number of digits constituting a source sentence. (Remember we’ve padded them to be of uniform length.) In familiar RNN parlance, we could also speak of <code>timesteps</code> here (we soon will).</p></li>
<li><p>After the embedding step, the tensors will have an additional axis, as each timestep (token) will have been embedded as an <code>embedding_dim</code>-dimensional vector. So our shapes are now <code>(batch_size, max_length_input, embedding_dim)</code>.</p></li>
<li><p>Note how when calling the GRU, we’re passing in the hidden state we received as <code>initial_state</code>. We get back a list: the GRU output and last hidden state.</p></li>
</ul>
<p>At this point, it helps to look up RNN output shapes in the <a href="https://tensorflow.rstudio.com/keras/reference/layer_simple_rnn.html">documentation</a>.</p>
<p>We have specified our GRU to return sequences as well as the state. Having asked for the state means we’ll get back a list of tensors: the output, and the last state(s) - a single last state in this case as we’re using GRU. That state itself will be of shape <code>(batch_size, gru_units)</code>. Having asked for sequences means the output will be of shape <code>(batch_size, max_length_input, gru_units)</code>. So that’s that. We bundle output and last state in a list and pass it to the calling code.</p>
<p>Before we show the decoder, we need to say a few things about attention.</p>
<h3 id="attention-in-a-nutshell">Attention in a nutshell</h3>
<p>As T. Luong nicely puts it in his <a href="tbd">thesis</a>, the idea of the attention mechanism is</p>
<blockquote>
<p>to provide a ‘random access memory’ of source hidden states which one can constantly refer to as translation progresses.</p>
</blockquote>
<p>This means that at every timestep, the decoder receives not just the previous decoder hidden state, but also the complete output from the encoder. It then “makes up its mind” as to what part of the encoded input matters at the current point in time. Although various attention mechanisms exist, the basic procedure often goes like this. First, we create a <em>score</em> that relates the decoder hidden state at a given timestep to the encoder hidden states at every timestep. Different score functions exist; the following is commonly referred to as <em>Bahdanau style</em> (additive) attention (after <a href="tbd" class="uri">tbd</a>)</p>
<p><span class="math display">\[score(\mathbf{h_t},\bar{\mathbf{h_s}}) = \mathbf{v_a}^T tanh(\mathbf{W_1}\mathbf{h_t} + \mathbf{W_2}\bar{\mathbf{h_s}})\]</span></p>
<p>From these scores, we want to find the encoder states that matter most to the current decoder timestep. Basically, we just normalize the scores doing a softmax, which leaves us with a set of <em>attention weights</em>:</p>
<p><span class="math display">\[\alpha_{ts} = \frac{exp(score(\mathbf{h_t},\bar{\mathbf{h_s}}))}{\sum{score(\mathbf{h_t},\bar{\mathbf{h_{s&#39;}}})}}\]</span></p>
<h3 id="attention-decoder">Attention decoder</h3>
<p>Here’s the decoder with the attention mechanism - not too long in terms of code, but with a lot going on.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
attention_decoder &lt;-
  function(object,
           gru_units,
           embedding_dim,
           target_vocab_size,
           name = NULL) {
    
    keras_model_custom(name = name, function(model) {
      model$gru &lt;-
        layer_gru(
          units = gru_units,
          return_sequences = TRUE,
          return_state = TRUE
        )
      model$embedding &lt;-
        layer_embedding(input_dim = target_vocab_size, output_dim = embedding_dim)
      gru_units &lt;- gru_units
      model$fc &lt;- layer_dense(units = target_vocab_size)
      model$W1 &lt;- layer_dense(units = gru_units)
      model$W2 &lt;- layer_dense(units = gru_units)
      model$V &lt;- layer_dense(units = 1L)
 
      function(inputs, mask = NULL) {
        
        x &lt;- inputs[[1]]
        hidden &lt;- inputs[[2]]
        encoder_output &lt;- inputs[[3]]
        
        # encoder_output is of shape (batch_size, max_length_input, gru_units)
        # hidden has shape (batch_size, gru_units)
        # hidden_with_time_axis has shape (batch_size, 1, gru_units)
        # we are doing this to perform addition to calculate the score
        hidden_with_time_axis &lt;- k_expand_dims(hidden, 2L)
        # score has shape (batch_size, max_length, gru_units)
        score &lt;-
          k_tanh(model$W1(encoder_output) + model$W2(hidden_with_time_axis))
        
        # Softmax by default is applied on the last axis but here we want to apply
        # it on the 2nd axis, since the shape of score is
        # (batch_size, max_length, gru_units).
        # Max_length is the length of our input.
        # Since we are trying to assign a weight to each input,
        # softmax should be applied on that axis.
        
        # attention_weights has shape (batch_size, max_length_input, 1)
        # we get 1 at the last axis because we are applying score to self$V
        attention_weights &lt;- k_softmax(model$V(score), axis =  2)
        
        # context_vector has shape (batch_size, gru_units)
        # Same reason as above for choosing axis 2.
        context_vector &lt;- attention_weights * encoder_output
        context_vector &lt;- k_sum(context_vector, axis = 2)
        
        # x shape after passing through embedding is (batch_size, 1, embedding_dim)
        # here timesteps is 1 because we&#39;re forecasting 1 at a time
        x &lt;- model$embedding(x)
        
        # x shape after concatenation is (batch_size, 1, embedding_dim + gru_units)
        x &lt;-
          k_concatenate(list(k_expand_dims(context_vector, 2), x), axis = 3)
        
        c(output, state) %&lt;-% model$gru(x)
        
        # output shape is (batch_size * max_length, gru_units)
        output &lt;- k_reshape(output, c(-1L , gru_units))
        
        # final output shape is (batch_size * max_length, target_vocab_size)
        x &lt;- model$fc(output)
        
        # shapes are now:
        # x:(batch_size, target_vocab_size)
        # state: (batch_size, gru_size)
        # attention_weights is (batch_size, src_maxlen, 1)
        list(x, state, attention_weights)
        
      }
      
    })
  }</code></pre>
</div>
<p>Firstly, we notice that in addition to the usual embedding and GRU layers we’d expect in a decoder, there are a few additional dense layers. We’ll comment on those as we go.</p>
<p>This time, the input to what is effectively the <code>call</code> function consists of three parts: input, hidden state, and the output from the encoder.</p>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
