<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Math, code, concepts: A third road to deep learning</title>
  
  <meta property="description" itemprop="description" content="Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it&#39;s all about."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-03-15"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-03-15"/>
  <meta name="article:author" content="Sigrid Keydana"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Math, code, concepts: A third road to deep learning"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it&#39;s all about."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Math, code, concepts: A third road to deep learning"/>
  <meta property="twitter:description" content="Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it&#39;s all about."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","slug","date","categories","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Math, code, concepts: A third road to deep learning"]},{"type":"character","attributes":{},"value":["Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it's all about.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydana2019mathcodeconcepts"]},{"type":"character","attributes":{},"value":["03-15-2019"]},{"type":"character","attributes":{},"value":["Meta","Concepts"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/prev.jpg"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["concepts-way-to-dl_files/bowser-1.9.3/bowser.min.js","concepts-way-to-dl_files/distill-2.2.21/template.v2.js","concepts-way-to-dl_files/jquery-1.11.3/jquery.min.js","concepts-way-to-dl_files/webcomponents-2.0.0/webcomponents.js","images/prev.jpg"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="concepts-way-to-dl_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="concepts-way-to-dl_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="concepts-way-to-dl_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="concepts-way-to-dl_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Math, code, concepts: A third road to deep learning","description":"Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it's all about.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/"}],"publishedDate":"2019-03-15T00:00:00.000+01:00","citationText":"Keydana, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Math, code, concepts: A third road to deep learning</h1>
<p><p>Not everybody who wants to get into deep learning has a strong background in math or programming. This post elaborates on a concepts-driven, abstraction-based way to learn what it’s all about.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>03-15-2019
</div>

<div class="d-article">
<p>In the previous version of their awesome deep learning MOOC, I remember fast.ai’s Jeremy Howard saying something like this:</p>
<blockquote>
<p>You are either a math person or a code person, and […] <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<p>I may be wrong about the <em>either</em>, and this is not about <em>either</em> versus, say, <em>both</em>. What if in reality, you’re none of the above?</p>
<p>What if you come from a background that is close to neither math and statistics, nor computer science: the humanities, say? You may not have that intuitive, fast, effortless-looking understanding of LaTeX formulae that comes with natural talent and/or years of training, or both - the same goes for computer code.</p>
<p>Understanding always has to start somewhere, so it will have to start with math or code (or both). Also, it’s always iterative, and iterations will often alternate between math and code. But what are things you can do when primarily, you’d say you are a <em>concepts person</em>?</p>
<p>When meaning doesn’t automatically emerge from formulae, it helps to look for materials (blog posts, articles, books) that stress the <em>concepts</em> those formulae are all about. By concepts, I mean abstractions, concise, <em>verbal</em> characterizations of what a formula signifies.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Let’s try to make <em>conceptual</em> a bit more concrete. At least three aspects come to mind: useful <em>abstractions</em>, <em>chunking</em> (composing symbols into meaningful blocks), and <em>action</em> (what does that entity actually <em>do</em>?)</p>
<h2 id="abstraction">Abstraction</h2>
<p>To many people, in school, math meant nothing. Calculus was about manufacturing cans: How can we get as much soup as possible into the can while economizing on tin. How about this instead: Calculus<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> is about how one thing changes as another changes? Suddenly, you start thinking: What, in my world, can I apply this to?</p>
<p>A neural network is trained using backprop - just the <em>chain rule of calculus</em>, many texts say. How about life. How would my present be different had I spent more time exercising the ukulele? Then, how much more time would I have spent exercising the ukulele if my mother hadn’t discouraged me so much? And then - how much less discouraging would she have been had she not been forced to give up her own career as a circus artist? And so on.</p>
<p>As a more concrete example, take optimizers. With gradient descent as a baseline, what, in a nutshell, is different about momentum, RMSProp, Adam?</p>
<p>Starting with momentum, this is the formula in one of the go-to posts, Sebastian Ruder’s <a href="http://ruder.io/optimizing-gradient-descent/">http://ruder.io/optimizing-gradient-descent/</a> <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p><span class="math display">\[v_t = \gamma v_{t-1} + \eta \nabla_{\theta} J(\theta) \\
\theta = \theta - v_t\]</span></p>
<p>The formula tells us that the change to the weights<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> is made up of two parts: the gradient of the loss<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> with respect to the weights, computed at some point in time <span class="math inline">\(t\)</span> (and scaled by the learning rate<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>), and the previous change computed at time <span class="math inline">\(t-1\)</span> and discounted by some factor <span class="math inline">\(\gamma\)</span>. What does this <em>actually</em> tell us?</p>
<p>In his Coursera MOOC, Andrew Ng introduces momentum (and RMSProp, and Adam) after two videos that aren’t even about deep learning. He introduces exponential moving averages, which will be familiar to many R users: We calculate a running average where at each point in time, the running result is weighted by a certain factor (0.9, say), and the current observation by 1 minus that factor (0.1, in this example). Now look at how <em>momentum</em> is presented:<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p><span class="math display">\[v = \beta v + (1-\beta) dW \\ 
W = W - \alpha v\]</span></p>
<p>We immediately see how <span class="math inline">\(v\)</span> is the exponential moving average of gradients, and it is this that gets subtracted from the weights (scaled by the learning rate).</p>
<p>Building on that abstraction in the viewers’ minds, Ng goes on to present RMSProp. This time, a moving average is kept of the <em>squared weights</em> <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>, and at each time, this average (or rather, its square root) is used to scale the current gradient.</p>
<p><span class="math display">\[s = \beta s + (1-\beta) dW^2 \\ 
W = W - \alpha \frac{dW}{\sqrt s}\]</span></p>
<p>If you know a bit about Adam, you can guess what comes next: Why not have moving averages in the numerator as well as the denominator?</p>
<p><span class="math display">\[v = \beta_1 v + (1-\beta_1) dW \\ 
s = \beta_2 s + (1-\beta_2) dW^2 \\
W = W - \alpha \frac{v}{\sqrt s + \epsilon}\]</span></p>
<p>Of course, actual implementations may differ in details, and not always expose those features that clearly. But for understanding and memorization, abstractions like this one - <em>exponential moving average</em> - do a lot. Let’s now see about chunking.</p>
<h2 id="chunking">Chunking</h2>
<p>Looking again at the above formula from Sebastian Ruder’s post,</p>
<p><span class="math display">\[v_t = \gamma v_{t-1} + \eta \nabla_{\theta} J(\theta) \\
\theta = \theta - v_t\]</span></p>
<p>how easy is it to parse the first line? Of course that depends on experience, but let’s focus on the formula itself.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>Reading that first line, we mentally build something like an AST (abstract syntax tree). Exploiting programming language vocabulary even further, operator precedence is crucial: To understand the right half of the tree, we want to first parse <span class="math inline">\(\nabla_{\theta} J(\theta)\)</span>, and then only take <span class="math inline">\(\eta\)</span> into consideration.</p>
<p>Moving on to larger formulae, the problem of operator precedence becomes one of <em>chunking</em>: Take that bunch of symbols and see it as a whole. We could call this abstraction again, just like above. But here, the focus is not on <em>naming</em> things or verbalizing, but on <em>seeing</em>: Seeing at a glance that when you read</p>
<p><span class="math display">\[\frac{e^{z_i}}{\sum_j{e^{z_j}}}\]</span></p>
<p>it is “just a softmax”. Again, my inspiration for this comes from Jeremy Howard, who I remember demonstrating, in one of the fastai lectures, that this is how you read a paper.</p>
<p>Let’s turn to a more complex example. Last year’s article on <a href="https://blogs.rstudio.com/tensorflow/posts/2018-07-30-attention-layer/">Attention-based Neural Machine Translation with Keras</a> included a short exposition of <em>attention</em>, featuring four steps:</p>
<ol type="1">
<li>Scoring encoder hidden states as to inasmuch they are a fit to the current decoder hidden state.</li>
</ol>
<p>Choosing Luong-style attention now<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>, we have</p>
<p><span class="math display">\[score(\mathbf{h}_t,\bar{\mathbf{h}_s}) = \mathbf{h}_t^T \mathbf{W}\bar{\mathbf{h}_s}\]</span></p>
<p>On the right, we see three symbols, which may appear meaningless at first but if we mentally “fade out” the weight matrix in the middle, a dot product appears, indicating that essentially, this is calculating <em>similarity</em>.</p>
<ol start="2" type="1">
<li>Now comes what’s called <em>attention weights</em>: At the current timestep, which encoder states matter most?</li>
</ol>
<p><span class="math display">\[\alpha_{ts} = \frac{exp(score(\mathbf{h}_t,\bar{\mathbf{h}_s}))}{\sum_{s&#39;=1}^{S}{score(\mathbf{h}_t,\bar{\mathbf{h}_{s&#39;}})}}\]</span></p>
<p>Scrolling up a bit, we see that this, in fact, is “just a softmax” (even though the physical appearance is not the same). Here, it is used to normalize the scores, making them sum to 1.</p>
<ol start="3" type="1">
<li>Next up is the <em>context vector</em>:</li>
</ol>
<p><span class="math display">\[\mathbf{c}_t= \sum_s{\alpha_{ts} \bar{\mathbf{h}_s}}\]</span></p>
<p>Without much thinking - but remembering from right above that the <span class="math inline">\(\alpha\)</span>s represent attention <em>weights</em> - we see a weighted average.</p>
<p>Finally, in step</p>
<ol start="4" type="1">
<li>we need to actually combine that context vector with the current hidden state (here, done by training a fully connected layer on their concatenation):</li>
</ol>
<p><span class="math display">\[\mathbf{a}_t = tanh(\mathbf{W_c} [ \mathbf{c}_t ; \mathbf{h}_t])\]</span></p>
<p>This last step may be a better example of abstraction than of chunking, but anyway those are closely related: We need to chunk adequately to name concepts, and intuition about concepts helps chunk correctly. Closely related to abstraction, too, is analyzing what entities <em>do</em>.</p>
<h2 id="action">Action</h2>
<p>Although not deep learning related (in a narrow sense), my favorite quote comes from one of Gilbert Strang’s lectures on linear algebra:<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<blockquote>
<p>Matrices don’t just sit there, they do something.</p>
</blockquote>
<p>If in school calculus was about saving production materials, matrices were about matrix multiplication - the rows-by-columns way. (Or perhaps they existed for us to be trained to compute determinants, seemingly useless numbers that turn out to have a meaning, as we are going to see in a future post.) Conversely, based on the much more illuminating <em>matrix multiplication as linear combination of columns</em> (resp. rows) view, Gilbert Strang introduces types of matrices as agents, concisely named by initial.</p>
<p>For example, when multiplying another matrix <span class="math inline">\(A\)</span> on the right, this permutation matrix <span class="math inline">\(P\)</span></p>
<p><span class="math display">\[\mathbf{P} = \left[\begin{array}
{rrr}
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0
\end{array}\right]
\]</span></p>
<p>puts <span class="math inline">\(A\)</span>’s third row first, its first row second, and its second row third:</p>
<p><span class="math display">\[\mathbf{PA} = \left[\begin{array}
{rrr}
0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0
\end{array}\right]
\left[\begin{array}
{rrr}
0 &amp; 1 &amp; 1 \\
1 &amp; 3 &amp; 7 \\
2 &amp; 4 &amp; 8
\end{array}\right] =
\left[\begin{array}
{rrr}
2 &amp; 4 &amp; 8 \\
0 &amp; 1 &amp; 1 \\
1 &amp; 3 &amp; 7
\end{array}\right]
\]</span></p>
<p>In the same way, reflection, rotation, and projection matrices are presented via their <em>actions</em>. The same goes for one of the most interesting topics in linear algebra from the point of view of the data scientist: matrix factorizations. <span class="math inline">\(LU\)</span>, <span class="math inline">\(QR\)</span>, eigendecomposition, <span class="math inline">\(SVD\)</span> are all characterized by <em>what they do</em>. <a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>Who are the agents in neural networks? Activation functions are agents; this is where we have to mention <code>softmax</code> for the third time: Its strategy was described in <a href="https://blogs.rstudio.com/tensorflow/posts/2018-10-11-activations-intro/">Winner takes all: A look at activations and cost functions</a>.</p>
<p>Also, optimizers are agents, and this is where we finally include some code. The explicit training loop used in all of the eager execution blog posts so far</p>
<pre><code>
with(tf$GradientTape() %as% tape, {
     
  # run model on current batch
  preds &lt;- model(x)
     
  # compute the loss
  loss &lt;- mse_loss(y, preds, x)
})
    
# get gradients of loss w.r.t. model weights
gradients &lt;- tape$gradient(loss, model$variables)
    
# update model weights
optimizer$apply_gradients(
  purrr::transpose(list(gradients, model$variables)),
  global_step = tf$train$get_or_create_global_step()
)</code></pre>
<p>has the optimizer do a single thing: <em>apply</em> the gradients it gets passed from the gradient tape.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> Thinking back to the characterization of different optimizers we saw above, this piece of code adds vividness to the thought that optimizers differ in what they <em>actually do</em> once they got those gradients.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Wrapping up, the goal here was to elaborate a bit on a conceptual, abstraction-driven way to get more familiar with the math involved in deep learning (or machine learning, in general). Certainly, the three aspects highlighted interact, overlap, form a whole, and there are other aspects to it. Analogy may be one, but it was left out here because it seems even more subjective, and less general. Comments describing user experiences are very welcome.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>If I don’t remember correctly: please just allow me to use this as the perfect intro to this post.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Certainly <em>visualization</em> may be very useful, too, depending on the topic/algorithm and on “how visual a person” you are. But there is no need to stress the importance of visualization - everybody agrees on it - so this post is dedicated to verbal/conceptual methods.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Differential calculus, to be precise.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>This is of course an excellent article that <em>does</em> mention concepts. It is just not intended for beginners, in contrast to the approach highlighted below.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><span class="math inline">\(\theta\)</span><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p><span class="math inline">\(J\)</span><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p><span class="math inline">\(\eta\)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Following the notation from the video, marginally simplified. Here <span class="math inline">\(\beta\)</span> is the scale factor applied to the running average, <span class="math inline">\(dW\)</span> is the gradient of the loss with respect to the weights, and <span class="math inline">\(\alpha\)</span> is the learning rate.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p><span class="math inline">\(W^2\)</span><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p> As a side note, picking up on Jeremy Howard again: The Greek letters of course don’t make things any easier, but even with a history of studying ancient Greek for five years those formulae aren’t necessarily parsed easily.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>The original post showed Bahdanau-style attention.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>At least that’s what I remember him saying, approximately. The exact wording does not matter here.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Although, if this were the paragraph about <em>abstractions</em>, Gilbert Strang’s books would yield perfect examples as well.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>In other use cases, the optimizer class may also be used to compute gradients. But that method (<code>optimizer$compute_gradients</code>) is defined in the optimizer superclass and not subclass specific.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
