<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="radix" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Winner takes all: A glance at activations and cost functions</title>
  
  <meta property="description" itemprop="description" content="Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post, we provide a conceptual, intuitive introduction."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2018-10-11"/>
  <meta property="article:created" itemprop="dateCreated" content="2018-10-11"/>
  <meta name="article:author" content="Sigrid Keydana"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Winner takes all: A glance at activations and cost functions"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post, we provide a conceptual, intuitive introduction."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Winner takes all: A glance at activations and cost functions"/>
  <meta property="twitter:description" content="Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post, we provide a conceptual, intuitive introduction."/>
  
  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Deep learning;citation_publication_date=2016;citation_publisher=MIT Press;citation_author=Ian Goodfellow;citation_author=Yoshua Bengio;citation_author=Aaron Courville"/>
  <meta name="citation_reference" content="citation_title=Machine learning: A probabilistic perspective;citation_publication_date=2012;citation_publisher=MIT Press;citation_author=Kevin Murphy"/>
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","bibliography","slug","date","categories","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Winner takes all: A glance at activations and cost functions"]},{"type":"character","attributes":{},"value":["Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post, we provide a conceptual, intuitive introduction.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"character","attributes":{},"value":["keydana2018activationsintro"]},{"type":"character","attributes":{},"value":["10-11-2018"]},{"type":"character","attributes":{},"value":["Keras","Introductions"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["images/output.png"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["activations_intro_files/bowser-1.9.3/bowser.min.js","activations_intro_files/distill-2.2.21/template.v2.js","activations_intro_files/jquery-1.11.3/jquery.min.js","activations_intro_files/webcomponents-2.0.0/webcomponents.js","bibliography.bib","images/output.png","images/Rplot.png","images/sigmoid.png","images/softmax_post.png","images/softmax_pre.png","images/xent.png"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.text();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.text(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        if ($.inArray(language, ["r", "cpp", "c", "java"]) != -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      $(this).find('img, .html-widget').css('width', '100%');
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.radix-site-header a').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="activations_intro_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="activations_intro_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="activations_intro_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="activations_intro_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Winner takes all: A glance at activations and cost functions","description":"Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post, we provide a conceptual, intuitive introduction.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/"}],"publishedDate":"2018-10-11T00:00:00.000+02:00","citationText":"Keydana, 2018"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Winner takes all: A glance at activations and cost functions</h1>
<p>Why do we use the activations we use, and how do they relate to the cost functions they tend to co-appear with? In this post, we provide a conceptual, intuitive introduction.</p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>10-11-2018
</div>

<div class="d-article">
<p>You’re building a Keras model. If you haven’t been doing deep learning for so long, getting the output activations and cost function right might involve some memorization (or lookup). You might be trying to recall the general proceedings like so:</p>
<p><em>So with my cats and dogs, I’m doing 2-class classification, so I have to use sigmoid activation in the output layer, right, and then, it’s binary crossentropy for the cost function…</em> Or: <em>I’m doing classification on ImageNet, that’s multi-class, so that was softmax for activation, and then, cost should be categorical crossentropy…</em></p>
<p>It’s fine to memorize stuff like this, but knowing a bit about the reasons behind often makes things easier. So we ask: Why is it that these output activations and cost functions go together? And, do they always have to?</p>
<h2 id="in-a-nutshell">In a nutshell</h2>
<p>Put simply, we choose activations do make the network predict what we want it to predict. The cost function is then determined by the model.</p>
<p>This is because neural networks are normally optimized using <em>maximum likelihood</em>, and depending on the distribution we assume for the output units, maximum likelihood yields different optimization objectives.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> <span class="citation" data-cites="Goodfellow-et-al-2016">(Goodfellow, Bengio, and Courville <a href="#ref-Goodfellow-et-al-2016">2016</a>)</span> All of these objectives then minimize the cross entropy (pragmatically: mismatch) between the true distribution and the predicted distribution.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>Let’s start with the simplest, the linear case.</p>
<h2 id="regression">Regression</h2>
<p>For the botanists among us, here’s a super simple network meant to predict sepal width from sepal length:<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(units = 32) %&gt;%
  layer_dense(units = 1)

model %&gt;% compile(optimizer = &quot;adam&quot;, loss = &quot;mean_squared_error&quot;)

model %&gt;% fit(
  x = iris$Sepal.Length %&gt;% as.matrix(),
  y = iris$Sepal.Width %&gt;% as.matrix(),
  epochs = 50
)</code></pre>
</div>
<p>Our model’s assumption here is that sepal width is normally distributed, given sepal length. Most often, we’re trying to predict the mean of a conditional Gaussian distribution:<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p><span class="math display">\[p(y|\mathbf{x} = N(y; \mathbf{w}^t\mathbf{h} + b)\]</span></p>
<p>In that case, the cost function that minimizes cross entropy (equivalently: optimizes maximum likelihood) is <em>mean squared error</em>. And that’s exactly what we’re using as a cost function above.</p>
<p>Alternatively, we might wish to predict the median of that conditional distribution. In that case, we’d change the cost function to use mean absolute error:</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
model %&gt;% compile(optimizer = &quot;adam&quot;, loss = &quot;mean_absolute_error&quot;)</code></pre>
</div>
<p>Now let’s move on beyond linearity.</p>
<h2 id="binary-classification">Binary classification</h2>
<p>We’re enthusiastic bird watchers and want an application to notify us when there’s a bird in our garden - not when the neighbors landed their airplane, though. We’ll thus train a network to distinguish between two classes: birds and airplanes.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# Using the CIFAR-10 dataset that conveniently comes with Keras.
cifar10 &lt;- dataset_cifar10()

x_train &lt;- cifar10$train$x / 255
y_train &lt;- cifar10$train$y

is_bird &lt;- cifar10$train$y == 2
x_bird &lt;- x_train[is_bird, , ,]
y_bird &lt;- rep(0, 5000)

is_plane &lt;- cifar10$train$y == 0
x_plane &lt;- x_train[is_plane, , ,]
y_plane &lt;- rep(1, 5000)

x &lt;- abind::abind(x_bird, x_plane, along = 1)
y &lt;- c(y_bird, y_plane)

model &lt;- keras_model_sequential() %&gt;%
  layer_conv_2d(
    filter = 8,
    kernel_size = c(3, 3),
    padding = &quot;same&quot;,
    input_shape = c(32, 32, 3),
    activation = &quot;relu&quot;
  ) %&gt;%
  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%
  layer_conv_2d(
    filter = 8,
    kernel_size = c(3, 3),
    padding = &quot;same&quot;,
    activation = &quot;relu&quot;
  ) %&gt;%
  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%
layer_flatten() %&gt;%
  layer_dense(units = 32, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 1, activation = &quot;sigmoid&quot;)

model %&gt;% compile(optimizer = &quot;adam&quot;, loss = &quot;binary_crossentropy&quot;, metrics = &quot;accuracy&quot;)
model %&gt;% fit(
  x = x,
  y = y,
  epochs = 50
)</code></pre>
</div>
<p>Although we normally talk about “binary classification”, the way the outcome is usually modeled is as a <em>Bernoulli random variable</em>, conditioned on the input data. So:</p>
<p><span class="math display">\[P(y = 1|\mathbf{x}) = p, \ 0\leq p\leq1\]</span></p>
<p>A Bernoulli random variable takes on values between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. So that’s what our network should produce. One idea might be to just clip all values of <span class="math inline">\(\mathbf{w}^t\mathbf{h} + b\)</span> outside that interval. But if we do this, the gradient in these regions will be <span class="math inline">\(0\)</span>: The network cannot learn.</p>
<p>A better way is to squish the complete incoming interval into the range (0,1), using the logistic <em>sigmoid</em> function</p>
<p><span class="math display">\[ \sigma(x) = \frac{1}{1 + e^{(-x)}} \]</span></p>
<figure>
<img src="images/sigmoid.png" alt="The sigmoid function squishes its input into the interval (0,1)" style="width:100.0%" /><figcaption>The sigmoid function squishes its input into the interval (0,1)</figcaption>
</figure>
<p>As you can see, the sigmoid function saturates when its input gets very large, or very small. Is this problematic? It depends. In the end, what we care about is if the cost function saturates. Were we to choose mean squared error here, as in the regression task above, that’s indeed what could happen.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>However, if we follow the general principle of maximum likelihood/cross entropy, the loss will be</p>
<p><span class="math display">\[- log P (y|\mathbf{x})\]</span></p>
<p>where the <span class="math inline">\(log\)</span> undoes the <span class="math inline">\(exp\)</span> in the sigmoid.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p>In Keras, the corresponding loss function is <code>binary_crossentropy</code>. For a single item, the loss will be</p>
<ul>
<li><span class="math inline">\(- log(p)\)</span> when the ground truth is 1</li>
<li><span class="math inline">\(- log(1-p)\)</span> when the ground truth is 0<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></li>
</ul>
<p>Here, you can see that when for an individual example, the network predicts the wrong class <em>and</em> is highly confident about it, this example will contributely very strongly to the loss.</p>
<figure>
<img src="images/xent.png" alt="Cross entropy penalizes wrong predictions most when they are highly confident." style="width:100.0%" /><figcaption>Cross entropy penalizes wrong predictions most when they are highly confident.</figcaption>
</figure>
<p>What happens when we distinguish between more than two classes?</p>
<h2 id="multi-class-classification">Multi-class classification</h2>
<p>CIFAR-10 has 10 classes; so now we want to decide which of 10 object classes is present in the image.</p>
<p>Here first is the code: Not many differences to the above, but note the changes in activation and cost function.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
cifar10 &lt;- dataset_cifar10()

x_train &lt;- cifar10$train$x / 255
y_train &lt;- cifar10$train$y

model &lt;- keras_model_sequential() %&gt;%
  layer_conv_2d(
    filter = 8,
    kernel_size = c(3, 3),
    padding = &quot;same&quot;,
    input_shape = c(32, 32, 3),
    activation = &quot;relu&quot;
  ) %&gt;%
  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%
  layer_conv_2d(
    filter = 8,
    kernel_size = c(3, 3),
    padding = &quot;same&quot;,
    activation = &quot;relu&quot;
  ) %&gt;%
  layer_max_pooling_2d(pool_size = c(2, 2)) %&gt;%
  layer_flatten() %&gt;%
  layer_dense(units = 32, activation = &quot;relu&quot;) %&gt;%
  layer_dense(units = 10, activation = &quot;softmax&quot;)

model %&gt;% compile(
  optimizer = &quot;adam&quot;,
  loss = &quot;sparse_categorical_crossentropy&quot;,
  metrics = &quot;accuracy&quot;
)

model %&gt;% fit(
  x = x_train,
  y = y_train,
  epochs = 50
)</code></pre>
</div>
<p>So now we have <em>softmax</em> combined with <em>categorical crossentropy</em>. What’s their <em>raison d’être</em>?</p>
<p>Again, we want a valid probability distribution: Probabilities for all disjunct events should sum to 1.</p>
<p>CIFAR-10 has one object per image; so events are disjunct. Then we have a single-draw multinomial distribution<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a><span class="citation" data-cites="Murphy-2012">(Murphy <a href="#ref-Murphy-2012">2012</a>)</span> that can be modeled by the softmax activation:</p>
<p><span class="math display">\[softmax(\mathbf{z})_i = \frac{e^{z_i}}{\sum_j{e^{z_j}}}\]</span></p>
<p>Just as the sigmoid, the softmax can saturate. In this case, that will happen when <em>differences</em> between outputs become very big. Also like with the sigmoid, a <span class="math inline">\(log\)</span> in the cost function undoes the <span class="math inline">\(exp\)</span> that’s responsible for saturation:</p>
<p><span class="math display">\[log\ softmax(\mathbf{z})_i = z_i - log\sum_j{e^{z_j}}\]</span></p>
<p>Here <span class="math inline">\(z_i\)</span> is the class we’re estimating the probability of - we see that its contribution to the loss is linear and thus, can never saturate.</p>
<p>In Keras, the loss function that does this for us is called <code>categorical_crossentropy</code>.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>Let’s take a closer look at what softmax does. Assume these are the raw outputs of our 10 output units:</p>
<figure>
<img src="images/softmax_pre.png" alt="Simulated output before application of softmax." style="width:100.0%" /><figcaption>Simulated output before application of softmax.</figcaption>
</figure>
<p>Now this is what the normalized probability distribution looks like after taking the softmax:</p>
<figure>
<img src="images/softmax_post.png" alt="Final output after softmax." style="width:100.0%" /><figcaption>Final output after softmax.</figcaption>
</figure>
<p>Do you see where the <em>winner takes all</em> in the title comes from? This is an important point to keep in mind: Activation functions are not just there to produce certain desired distributions; they can also change relationships between values.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We started this post alluding to common heuristics, such as “for multi-class classification, we use softmax activation, combined with categorical crossentropy as the loss function”. Hopefully, we’ve succeeded in showing why these heuristics make sense.</p>
<p>However, knowing that background, you can also infer when these rules do not apply. For example, say you want to detect several objects in an image. In that case, the <em>winner-takes-all</em> strategy is not the most useful, as we don’t want to exaggerate differences between candidates. So here, we’d use <em>sigmoid</em> on all output units instead, to determine a probability of presence <em>per object</em>.</p>
<div id="refs" class="references">
<div id="ref-Goodfellow-et-al-2016">
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.</p>
</div>
<div id="ref-Murphy-2012">
<p>Murphy, Kevin. 2012. <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>For a more mathematical development of this topic, see chapter 6.2 of Goodfellow et al., Deep Learning. This post is meant to be an intuitive introduction.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>See chapter 5.5 in Goodfellow et al. for details.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>In case you’d like a more comprehensive introduction to doing regression with Keras, see the tutorial at <a href="https://tensorflow.rstudio.com/keras/articles/tutorial_basic_regression.html" class="uri">https://tensorflow.rstudio.com/keras/articles/tutorial_basic_regression.html</a>.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Assuming a single output unit in the formula here.<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>For a more detailed introduction to classification with Keras, see the tutorial at <a href="https://tensorflow.rstudio.com/keras/articles/tutorial_basic_classification.html" class="uri">https://tensorflow.rstudio.com/keras/articles/tutorial_basic_classification.html</a>.<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>The actual outcome depends on the task. In the above simple classification example, training with mean squared error will attain similar accuracy in similar time.<a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>If you need the details, see section 6.2.2.2 in Goodfellow et al.<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>Here p is the predicted probability, i.e., the output activations of the network.<a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>popularly known as “Multinoulli”, mostly due to Muphy’s <em>Machine learning</em><a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>We use sparse_categorical_crossentropy in the code which is the same as <code>categorical_crossentropy</code> but does not need conversion of integer labels to one-hot vectors.<a href="#fnref10" class="footnote-back">↩</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<script id="distill-bibliography" type="text/bibtex">
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@book{Murphy-2012,
    title={Machine Learning: A Probabilistic Perspective},
    author={Kevin Murphy},
    publisher={MIT Press},
    year={2012}
}
</script>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
