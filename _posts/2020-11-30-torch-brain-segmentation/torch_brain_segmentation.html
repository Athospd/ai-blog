<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #545454; font-weight: bold; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #a1024a; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007faa; font-weight: bold; } /* ControlFlow */
code span.ch { color: #008000; } /* Char */
code span.cn { color: #d91e18; } /* Constant */
code span.co { color: #545454; } /* Comment */
code span.cv { color: #545454; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #aa5d00; } /* DataType */
code span.dv { color: #a1024a; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #a1024a; } /* Float */
code span.fu { color: #4254a7; } /* Function */
code span.im { } /* Import */
code span.in { color: #545454; font-weight: bold; } /* Information */
code span.kw { color: #007faa; font-weight: bold; } /* Keyword */
code span.op { color: #696969; } /* Operator */
code span.ot { color: #007faa; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #008000; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #008000; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #008000; } /* VerbatimString */
code span.wa { color: #545454; font-weight: bold; font-style: italic; } /* Warning */
</style>

  <!--radix_placeholder_meta_tags-->
  <title>Brain image segmentation with torch</title>

  <meta property="description" itemprop="description" content="The need to segment images arises in various sciences and their applications, many of whom are vital to human (and animal) life. In this introductory post, we train a U-Net to mark lesioned regions on MRI brain scans."/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2020-11-26"/>
  <meta property="article:created" itemprop="dateCreated" content="2020-11-26"/>
  <meta name="article:author" content="Sigrid Keydana"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Brain image segmentation with torch"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="The need to segment images arises in various sciences and their applications, many of whom are vital to human (and animal) life. In this introductory post, we train a U-Net to mark lesioned regions on MRI brain scans."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Brain image segmentation with torch"/>
  <meta property="twitter:description" content="The need to segment images arises in various sciences and their applications, many of whom are vital to human (and animal) life. In this introductory post, we train a U-Net to mark lesioned regions on MRI brain scans."/>

  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=U-net: Convolutional networks for biomedical image segmentation;citation_publication_date=2015;citation_volume=abs/1505.04597;citation_author=Olaf Ronneberger;citation_author=Philipp Fischer;citation_author=Thomas Brox"/>
  <meta name="citation_reference" content="citation_title=Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm;citation_publication_date=2019;citation_volume=109;citation_doi=https://doi.org/10.1016/j.compbiomed.2019.05.002;citation_issn=0010-4825;citation_author=Mateusz Buda;citation_author=Ashirbani Saha;citation_author=Maciej A. Mazurowski"/>
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","slug","date","categories","bibliography","output","preview"]}},"value":[{"type":"character","attributes":{},"value":["Brain image segmentation with torch"]},{"type":"character","attributes":{},"value":["The need to segment images arises in various sciences and their applications, many of whom are vital to human (and animal) life. In this introductory post, we train a U-Net to mark lesioned regions on MRI brain scans.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Sigrid Keydana"]},{"type":"character","attributes":{},"value":["RStudio"]},{"type":"character","attributes":{},"value":["https://www.rstudio.com/"]}]}]},{"type":"character","attributes":{},"value":["keydanatorchtabular"]},{"type":"character","attributes":{},"value":["11-26-2020"]},{"type":"character","attributes":{},"value":["Torch","R","Image Recognition & Image Processing"]},{"type":"character","attributes":{},"value":["bibliography.bib"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]}]}]},{"type":"character","attributes":{},"value":["images/scans.png"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["bibliography.bib","images/brainseg_augmentation.png","images/eval_masks.png","images/scan_and_mask.png","images/scans.png","images/unet.png","torch_brain_segmentation_files/anchor-4.2.2/anchor.min.js","torch_brain_segmentation_files/bowser-1.9.3/bowser.min.js","torch_brain_segmentation_files/distill-2.2.21/template.v2.js","torch_brain_segmentation_files/header-attrs-2.5/header-attrs.js","torch_brain_segmentation_files/jquery-1.11.3/jquery.min.js","torch_brain_segmentation_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: hidden;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure img {
    width: 100%;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="torch_brain_segmentation_files/header-attrs-2.5/header-attrs.js"></script>
  <script src="torch_brain_segmentation_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="torch_brain_segmentation_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="torch_brain_segmentation_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="torch_brain_segmentation_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="torch_brain_segmentation_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Brain image segmentation with torch","description":"The need to segment images arises in various sciences and their applications, many of whom are vital to human (and animal) life. In this introductory post, we train a U-Net to mark lesioned regions on MRI brain scans.","authors":[{"author":"Sigrid Keydana","authorURL":"#","affiliation":"RStudio","affiliationURL":"https://www.rstudio.com/","orcidID":""}],"publishedDate":"2020-11-26T00:00:00.000+01:00","citationText":"Keydana, 2020"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Brain image segmentation with torch</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
<div class="dt=tag">Torch</div>
<div class="dt=tag">R</div>
<div class="dt=tag">Image Recognition &amp; Image Processing</div>
</div>
<!--/radix_placeholder_categories-->
<p><p>The need to segment images arises in various sciences and their applications, many of whom are vital to human (and animal) life. In this introductory post, we train a U-Net to mark lesioned regions on MRI brain scans.</p></p>
</div>

<div class="d-byline">
  Sigrid Keydana  (RStudio)<a href="https://www.rstudio.com/" class="uri">https://www.rstudio.com/</a>
  
<br/>11-26-2020
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#when-what-is-not-enough">When <em>what</em> is not enough</a></li>
<li><a href="#u-net">U-Net</a></li>
<li><a href="#brain-image-segmentation">Brain image segmentation</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#dataset">Dataset</a></li>
<li><a href="#model">Model</a></li>
<li><a href="#optimization">Optimization</a></li>
<li><a href="#training">Training</a></li>
<li><a href="#evaluation">Evaluation</a></li>
<li><a href="#wrapup">Wrapup</a></li>
</ul>
</nav>
</div>
<h2 id="when-what-is-not-enough">When <em>what</em> is not enough</h2>
<p>True, sometimes it’s vital to distinguish between different kinds of objects. Is that a car speeding towards me, in which case I’d better jump out of the way? Or is it a huge terrier (in which case I’d probably do the same)? Often in real life though, instead of coarse-grained <em>classification</em>, what is needed is fine-grained <em>segmentation</em>.</p>
<p>Zooming in on images, we’re not looking for a single label; instead, we want to classify every pixel according to some criterion:</p>
<ul>
<li><p>In medicine, we may want to distinguish between different cell types, or identify tumors.</p></li>
<li><p>In various earth sciences, satellite data are used to segment terrestrial surfaces.</p></li>
<li><p>To enable use of custom backgrounds, video-conferencing software has to be able to tell foreground from background.</p></li>
</ul>
<p>Image segmentation is a form of supervised learning: Some kind of ground truth is needed. Here, it comes in form of a <em>mask</em> – an image, of spatial resolution identical to that of the input data, that designates the true class for every pixel. Accordingly, classification loss is calculated pixel-wise; losses are then summed up to yield an aggregate to be used in optimization.</p>
<p>The “canonical” architecture for image segmentation, around since 2015, is <em>U-Net.</em></p>
<h2 id="u-net">U-Net</h2>
<p>Here is the prototypical U-Net, as depicted in the original Rönneberger et al. paper <span class="citation" data-cites="RonnebergerFB15">(<a href="#ref-RonnebergerFB15" role="doc-biblioref">Ronneberger, Fischer, and Brox 2015</a>)</span>.</p>
<p>Of this architecture, numerous variants exist; you could use different layer sizes, activations, ways to achieve downsizing and upsizing, and more. However, there is one defining characteristic: The U-shape, stabilized by the “bridges” crossing over horizontally at all levels.</p>
<p><img src="images/unet.png" title="The original U-Net, as depicted in Ronnerberger et al. (2015)." /></p>
<p>In a nutshell, the left-hand side of the U resembles the convolutional architectures used in image classification: It successively reduces spatial resolution. At the same time, another dimension – the <em>channels</em> dimension – is used to build up a hierarchy of features, ranging from very basic to very specialized.</p>
<p>Unlike in classification, however, the output should have the same spatial resolution as the input. Thus, we need to upsize again – this is taken care of by the right-hand side of the U. But: How are we going to arrive at a good <em>per-pixel</em> classification, now that so much spatial information has been lost?</p>
<p>This is what the “bridges” are for: At each level, the input to an upsampling layer is a <em>concatenation</em> of the previous layer’s output – which went through the whole compression/decompression routine – and some preserved intermediate representation from the downsizing phase. In this way, a U-Net architecture combines attention to detail with feature extraction.</p>
<h2 id="brain-image-segmentation">Brain image segmentation</h2>
<p>With U-Net, domain applicability is as broad as the architecture is flexible. Here, we want to detect abnormalities in brain scans. The dataset, used in <span class="citation" data-cites="BUDA2019218"><a href="#ref-BUDA2019218" role="doc-biblioref">Buda, Saha, and Mazurowski</a> (<a href="#ref-BUDA2019218" role="doc-biblioref">2019</a>)</span>, contains MR images together with manually created <a href="https://en.wikipedia.org/wiki/Fluid-attenuated_inversion_recovery">FLAIR</a> abnormality segmentation masks. It is available on <a href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation">Kaggle</a>.</p>
<p>Nicely, the paper is accompanied by a <a href="https://github.com/mateuszbuda/brain-segmentation-pytorch">GitHub repository</a>. Below, we closely follow (though not exactly replicate) the authors’ preprocessing and data augmentation code.</p>
<p>As is often the case in medical imaging, there is notable class imbalance in the data. For every patient, sections have been taken at multiple positions. (Number of sections per patient varies.) Most sections do not exhibit any lesions; the corresponding masks are colored black everywhere.</p>
<p>Here are three examples where the masks <em>do</em> indicate abnormalities:</p>
<p><img src="images/scans.png" /></p>
<p>Let’s see if we can build a U-Net that generates such masks for us.</p>
<h2 id="data">Data</h2>
<p>Before you start typing, here is a <a href="https://colab.research.google.com/drive/1gcPOlF4jff42yiquRbbCxnRANEqPpGMD?usp=sharing">Colaboratory notebook</a> to conveniently follow along.</p>
<p>We use <code>pins</code> to obtain the data. Please see <a href="https://pins.rstudio.com/articles/boards-kaggle.html">this introduction</a> if you haven’t been using that package before.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://torch.mlverse.org/docs'>torch</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>torchvision</span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='http://tidyverse.tidyverse.org'>tidyverse</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://docs.ropensci.org/magick/'>magick</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/nteetor/zeallot'>zeallot</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://wilkelab.org/cowplot/'>cowplot</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/r-lib/zip#readme'>zip</a></span><span class='op'>)</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/rstudio/pins'>pins</a></span><span class='op'>)</span>

<span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_manual_seed.html'>torch_manual_seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>777</span><span class='op'>)</span>

<span class='co'># use your own kaggle.json here</span>
<span class='fu'>pins</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/pins/man/board_register_kaggle.html'>board_register_kaggle</a></span><span class='op'>(</span>token <span class='op'>=</span> <span class='st'>"~/kaggle.json"</span><span class='op'>)</span>

<span class='va'>files</span> <span class='op'>&lt;-</span> <span class='fu'>pins</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/pins/man/pin_get.html'>pin_get</a></span><span class='op'>(</span><span class='st'>"mateuszbuda/lgg-mri-segmentation"</span>, board <span class='op'>=</span> <span class='st'>"kaggle"</span>,  extract <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>The dataset is not that big – it includes scans from 110 different patients –, so we’ll have to do with just a training and a validation set. (Don’t do this in real life, as you’ll inevitably end up fine-tuning on the latter.)</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>train_dir</span> <span class='op'>&lt;-</span> <span class='st'>"data/mri_train"</span>
<span class='va'>valid_dir</span> <span class='op'>&lt;-</span> <span class='st'>"data/mri_valid"</span>

<span class='kw'>if</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/files2.html'>dir.exists</a></span><span class='op'>(</span><span class='va'>train_dir</span><span class='op'>)</span><span class='op'>)</span> <span class='fu'><a href='https://rdrr.io/r/base/unlink.html'>unlink</a></span><span class='op'>(</span><span class='va'>train_dir</span>, recursive <span class='op'>=</span> <span class='cn'>TRUE</span>, force <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
<span class='kw'>if</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/files2.html'>dir.exists</a></span><span class='op'>(</span><span class='va'>valid_dir</span><span class='op'>)</span><span class='op'>)</span> <span class='fu'><a href='https://rdrr.io/r/base/unlink.html'>unlink</a></span><span class='op'>(</span><span class='va'>valid_dir</span>, recursive <span class='op'>=</span> <span class='cn'>TRUE</span>, force <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>

<span class='fu'>zip</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/zip/man/unzip.html'>unzip</a></span><span class='op'>(</span><span class='va'>files</span>, exdir <span class='op'>=</span> <span class='st'>"data"</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/files.html'>file.rename</a></span><span class='op'>(</span><span class='st'>"data/kaggle_3m"</span>, <span class='va'>train_dir</span><span class='op'>)</span>

<span class='co'># this is a duplicate, again containing kaggle_3m (evidently a packaging error on Kaggle)</span>
<span class='co'># we just remove it</span>
<span class='fu'><a href='https://rdrr.io/r/base/unlink.html'>unlink</a></span><span class='op'>(</span><span class='st'>"data/lgg-mri-segmentation"</span>, recursive <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/files2.html'>dir.create</a></span><span class='op'>(</span><span class='va'>valid_dir</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Of those 110 patients, we keep 30 for validation. Some more file manipulations, and we’re set up with a nice hierarchical structure, with each of <code>train_dir</code> and <code>valid_dir</code> holding their per-patient sub-directories, respectively.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>valid_indices</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>patients</span><span class='op'>)</span>, <span class='fl'>30</span><span class='op'>)</span>

<span class='va'>patients</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/list.files.html'>list.dirs</a></span><span class='op'>(</span><span class='va'>train_dir</span>, recursive <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span>

<span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='va'>valid_indices</span><span class='op'>)</span> <span class='op'>{</span>
  <span class='fu'><a href='https://rdrr.io/r/base/files2.html'>dir.create</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>valid_dir</span>, <span class='fu'><a href='https://rdrr.io/r/base/basename.html'>basename</a></span><span class='op'>(</span><span class='va'>patients</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
  <span class='kw'>for</span> <span class='op'>(</span><span class='va'>f</span> <span class='kw'>in</span> <span class='fu'><a href='https://rdrr.io/r/base/list.files.html'>list.files</a></span><span class='op'>(</span><span class='va'>patients</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>    
    <span class='fu'><a href='https://rdrr.io/r/base/files.html'>file.rename</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>train_dir</span>, <span class='fu'><a href='https://rdrr.io/r/base/basename.html'>basename</a></span><span class='op'>(</span><span class='va'>patients</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>)</span>, <span class='va'>f</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>valid_dir</span>, <span class='fu'><a href='https://rdrr.io/r/base/basename.html'>basename</a></span><span class='op'>(</span><span class='va'>patients</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>)</span>, <span class='va'>f</span><span class='op'>)</span><span class='op'>)</span>    
  <span class='op'>}</span>
  <span class='fu'><a href='https://rdrr.io/r/base/unlink.html'>unlink</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/file.path.html'>file.path</a></span><span class='op'>(</span><span class='va'>train_dir</span>, <span class='fu'><a href='https://rdrr.io/r/base/basename.html'>basename</a></span><span class='op'>(</span><span class='va'>patients</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>)</span><span class='op'>)</span>, recursive <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>We now need a <code>dataset</code> that knows what to do with these files.</p>
<h2 id="dataset">Dataset</h2>
<p>Like every <code>torch</code> dataset, this one has <code>initialize()</code> and <code>.getitem()</code> methods. <code>initialize()</code> creates an inventory of scan and mask file names, to be used by <code>.getitem()</code> when it actually reads those files. In contrast to what we’ve seen in previous posts, though , <code>.getitem()</code> does not simply return input-target pairs in order. Instead, whenever the parameter <code>random_sampling</code> is true, it will perform weighted sampling, preferring items with sizable lesions. This option will be used for the training set, to counter the class imbalance mentioned above.</p>
<p>The other way training and validation sets will differ is use of data augmentation. Training images/masks may be flipped, re-sized, and rotated; probabilities and amounts are configurable.</p>
<p>An instance of <code>brainseg_dataset</code> encapsulates all this functionality:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>brainseg_dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/dataset.html'>dataset</a></span><span class='op'>(</span>
  name <span class='op'>=</span> <span class='st'>"brainseg_dataset"</span>,
  
  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>img_dir</span>,
                        <span class='va'>augmentation_params</span> <span class='op'>=</span> <span class='cn'>NULL</span>,
                        <span class='va'>random_sampling</span> <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>images</span> <span class='op'>&lt;-</span> <span class='fu'>tibble</span><span class='op'>(</span>
      img <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/grep.html'>grep</a></span><span class='op'>(</span>
        <span class='fu'><a href='https://rdrr.io/r/base/list.files.html'>list.files</a></span><span class='op'>(</span>
          <span class='va'>img_dir</span>,
          full.names <span class='op'>=</span> <span class='cn'>TRUE</span>,
          pattern <span class='op'>=</span> <span class='st'>"tif"</span>,
          recursive <span class='op'>=</span> <span class='cn'>TRUE</span>
        <span class='op'>)</span>,
        pattern <span class='op'>=</span> <span class='st'>'mask'</span>,
        invert <span class='op'>=</span> <span class='cn'>TRUE</span>,
        value <span class='op'>=</span> <span class='cn'>TRUE</span>
      <span class='op'>)</span>,
      mask <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/grep.html'>grep</a></span><span class='op'>(</span>
        <span class='fu'><a href='https://rdrr.io/r/base/list.files.html'>list.files</a></span><span class='op'>(</span>
          <span class='va'>img_dir</span>,
          full.names <span class='op'>=</span> <span class='cn'>TRUE</span>,
          pattern <span class='op'>=</span> <span class='st'>"tif"</span>,
          recursive <span class='op'>=</span> <span class='cn'>TRUE</span>
        <span class='op'>)</span>,
        pattern <span class='op'>=</span> <span class='st'>'mask'</span>,
        value <span class='op'>=</span> <span class='cn'>TRUE</span>
      <span class='op'>)</span>
    <span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>slice_weights</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>calc_slice_weights</span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>images</span><span class='op'>$</span><span class='va'>mask</span><span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>augmentation_params</span> <span class='op'>&lt;-</span> <span class='va'>augmentation_params</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>random_sampling</span> <span class='op'>&lt;-</span> <span class='va'>random_sampling</span>
  <span class='op'>}</span>,
  
  .getitem <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>i</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>index</span> <span class='op'>&lt;-</span>
      <span class='kw'>if</span> <span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>random_sampling</span> <span class='op'>==</span> <span class='cn'>TRUE</span><span class='op'>)</span>
        <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='va'>self</span><span class='op'>$</span><span class='fu'>.length</span><span class='op'>(</span><span class='op'>)</span>, <span class='fl'>1</span>, prob <span class='op'>=</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>slice_weights</span><span class='op'>)</span>
    <span class='kw'>else</span>
      <span class='va'>i</span>
    
    <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>images</span><span class='op'>$</span><span class='va'>img</span><span class='op'>[</span><span class='va'>index</span><span class='op'>]</span> <span class='op'>%&gt;%</span>
      <span class='fu'><a href='https://docs.ropensci.org/magick/reference/editing.html'>image_read</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
      <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_to_tensor.html'>transform_to_tensor</a></span><span class='op'>(</span><span class='op'>)</span> 
    <span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>images</span><span class='op'>$</span><span class='va'>mask</span><span class='op'>[</span><span class='va'>index</span><span class='op'>]</span> <span class='op'>%&gt;%</span>
      <span class='fu'><a href='https://docs.ropensci.org/magick/reference/editing.html'>image_read</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
      <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_to_tensor.html'>transform_to_tensor</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
      <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_rgb_to_grayscale.html'>transform_rgb_to_grayscale</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
      <span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_unsqueeze.html'>torch_unsqueeze</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>)</span>
    
    <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>min_max_scale</span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span>
    
    <span class='kw'>if</span> <span class='op'>(</span><span class='op'>!</span><span class='fu'><a href='https://rdrr.io/r/base/NULL.html'>is.null</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>augmentation_params</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>scale_param</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>augmentation_params</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>]</span>
      <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>resize</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='va'>scale_param</span><span class='op'>)</span>
      
      <span class='va'>rot_param</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>augmentation_params</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span>
      <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>rotate</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='va'>rot_param</span><span class='op'>)</span>
      
      <span class='va'>flip_param</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>augmentation_params</span><span class='op'>[</span><span class='fl'>3</span><span class='op'>]</span>
      <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>flip</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='va'>flip_param</span><span class='op'>)</span>
      
    <span class='op'>}</span>
    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>img <span class='op'>=</span> <span class='va'>img</span>, mask <span class='op'>=</span> <span class='va'>mask</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  .length <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>images</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  calc_slice_weights <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>masks</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>weights</span> <span class='op'>&lt;-</span> <span class='fu'>map_dbl</span><span class='op'>(</span><span class='va'>masks</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>img</span> <span class='op'>&lt;-</span>
        <span class='fu'><a href='https://rdrr.io/r/base/integer.html'>as.integer</a></span><span class='op'>(</span><span class='fu'>magick</span><span class='fu'>::</span><span class='fu'><a href='https://docs.ropensci.org/magick/reference/editing.html'>image_data</a></span><span class='op'>(</span><span class='fu'><a href='https://docs.ropensci.org/magick/reference/editing.html'>image_read</a></span><span class='op'>(</span><span class='va'>m</span><span class='op'>)</span>, channels <span class='op'>=</span> <span class='st'>"gray"</span><span class='op'>)</span><span class='op'>)</span>
      <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>img</span> <span class='op'>/</span> <span class='fl'>255</span><span class='op'>)</span>
    <span class='op'>}</span><span class='op'>)</span>
    
    <span class='va'>sum_weights</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>weights</span><span class='op'>)</span>
    <span class='va'>num_weights</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>weights</span><span class='op'>)</span>
    
    <span class='va'>weights</span> <span class='op'>&lt;-</span> <span class='va'>weights</span> <span class='op'>%&gt;%</span> <span class='fu'>map_dbl</span><span class='op'>(</span><span class='kw'>function</span><span class='op'>(</span><span class='va'>w</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>w</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='va'>w</span> <span class='op'>+</span> <span class='va'>sum_weights</span> <span class='op'>*</span> <span class='fl'>0.1</span> <span class='op'>/</span> <span class='va'>num_weights</span><span class='op'>)</span> <span class='op'>/</span> <span class='op'>(</span><span class='va'>sum_weights</span> <span class='op'>*</span> <span class='fl'>1.1</span><span class='op'>)</span>
    <span class='op'>}</span><span class='op'>)</span>
    <span class='va'>weights</span>
  <span class='op'>}</span>,
  
  min_max_scale <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>min</span> <span class='op'>=</span> <span class='va'>x</span><span class='op'>$</span><span class='fu'>min</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span>
    <span class='va'>max</span> <span class='op'>=</span> <span class='va'>x</span><span class='op'>$</span><span class='fu'>max</span><span class='op'>(</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span>
    <span class='va'>x</span><span class='op'>$</span><span class='fu'>clamp_</span><span class='op'>(</span>min <span class='op'>=</span> <span class='va'>min</span>, max <span class='op'>=</span> <span class='va'>max</span><span class='op'>)</span>
    <span class='va'>x</span><span class='op'>$</span><span class='fu'>add_</span><span class='op'>(</span><span class='op'>-</span><span class='va'>min</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>div_</span><span class='op'>(</span><span class='va'>max</span> <span class='op'>-</span> <span class='va'>min</span> <span class='op'>+</span> <span class='fl'>1e-5</span><span class='op'>)</span>
    <span class='va'>x</span>
  <span class='op'>}</span>,
  
  resize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='va'>scale_param</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>img_size</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span>
    <span class='va'>rnd_scale</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span> <span class='op'>-</span> <span class='va'>scale_param</span>, <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>scale_param</span><span class='op'>)</span>
    <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_resize.html'>transform_resize</a></span><span class='op'>(</span><span class='va'>img</span>, size <span class='op'>=</span> <span class='va'>rnd_scale</span> <span class='op'>*</span> <span class='va'>img_size</span><span class='op'>)</span>
    <span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_resize.html'>transform_resize</a></span><span class='op'>(</span><span class='va'>mask</span>, size <span class='op'>=</span> <span class='va'>rnd_scale</span> <span class='op'>*</span> <span class='va'>img_size</span><span class='op'>)</span>
    <span class='va'>diff</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/dim.html'>dim</a></span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>2</span><span class='op'>]</span> <span class='op'>-</span> <span class='va'>img_size</span>
    <span class='kw'>if</span> <span class='op'>(</span><span class='va'>diff</span> <span class='op'>&gt;</span> <span class='fl'>0</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>top</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>ceiling</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>
      <span class='va'>left</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>ceiling</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>
      <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_crop.html'>transform_crop</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>top</span>, <span class='va'>left</span>, <span class='va'>img_size</span>, <span class='va'>img_size</span><span class='op'>)</span>
      <span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_crop.html'>transform_crop</a></span><span class='op'>(</span><span class='va'>mask</span>, <span class='va'>top</span>, <span class='va'>left</span>, <span class='va'>img_size</span>, <span class='va'>img_size</span><span class='op'>)</span>
    <span class='op'>}</span> <span class='kw'>else</span> <span class='op'>{</span>
      <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_pad.html'>transform_pad</a></span><span class='op'>(</span><span class='va'>img</span>,
                           padding <span class='op'>=</span> <span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
                             <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>ceiling</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>,
                             <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>,
                             <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>ceiling</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>,
                             <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>
                           <span class='op'>)</span><span class='op'>)</span>
      <span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_pad.html'>transform_pad</a></span><span class='op'>(</span><span class='va'>mask</span>, padding <span class='op'>=</span> <span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span>
        <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>ceiling</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span> <span class='fl'>2</span><span class='op'>)</span>,
        <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span>
                <span class='fl'>2</span><span class='op'>)</span>,
        <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>ceiling</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span>
                  <span class='fl'>2</span><span class='op'>)</span>,
        <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>floor</a></span><span class='op'>(</span><span class='va'>diff</span> <span class='op'>/</span>
                <span class='fl'>2</span><span class='op'>)</span>
      <span class='op'>)</span><span class='op'>)</span>
    <span class='op'>}</span>
    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  rotate <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='va'>rot_param</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>rnd_rot</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>1</span> <span class='op'>-</span> <span class='va'>rot_param</span>, <span class='fl'>1</span> <span class='op'>+</span> <span class='va'>rot_param</span><span class='op'>)</span>
    <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_rotate.html'>transform_rotate</a></span><span class='op'>(</span><span class='va'>img</span>, angle <span class='op'>=</span> <span class='va'>rnd_rot</span><span class='op'>)</span>
    <span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_rotate.html'>transform_rotate</a></span><span class='op'>(</span><span class='va'>mask</span>, angle <span class='op'>=</span> <span class='va'>rnd_rot</span><span class='op'>)</span>
    
    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  flip <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='va'>flip_param</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>rnd_flip</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>)</span>
    <span class='kw'>if</span> <span class='op'>(</span><span class='va'>rnd_flip</span> <span class='op'>&gt;</span> <span class='va'>flip_param</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_hflip.html'>transform_hflip</a></span><span class='op'>(</span><span class='va'>img</span><span class='op'>)</span>
      <span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_hflip.html'>transform_hflip</a></span><span class='op'>(</span><span class='va'>mask</span><span class='op'>)</span>
    <span class='op'>}</span>
    
    <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span>
  <span class='op'>}</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>After instantiation, we see we have 2977 training pairs and 952 validation pairs, respectively:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>train_ds</span> <span class='op'>&lt;-</span> <span class='fu'>brainseg_dataset</span><span class='op'>(</span>
  <span class='va'>train_dir</span>,
  augmentation_params <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0.05</span>, <span class='fl'>15</span>, <span class='fl'>0.5</span><span class='op'>)</span>,
  random_sampling <span class='op'>=</span> <span class='cn'>TRUE</span>
<span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>train_ds</span><span class='op'>)</span>
<span class='co'># 2977</span>

<span class='va'>valid_ds</span> <span class='op'>&lt;-</span> <span class='fu'>brainseg_dataset</span><span class='op'>(</span>
  <span class='va'>valid_dir</span>,
  augmentation_params <span class='op'>=</span> <span class='cn'>NULL</span>,
  random_sampling <span class='op'>=</span> <span class='cn'>FALSE</span>
<span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>valid_ds</span><span class='op'>)</span>
<span class='co'># 952</span>
</code></pre>
</div>
</div>
<p>As a correctness check, let’s plot an image and associated mask:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='fu'><a href='https://rdrr.io/r/graphics/par.html'>par</a></span><span class='op'>(</span>mfrow <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>, <span class='fl'>2</span><span class='op'>)</span>, mar <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span>

<span class='va'>img_and_mask</span> <span class='op'>&lt;-</span> <span class='va'>valid_ds</span><span class='op'>[</span><span class='fl'>27</span><span class='op'>]</span>
<span class='va'>img</span> <span class='op'>&lt;-</span> <span class='va'>img_and_mask</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>
<span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='va'>img_and_mask</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span>

<span class='va'>img</span><span class='op'>$</span><span class='fu'>permute</span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>, <span class='fl'>3</span>, <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/grDevices/as.raster.html'>as.raster</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='va'>mask</span><span class='op'>$</span><span class='fu'>squeeze</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/grDevices/as.raster.html'>as.raster</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<p><img src="images/scan_and_mask.png" width="402" /></p>
</div>
<p>With <code>torch</code>, it is straightforward to inspect what happens when you change augmentation-related parameters. We just pick a pair from the validation set, which has not had any augmentation applied as yet, and call <code>valid_ds$&lt;augmentation_func()&gt;</code> directly. Just for fun, let’s use more “extreme” parameters here than we do in actual training. (Actual training uses the settings from Mateusz’ GitHub repository, which we assume have been carefully chosen for optimal performance.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>)</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>img_and_mask</span> <span class='op'>&lt;-</span> <span class='va'>valid_ds</span><span class='op'>[</span><span class='fl'>77</span><span class='op'>]</span>
<span class='va'>img</span> <span class='op'>&lt;-</span> <span class='va'>img_and_mask</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span>
<span class='va'>mask</span> <span class='op'>&lt;-</span> <span class='va'>img_and_mask</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span>

<span class='va'>imgs</span> <span class='op'>&lt;-</span> <span class='fu'>map</span> <span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>24</span>, <span class='kw'>function</span><span class='op'>(</span><span class='va'>i</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='co'># scale factor; train_ds really uses 0.05</span>
  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>valid_ds</span><span class='op'>$</span><span class='fu'>resize</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='fl'>0.2</span><span class='op'>)</span> 
  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>valid_ds</span><span class='op'>$</span><span class='fu'>flip</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='fl'>0.5</span><span class='op'>)</span>
  <span class='co'># rotation angle; train_ds really uses 15</span>
  <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='va'>valid_ds</span><span class='op'>$</span><span class='fu'>rotate</span><span class='op'>(</span><span class='va'>img</span>, <span class='va'>mask</span>, <span class='fl'>90</span><span class='op'>)</span> 
  <span class='va'>img</span> <span class='op'>%&gt;%</span>
    <span class='fu'><a href='https://rdrr.io/pkg/torchvision/man/transform_rgb_to_grayscale.html'>transform_rgb_to_grayscale</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'>rowid_to_column</span><span class='op'>(</span>var <span class='op'>=</span> <span class='st'>"Y"</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'>gather</span><span class='op'>(</span>key <span class='op'>=</span> <span class='st'>"X"</span>, value <span class='op'>=</span> <span class='st'>"value"</span>, <span class='op'>-</span><span class='va'>Y</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'>mutate</span><span class='op'>(</span>X <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/numeric.html'>as.numeric</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/grep.html'>gsub</a></span><span class='op'>(</span><span class='st'>"V"</span>, <span class='st'>""</span>, <span class='va'>X</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'>ggplot</span><span class='op'>(</span><span class='fu'>aes</span><span class='op'>(</span><span class='va'>X</span>, <span class='va'>Y</span>, fill <span class='op'>=</span> <span class='va'>value</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span>
    <span class='fu'>geom_raster</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span>
    <span class='fu'>theme_void</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span>
    <span class='fu'>theme</span><span class='op'>(</span>legend.position <span class='op'>=</span> <span class='st'>"none"</span><span class='op'>)</span> <span class='op'>+</span>
    <span class='fu'>theme</span><span class='op'>(</span>aspect.ratio <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span>
  
<span class='op'>}</span><span class='op'>)</span>

<span class='fu'><a href='https://wilkelab.org/cowplot/reference/plot_grid.html'>plot_grid</a></span><span class='op'>(</span>plotlist <span class='op'>=</span> <span class='va'>imgs</span>, nrow <span class='op'>=</span> <span class='fl'>4</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<p><img src="images/brainseg_augmentation.png" width="402" /></p>
</div>
<p>Now we still need the data loaders, and then, nothing keeps us from proceeding to the next big task: building the model.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>batch_size</span> <span class='op'>&lt;-</span> <span class='fl'>4</span>
<span class='va'>train_dl</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/dataloader.html'>dataloader</a></span><span class='op'>(</span><span class='va'>train_ds</span>, <span class='va'>batch_size</span><span class='op'>)</span>
<span class='va'>valid_dl</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/dataloader.html'>dataloader</a></span><span class='op'>(</span><span class='va'>valid_ds</span>, <span class='va'>batch_size</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="model">Model</h2>
<p>Our model nicely illustrates the kind of modular code that comes “naturally” with <code>torch</code>. We approach things top-down, starting with the U-Net container itself.</p>
<p><code>unet</code> takes care of the global composition – how far “down” do we go, shrinking the image while incrementing the number of filters, and then how do we go “up” again?</p>
<p>Importantly, it is also the system’s memory: In <code>forward()</code>, it keeps track of layer outputs seen going “down,” to be added back in going “up.”</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>unet</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_module.html'>nn_module</a></span><span class='op'>(</span>
  <span class='st'>"unet"</span>,
  
  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>channels_in</span> <span class='op'>=</span> <span class='fl'>3</span>,
                        <span class='va'>n_classes</span> <span class='op'>=</span> <span class='fl'>1</span>,
                        <span class='va'>depth</span> <span class='op'>=</span> <span class='fl'>5</span>,
                        <span class='va'>n_filters</span> <span class='op'>=</span> <span class='fl'>6</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>down_path</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_module_list.html'>nn_module_list</a></span><span class='op'>(</span><span class='op'>)</span>
    
    <span class='va'>prev_channels</span> <span class='op'>&lt;-</span> <span class='va'>channels_in</span>
    <span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='va'>depth</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>self</span><span class='op'>$</span><span class='va'>down_path</span><span class='op'>$</span><span class='fu'>append</span><span class='op'>(</span><span class='fu'>down_block</span><span class='op'>(</span><span class='va'>prev_channels</span>, <span class='fl'>2</span> <span class='op'>^</span> <span class='op'>(</span><span class='va'>n_filters</span> <span class='op'>+</span> <span class='va'>i</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
      <span class='va'>prev_channels</span> <span class='op'>&lt;-</span> <span class='fl'>2</span> <span class='op'>^</span> <span class='op'>(</span><span class='va'>n_filters</span> <span class='op'>+</span> <span class='va'>i</span> <span class='op'>-</span><span class='fl'>1</span><span class='op'>)</span>
    <span class='op'>}</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>up_path</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_module_list.html'>nn_module_list</a></span><span class='op'>(</span><span class='op'>)</span>
    
    <span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='op'>(</span><span class='op'>(</span><span class='va'>depth</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>:</span><span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>self</span><span class='op'>$</span><span class='va'>up_path</span><span class='op'>$</span><span class='fu'>append</span><span class='op'>(</span><span class='fu'>up_block</span><span class='op'>(</span><span class='va'>prev_channels</span>, <span class='fl'>2</span> <span class='op'>^</span> <span class='op'>(</span><span class='va'>n_filters</span> <span class='op'>+</span> <span class='va'>i</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
      <span class='va'>prev_channels</span> <span class='op'>&lt;-</span> <span class='fl'>2</span> <span class='op'>^</span> <span class='op'>(</span><span class='va'>n_filters</span> <span class='op'>+</span> <span class='va'>i</span> <span class='op'>-</span> <span class='fl'>1</span><span class='op'>)</span>
    <span class='op'>}</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>last</span> <span class='op'>=</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_conv2d.html'>nn_conv2d</a></span><span class='op'>(</span><span class='va'>prev_channels</span>, <span class='va'>n_classes</span>, kernel_size <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>blocks</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='op'>)</span>
    
    <span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>down_path</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
      <span class='va'>x</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>down_path</span><span class='op'>[[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>]</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>
      <span class='kw'>if</span> <span class='op'>(</span><span class='va'>i</span> <span class='op'>!=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>down_path</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
        <span class='va'>blocks</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>blocks</span>, <span class='va'>x</span><span class='op'>)</span>
        <span class='va'>x</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nnf_max_pool2d.html'>nnf_max_pool2d</a></span><span class='op'>(</span><span class='va'>x</span>, <span class='fl'>2</span><span class='op'>)</span>
      <span class='op'>}</span>
    <span class='op'>}</span>
    
    <span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='va'>up_path</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>  
      <span class='va'>x</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='va'>up_path</span><span class='op'>[[</span><span class='va'>i</span><span class='op'>]</span><span class='op'>]</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>blocks</span><span class='op'>[[</span><span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>blocks</span><span class='op'>)</span> <span class='op'>-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span>
    <span class='op'>}</span>
    
    <span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_sigmoid.html'>torch_sigmoid</a></span><span class='op'>(</span><span class='va'>self</span><span class='op'>$</span><span class='fu'>last</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>)</span>
  <span class='op'>}</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p><code>unet</code> delegates to two containers just below it in the hierarchy: <code>down_block</code> and <code>up_block</code>. While <code>down_block</code> is “just” there for aesthetic reasons (it immediately delegates to its own workhorse, <code>conv_block</code>), in <code>up_block</code> we see the U-Net “bridges” in action.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>down_block</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_module.html'>nn_module</a></span><span class='op'>(</span>
  <span class='st'>"down_block"</span>,
  
  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>in_size</span>, <span class='va'>out_size</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>conv_block</span> <span class='op'>&lt;-</span> <span class='fu'>conv_block</span><span class='op'>(</span><span class='va'>in_size</span>, <span class='va'>out_size</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='va'>self</span><span class='op'>$</span><span class='fu'>conv_block</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>
  <span class='op'>}</span>
<span class='op'>)</span>

<span class='va'>up_block</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_module.html'>nn_module</a></span><span class='op'>(</span>
  <span class='st'>"up_block"</span>,
  
  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>in_size</span>, <span class='va'>out_size</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>up</span> <span class='op'>=</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html'>nn_conv_transpose2d</a></span><span class='op'>(</span><span class='va'>in_size</span>,
                                  <span class='va'>out_size</span>,
                                  kernel_size <span class='op'>=</span> <span class='fl'>2</span>,
                                  stride <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span>
    <span class='va'>self</span><span class='op'>$</span><span class='va'>conv_block</span> <span class='op'>=</span> <span class='fu'>conv_block</span><span class='op'>(</span><span class='va'>in_size</span>, <span class='va'>out_size</span><span class='op'>)</span>
  <span class='op'>}</span>,
  
  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>bridge</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>up</span> <span class='op'>&lt;-</span> <span class='va'>self</span><span class='op'>$</span><span class='fu'>up</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>
    <span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_cat.html'>torch_cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>up</span>, <span class='va'>bridge</span><span class='op'>)</span>, <span class='fl'>2</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
      <span class='va'>self</span><span class='op'>$</span><span class='fu'>conv_block</span><span class='op'>(</span><span class='op'>)</span>
  <span class='op'>}</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Finally, a <code>conv_block</code> is a sequential structure containing convolutional, ReLU, and dropout layers.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>conv_block</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_module.html'>nn_module</a></span><span class='op'>(</span> 
  <span class='st'>"conv_block"</span>,
  
  initialize <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>in_size</span>, <span class='va'>out_size</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>self</span><span class='op'>$</span><span class='va'>conv_block</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_sequential.html'>nn_sequential</a></span><span class='op'>(</span>
      <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_conv2d.html'>nn_conv2d</a></span><span class='op'>(</span><span class='va'>in_size</span>, <span class='va'>out_size</span>, kernel_size <span class='op'>=</span> <span class='fl'>3</span>, padding <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span>,
      <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_relu.html'>nn_relu</a></span><span class='op'>(</span><span class='op'>)</span>,
      <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_dropout.html'>nn_dropout</a></span><span class='op'>(</span><span class='fl'>0.6</span><span class='op'>)</span>,
      <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_conv2d.html'>nn_conv2d</a></span><span class='op'>(</span><span class='va'>out_size</span>, <span class='va'>out_size</span>, kernel_size <span class='op'>=</span> <span class='fl'>3</span>, padding <span class='op'>=</span> <span class='fl'>1</span><span class='op'>)</span>,
      <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nn_relu.html'>nn_relu</a></span><span class='op'>(</span><span class='op'>)</span>
    <span class='op'>)</span>
  <span class='op'>}</span>,
  
  forward <span class='op'>=</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span><span class='op'>{</span>
    <span class='va'>self</span><span class='op'>$</span><span class='fu'>conv_block</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>
  <span class='op'>}</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Now instantiate the model, and possibly, move it to the GPU:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>device</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_device.html'>torch_device</a></span><span class='op'>(</span><span class='kw'>if</span><span class='op'>(</span><span class='fu'><a href='https://torch.mlverse.org/docs/reference/cuda_is_available.html'>cuda_is_available</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span> <span class='st'>"cuda"</span> <span class='kw'>else</span> <span class='st'>"cpu"</span><span class='op'>)</span>
<span class='va'>model</span> <span class='op'>&lt;-</span> <span class='fu'>unet</span><span class='op'>(</span>depth <span class='op'>=</span> <span class='fl'>5</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="optimization">Optimization</h2>
<p>We train our model with a combination of cross entropy and <a href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient">dice loss</a>.</p>
<p>The latter, though not shipped with <code>torch</code>, may straightforwardly be implemented manually:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>calc_dice_loss</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>y_pred</span>, <span class='va'>y_true</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='va'>smooth</span> <span class='op'>&lt;-</span> <span class='fl'>1</span>
  <span class='va'>y_pred</span> <span class='op'>&lt;-</span> <span class='va'>y_pred</span><span class='op'>$</span><span class='fu'>view</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>1</span><span class='op'>)</span>
  <span class='va'>y_true</span> <span class='op'>&lt;-</span> <span class='va'>y_true</span><span class='op'>$</span><span class='fu'>view</span><span class='op'>(</span><span class='op'>-</span><span class='fl'>1</span><span class='op'>)</span>
  <span class='va'>intersection</span> <span class='op'>&lt;-</span> <span class='op'>(</span><span class='va'>y_pred</span> <span class='op'>*</span> <span class='va'>y_true</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>sum</span><span class='op'>(</span><span class='op'>)</span>
  
  <span class='fl'>1</span> <span class='op'>-</span> <span class='op'>(</span><span class='op'>(</span><span class='fl'>2</span> <span class='op'>*</span> <span class='va'>intersection</span> <span class='op'>+</span> <span class='va'>smooth</span><span class='op'>)</span> <span class='op'>/</span> <span class='op'>(</span><span class='va'>y_pred</span><span class='op'>$</span><span class='fu'>sum</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span> <span class='va'>y_true</span><span class='op'>$</span><span class='fu'>sum</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span> <span class='va'>smooth</span><span class='op'>)</span><span class='op'>)</span>
<span class='op'>}</span>

<span class='va'>dice_weight</span> <span class='op'>&lt;-</span> <span class='fl'>0.3</span>
</code></pre>
</div>
</div>
<p>Optimization uses stochastic gradient descent (SGD), together with the one-cycle learning rate scheduler introduced in the context of <a href="https://blogs.rstudio.com/ai/posts/2020-10-19-torch-image-classification/">image classification with torch</a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>optimizer</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/optim_sgd.html'>optim_sgd</a></span><span class='op'>(</span><span class='va'>model</span><span class='op'>$</span><span class='va'>parameters</span>, lr <span class='op'>=</span> <span class='fl'>0.1</span>, momentum <span class='op'>=</span> <span class='fl'>0.9</span><span class='op'>)</span>

<span class='va'>num_epochs</span> <span class='op'>&lt;-</span> <span class='fl'>20</span>

<span class='va'>scheduler</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/lr_one_cycle.html'>lr_one_cycle</a></span><span class='op'>(</span>
  <span class='va'>optimizer</span>,
  max_lr <span class='op'>=</span> <span class='fl'>0.1</span>,
  steps_per_epoch <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/length.html'>length</a></span><span class='op'>(</span><span class='va'>train_dl</span><span class='op'>)</span>,
  epochs <span class='op'>=</span> <span class='va'>num_epochs</span>
<span class='op'>)</span>
</code></pre>
</div>
</div>
<h2 id="training">Training</h2>
<p>The training loop then follows the usual scheme. One thing to note: Every epoch, we save the model (using <code>torch_save()</code>), so we can later pick the best one, should performance have degraded thereafter.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>train_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>zero_grad</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>b</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>target</span> <span class='op'>&lt;-</span> <span class='va'>b</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span>
  
  <span class='va'>bce_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy.html'>nnf_binary_cross_entropy</a></span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>target</span><span class='op'>)</span>
  <span class='va'>dice_loss</span> <span class='op'>&lt;-</span> <span class='fu'>calc_dice_loss</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>target</span><span class='op'>)</span>
  <span class='va'>loss</span> <span class='op'>&lt;-</span>  <span class='va'>dice_weight</span> <span class='op'>*</span> <span class='va'>dice_loss</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>-</span> <span class='va'>dice_weight</span><span class='op'>)</span> <span class='op'>*</span> <span class='va'>bce_loss</span>
  
  <span class='va'>loss</span><span class='op'>$</span><span class='fu'>backward</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>optimizer</span><span class='op'>$</span><span class='fu'>step</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>scheduler</span><span class='op'>$</span><span class='fu'>step</span><span class='op'>(</span><span class='op'>)</span>

  <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>bce_loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span>, <span class='va'>dice_loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span>, <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
  
<span class='op'>}</span>

<span class='va'>valid_batch</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='va'>output</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>b</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>target</span> <span class='op'>&lt;-</span> <span class='va'>b</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span>

  <span class='va'>bce_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy.html'>nnf_binary_cross_entropy</a></span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>target</span><span class='op'>)</span>
  <span class='va'>dice_loss</span> <span class='op'>&lt;-</span> <span class='fu'>calc_dice_loss</span><span class='op'>(</span><span class='va'>output</span>, <span class='va'>target</span><span class='op'>)</span>
  <span class='va'>loss</span> <span class='op'>&lt;-</span>  <span class='va'>dice_weight</span> <span class='op'>*</span> <span class='va'>dice_loss</span> <span class='op'>+</span> <span class='op'>(</span><span class='fl'>1</span> <span class='op'>-</span> <span class='va'>dice_weight</span><span class='op'>)</span> <span class='op'>*</span> <span class='va'>bce_loss</span>
  
  <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span><span class='va'>bce_loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span>, <span class='va'>dice_loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span>, <span class='va'>loss</span><span class='op'>$</span><span class='fu'>item</span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span>
  
<span class='op'>}</span>

<span class='kw'>for</span> <span class='op'>(</span><span class='va'>epoch</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='va'>num_epochs</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='va'>model</span><span class='op'>$</span><span class='fu'>train</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>train_bce</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>train_dice</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span>
  
  <span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/enumerate.html'>enumerate</a></span><span class='op'>(</span><span class='va'>train_dl</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
    <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>bce_loss</span>, <span class='va'>dice_loss</span>, <span class='va'>loss</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'>train_batch</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span>
    <span class='va'>train_bce</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>train_bce</span>, <span class='va'>bce_loss</span><span class='op'>)</span>
    <span class='va'>train_dice</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>train_dice</span>, <span class='va'>dice_loss</span><span class='op'>)</span>
    <span class='va'>train_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>train_loss</span>, <span class='va'>loss</span><span class='op'>)</span>
  <span class='op'>}</span>
  
  <span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_save.html'>torch_save</a></span><span class='op'>(</span><span class='va'>model</span>, <span class='fu'><a href='https://rdrr.io/r/base/paste.html'>paste0</a></span><span class='op'>(</span><span class='st'>"model_"</span>, <span class='va'>epoch</span>, <span class='st'>".pt"</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sprintf.html'>sprintf</a></span><span class='op'>(</span><span class='st'>"\nEpoch %d, training: loss:%3f, bce: %3f, dice: %3f\n"</span>,
              <span class='va'>epoch</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>train_loss</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>train_bce</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>train_dice</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
  
  <span class='va'>model</span><span class='op'>$</span><span class='fu'>eval</span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>valid_bce</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>valid_dice</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>valid_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>)</span>
  
  <span class='va'>i</span> <span class='op'>&lt;-</span> <span class='fl'>0</span>
  <span class='kw'>for</span> <span class='op'>(</span><span class='va'>b</span> <span class='kw'>in</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/enumerate.html'>enumerate</a></span><span class='op'>(</span><span class='va'>valid_dl</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>{</span>
    
    <span class='va'>i</span> <span class='op'>&lt;&lt;-</span> <span class='va'>i</span> <span class='op'>+</span> <span class='fl'>1</span>
    <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>bce_loss</span>, <span class='va'>dice_loss</span>, <span class='va'>loss</span><span class='op'>)</span> <span class='op'>%&lt;-%</span> <span class='fu'>valid_batch</span><span class='op'>(</span><span class='va'>b</span><span class='op'>)</span>
    <span class='va'>valid_bce</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>valid_bce</span>, <span class='va'>bce_loss</span><span class='op'>)</span>
    <span class='va'>valid_dice</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>valid_dice</span>, <span class='va'>dice_loss</span><span class='op'>)</span>
    <span class='va'>valid_loss</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='va'>valid_loss</span>, <span class='va'>loss</span><span class='op'>)</span>
    
  <span class='op'>}</span>
  
  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sprintf.html'>sprintf</a></span><span class='op'>(</span><span class='st'>"\nEpoch %d, validation: loss:%3f, bce: %3f, dice: %3f\n"</span>,
              <span class='va'>epoch</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>valid_loss</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>valid_bce</span><span class='op'>)</span>, <span class='fu'><a href='https://rdrr.io/r/base/mean.html'>mean</a></span><span class='op'>(</span><span class='va'>valid_dice</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<pre><code>Epoch 1, training: loss:0.304232, bce: 0.148578, dice: 0.667423
Epoch 1, validation: loss:0.333961, bce: 0.127171, dice: 0.816471

Epoch 2, training: loss:0.194665, bce: 0.101973, dice: 0.410945
Epoch 2, validation: loss:0.341121, bce: 0.117465, dice: 0.862983

[...]

Epoch 19, training: loss:0.073863, bce: 0.038559, dice: 0.156236
Epoch 19, validation: loss:0.302878, bce: 0.109721, dice: 0.753577

Epoch 20, training: loss:0.070621, bce: 0.036578, dice: 0.150055
Epoch 20, validation: loss:0.295852, bce: 0.101750, dice: 0.748757</code></pre>
<h2 id="evaluation">Evaluation</h2>
<p>In this run, it is the final model that performs best on the validation set. Still, we’d like to show how to load a saved model, using <code>torch_load()</code> .</p>
<p>Once loaded, put the model into <code>eval</code> mode:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='va'>saved_model</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/torch_load.html'>torch_load</a></span><span class='op'>(</span><span class='st'>"model_20.pt"</span><span class='op'>)</span> 

<span class='va'>model</span> <span class='op'>&lt;-</span> <span class='va'>saved_model</span>
<span class='va'>model</span><span class='op'>$</span><span class='fu'>eval</span><span class='op'>(</span><span class='op'>)</span>
</code></pre>
</div>
</div>
<p>Now, since we don’t have a separate test set, we already know the average out-of-sample metrics; but in the end, what we care about are the generated masks. Let’s view some, displaying ground truth and MRI scans for comparison.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre><code><span class='co'># without random sampling, we'd mainly see lesion-free patches</span>
<span class='va'>eval_ds</span> <span class='op'>&lt;-</span> <span class='fu'>brainseg_dataset</span><span class='op'>(</span><span class='va'>valid_dir</span>, augmentation_params <span class='op'>=</span> <span class='cn'>NULL</span>, random_sampling <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>
<span class='va'>eval_dl</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/dataloader.html'>dataloader</a></span><span class='op'>(</span><span class='va'>eval_ds</span>, batch_size <span class='op'>=</span> <span class='fl'>8</span><span class='op'>)</span>

<span class='va'>batch</span> <span class='op'>&lt;-</span> <span class='va'>eval_dl</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/dataloader_make_iter.html'>dataloader_make_iter</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/dataloader_next.html'>dataloader_next</a></span><span class='op'>(</span><span class='op'>)</span>

<span class='fu'><a href='https://rdrr.io/r/graphics/par.html'>par</a></span><span class='op'>(</span>mfcol <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>3</span>, <span class='fl'>8</span><span class='op'>)</span>, mar <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>0</span>, <span class='fl'>1</span>, <span class='fl'>0</span>, <span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span>

<span class='kw'>for</span> <span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fl'>8</span><span class='op'>)</span> <span class='op'>{</span>
  
  <span class='va'>img</span> <span class='op'>&lt;-</span> <span class='va'>batch</span><span class='op'>[[</span><span class='fl'>1</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='va'>i</span>, <span class='va'>..</span>, drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span>
  <span class='va'>inferred_mask</span> <span class='op'>&lt;-</span> <span class='fu'>model</span><span class='op'>(</span><span class='va'>img</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span><span class='op'>)</span>
  <span class='va'>true_mask</span> <span class='op'>&lt;-</span> <span class='va'>batch</span><span class='op'>[[</span><span class='fl'>2</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='va'>i</span>, <span class='va'>..</span>, drop <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>]</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='va'>device</span><span class='op'>)</span>
  
  <span class='va'>bce</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy.html'>nnf_binary_cross_entropy</a></span><span class='op'>(</span><span class='va'>inferred_mask</span>, <span class='va'>true_mask</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='st'>"cpu"</span><span class='op'>)</span> <span class='op'>%&gt;%</span>
    <span class='fu'><a href='https://rdrr.io/r/base/numeric.html'>as.numeric</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>dc</span> <span class='op'>&lt;-</span> <span class='fu'>calc_dice_loss</span><span class='op'>(</span><span class='va'>inferred_mask</span>, <span class='va'>true_mask</span><span class='op'>)</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='st'>"cpu"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/numeric.html'>as.numeric</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/sprintf.html'>sprintf</a></span><span class='op'>(</span><span class='st'>"\nSample %d, bce: %3f, dice: %3f\n"</span>, <span class='va'>i</span>, <span class='va'>bce</span>, <span class='va'>dc</span><span class='op'>)</span><span class='op'>)</span>
  

  <span class='va'>inferred_mask</span> <span class='op'>&lt;-</span> <span class='va'>inferred_mask</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='st'>"cpu"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='va'>.</span><span class='op'>[</span><span class='fl'>1</span>, <span class='fl'>1</span>, , <span class='op'>]</span>
  
  <span class='va'>inferred_mask</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/ifelse.html'>ifelse</a></span><span class='op'>(</span><span class='va'>inferred_mask</span> <span class='op'>&gt;</span> <span class='fl'>0.5</span>, <span class='fl'>1</span>, <span class='fl'>0</span><span class='op'>)</span>
  
  <span class='va'>img</span><span class='op'>[</span><span class='fl'>1</span>, <span class='fl'>1</span>, ,<span class='op'>]</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/grDevices/as.raster.html'>as.raster</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>true_mask</span><span class='op'>$</span><span class='fu'>to</span><span class='op'>(</span>device <span class='op'>=</span> <span class='st'>"cpu"</span><span class='op'>)</span><span class='op'>[</span><span class='fl'>1</span>, <span class='fl'>1</span>, ,<span class='op'>]</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/array.html'>as.array</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/grDevices/as.raster.html'>as.raster</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='op'>)</span>
  <span class='va'>inferred_mask</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/grDevices/as.raster.html'>as.raster</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='op'>)</span>
<span class='op'>}</span>
</code></pre>
</div>
</div>
<p>We also print the individual cross entropy and dice losses; relating those to the generated masks might yield useful information for model tuning.</p>
<pre><code>Sample 1, bce: 0.088406, dice: 0.387786}

Sample 2, bce: 0.026839, dice: 0.205724

Sample 3, bce: 0.042575, dice: 0.187884

Sample 4, bce: 0.094989, dice: 0.273895

Sample 5, bce: 0.026839, dice: 0.205724

Sample 6, bce: 0.020917, dice: 0.139484

Sample 7, bce: 0.094989, dice: 0.273895

Sample 8, bce: 2.310956, dice: 0.999824</code></pre>
<div class="layout-chunk" data-layout="l-body-outset">
<p><img src="images/eval_masks.png" width="600" /></p>
</div>
<p>While far from perfect, most of these masks aren’t that bad – a nice result given the small dataset!</p>
<h2 id="wrapup">Wrapup</h2>
<p>This has been our most complex <code>torch</code> post so far; however, we hope you’ve found the time well spent. For one, among applications of deep learning, medical image segmentation stands out as highly societally useful. Secondly, U-Net-like architectures are employed in many other areas. And finally, we once more saw <code>torch</code>’s flexibility and intuitive behavior in action.</p>
<p>Thanks for reading!</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-BUDA2019218" class="csl-entry" role="doc-biblioentry">
Buda, Mateusz, Ashirbani Saha, and Maciej A. Mazurowski. 2019. <span>“Association of Genomic Subtypes of Lower-Grade Gliomas with Shape Features Automatically Extracted by a Deep Learning Algorithm.”</span> <em>Computers in Biology and Medicine</em> 109: 218–25. https://doi.org/<a href="https://doi.org/10.1016/j.compbiomed.2019.05.002">https://doi.org/10.1016/j.compbiomed.2019.05.002</a>.
</div>
<div id="ref-RonnebergerFB15" class="csl-entry" role="doc-biblioentry">
Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. <span>“U-Net: Convolutional Networks for Biomedical Image Segmentation.”</span> <em>CoRR</em> abs/1505.04597. <a href="http://arxiv.org/abs/1505.04597">http://arxiv.org/abs/1505.04597</a>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Yes, we did a few experiments, confirming that more augmentation isn’t better … what did I say about inevitably ending up doing optimization on the validation set …<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="references">References</h3>
<div id="references-listing"></div>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
